{
 "cells": [
  {
   "source": [
    "# Virtual Internships Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Modules and Data\n",
    "\n",
    "First we will import all relevant modules. We will then import our csv as a pandas dataframe for easy use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Unnamed: 0  userIDs implementation  Line_ID ChatGroup  \\\n",
       "0               1        1              a        1     PRNLT   \n",
       "1               2        1              a        2     PRNLT   \n",
       "2               3        1              a        3     PRNLT   \n",
       "3               4        1              a        4     PRNLT   \n",
       "4               5        1              a        5     PRNLT   \n",
       "...           ...      ...            ...      ...       ...   \n",
       "19175       19176      392              o    19179    PESPVP   \n",
       "19176       19177      388              o    19180    PESPVP   \n",
       "19177       19178      367              o    19181    PESPVP   \n",
       "19178       19179      393              o    19182    PESPVP   \n",
       "19179       19180      367              o    19183    PESPVP   \n",
       "\n",
       "                                                 content  group_id RoleName  \\\n",
       "0                      Hello team. Welcome to Nephrotex!         2   Mentor   \n",
       "1      I'm Maria Williams. I'll be your design adviso...         2   Mentor   \n",
       "2            I'm here to help if you have any questions.         2   Mentor   \n",
       "3      Please introduce yourselves with the name you ...         2   Mentor   \n",
       "4      I just want to make sure everyone has found th...         2   Mentor   \n",
       "...                                                  ...       ...      ...   \n",
       "19175                                                yes         6   Player   \n",
       "19176                                        sounds good         6   Player   \n",
       "19177          Well, we are out of time for our meeting.         6   Mentor   \n",
       "19178                                          Precisely         6   Player   \n",
       "19179  Good discussion today! Don't forget to complet...         6   Mentor   \n",
       "\n",
       "                                                roomName  \\\n",
       "0      Introduction and Workflow Tutorial with Entran...   \n",
       "1      Introduction and Workflow Tutorial with Entran...   \n",
       "2      Introduction and Workflow Tutorial with Entran...   \n",
       "3      Introduction and Workflow Tutorial with Entran...   \n",
       "4      Introduction and Workflow Tutorial with Entran...   \n",
       "...                                                  ...   \n",
       "19175  Reflection team discussion of first batch results   \n",
       "19176  Reflection team discussion of first batch results   \n",
       "19177  Reflection team discussion of first batch results   \n",
       "19178  Reflection team discussion of first batch results   \n",
       "19179  Reflection team discussion of first batch results   \n",
       "\n",
       "       m_experimental_testing  m_making_design_choices  m_asking_questions  \\\n",
       "0                           0                        0                   0   \n",
       "1                           0                        0                   0   \n",
       "2                           0                        0                   0   \n",
       "3                           0                        0                   0   \n",
       "4                           0                        0                   0   \n",
       "...                       ...                      ...                 ...   \n",
       "19175                       0                        0                   0   \n",
       "19176                       0                        0                   0   \n",
       "19177                       0                        0                   0   \n",
       "19178                       0                        0                   0   \n",
       "19179                       0                        0                   0   \n",
       "\n",
       "       j_customer_consultants_requests  j_performance_parameters_requirements  \\\n",
       "0                                    0                                      0   \n",
       "1                                    0                                      0   \n",
       "2                                    0                                      0   \n",
       "3                                    1                                      0   \n",
       "4                                    0                                      0   \n",
       "...                                ...                                    ...   \n",
       "19175                                0                                      0   \n",
       "19176                                0                                      0   \n",
       "19177                                0                                      0   \n",
       "19178                                0                                      0   \n",
       "19179                                0                                      0   \n",
       "\n",
       "       j_communication  OutcomeScore  wordCount  \n",
       "0                    0             4          5  \n",
       "1                    0             4         11  \n",
       "2                    0             4          9  \n",
       "3                    0             4         51  \n",
       "4                    0             4         39  \n",
       "...                ...           ...        ...  \n",
       "19175                0             5          1  \n",
       "19176                0             8          2  \n",
       "19177                0             4          9  \n",
       "19178                0             4          1  \n",
       "19179                0             4         11  \n",
       "\n",
       "[19180 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>userIDs</th>\n      <th>implementation</th>\n      <th>Line_ID</th>\n      <th>ChatGroup</th>\n      <th>content</th>\n      <th>group_id</th>\n      <th>RoleName</th>\n      <th>roomName</th>\n      <th>m_experimental_testing</th>\n      <th>m_making_design_choices</th>\n      <th>m_asking_questions</th>\n      <th>j_customer_consultants_requests</th>\n      <th>j_performance_parameters_requirements</th>\n      <th>j_communication</th>\n      <th>OutcomeScore</th>\n      <th>wordCount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>a</td>\n      <td>1</td>\n      <td>PRNLT</td>\n      <td>Hello team. Welcome to Nephrotex!</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>a</td>\n      <td>2</td>\n      <td>PRNLT</td>\n      <td>I'm Maria Williams. I'll be your design adviso...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>a</td>\n      <td>3</td>\n      <td>PRNLT</td>\n      <td>I'm here to help if you have any questions.</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>a</td>\n      <td>4</td>\n      <td>PRNLT</td>\n      <td>Please introduce yourselves with the name you ...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>a</td>\n      <td>5</td>\n      <td>PRNLT</td>\n      <td>I just want to make sure everyone has found th...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19175</th>\n      <td>19176</td>\n      <td>392</td>\n      <td>o</td>\n      <td>19179</td>\n      <td>PESPVP</td>\n      <td>yes</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19176</th>\n      <td>19177</td>\n      <td>388</td>\n      <td>o</td>\n      <td>19180</td>\n      <td>PESPVP</td>\n      <td>sounds good</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19177</th>\n      <td>19178</td>\n      <td>367</td>\n      <td>o</td>\n      <td>19181</td>\n      <td>PESPVP</td>\n      <td>Well, we are out of time for our meeting.</td>\n      <td>6</td>\n      <td>Mentor</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>19178</th>\n      <td>19179</td>\n      <td>393</td>\n      <td>o</td>\n      <td>19182</td>\n      <td>PESPVP</td>\n      <td>Precisely</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19179</th>\n      <td>19180</td>\n      <td>367</td>\n      <td>o</td>\n      <td>19183</td>\n      <td>PESPVP</td>\n      <td>Good discussion today! Don't forget to complet...</td>\n      <td>6</td>\n      <td>Mentor</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>19180 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('virtualInternshipData_ADS2001.csv', encoding= 'unicode_escape') #read the csv provided\n",
    "df = df.drop(\"Unnamed: 0\",axis=1) #drop the unnamed column\n",
    "df"
   ]
  },
  {
   "source": [
    "## Stop Words\n",
    "When working with text or natural language, there are certain words that don't add any value to a sentence e.g. \"this\" and so we will need to remove these words. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With stop words: i'm maria williams. i'll design advisor internship.\nWithout stop words: i'm maria williams. i'll be your design advisor for your internship.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "df['content'] = df['content'].str.lower() #make all the letters lowercase for easy of use\n",
    "\n",
    "stop = stopwords.words('english') #import english stopwords from nltk \n",
    "df['content_without_stopwords'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #remove all stopwords in content column\n",
    "print('With stop words: ' + df['content_without_stopwords'][1])\n",
    "print('Without stop words: ' + df['content'][1])"
   ]
  },
  {
   "source": [
    "## Tokenizing\n",
    "\n",
    "In natural language processing, each document or sentence can thought of as a bag of words in the form of a list where each element is a word..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['content_tokenized'] = df.apply(lambda row: word_tokenize(row['content_without_stopwords']), axis=1) #tokenize all the content"
   ]
  },
  {
   "source": [
    "Splitting the document up like this is called <u>tokenizing</u>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello', 'team', '.', 'welcome', 'nephrotex', '!']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df['content_tokenized'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sors', 'handy', 'maybe', 'mention', 'excpet', 'url', 'overcome', 'somewhere', 'gladly', 'cost/performance/etc', 'ahve', 'cause', 'reasonably', 'surprises', 'testing', 'to', 'beta-t', 'papers', 'or', '......', 'coming', 'impacted', 'nice', 'standard', 'guard', 'characteristics', 'been', 'finn', 'ramping', 'concise', 'andy', 'okie', 'sipes', 'cheaper', 'longer', 'takes', 'adjusted', '1:30pm-2:10pm', '12:30am', 'particular', 'checklist', 'needs', 'not', 'pamda', 'process', '65.56', 'tim', 'refers', 'join', 'inital', '75ng/ml', '10-17', 'listening', 'mins', 'dialyzers', 'validate', 'thirdnow', 'dropped', 'viewing', 'divison', 'witnesses', 'retrieve', \"'t\", 'motion', 'jared', 'faster', 'bud', '5.pmma', 'topics', 'recommended', 'simulations', 'boundaries', 'gave', 'profitability', 'especially', 'issues', 'pricing', 'posssible', 'homework', 'respect', 'intended', 'don', 'unnecessarily', 'funny', 'gang', '@', 'former', 'state', 'tehrani', 'lab', 'hearing', 'refreshed', 'mates', 'agreeing', 'conduct', 'questionnaire', 'disagree', 'nanotues', 'amazing', '2.6.', 'midpoint', 'atm', 'alpha', 'attitude', 'marketability/public', 'around', 'positive', 'dated', 'hospital', 'importantly', '^ditto', 'praised', 'ultra', 'says', 'ksu', 'ricardo', 'clearly', 'dy-jet', 'anyhow', 'recieved', '50.2', 'clint', 'half', 'remainder', '10,15,20', 'miscommunicated', 'bayleyyeah', 'down', '17.', 'ellie', 'chunk', 'proficient', 'understood', 'wanting', 'victory', 'nano-tubing', 'hidrance', 'side', 'averaging', 'rise', '29.42', 'widely', 'downloaded', 'almost', \"'no\", 'middle/average', 'nanotubule', 'lines', 'addition', 'trust', 'achieved', '13', 'showed', 'ideas/', 'competitiors', 'immediately', 'drastic', 'ethersulfone', 'angelica', 'steric', 'mkay', 'recieve', 'aims', 'recommendation', 'x', 'whiteboard', 'lot', 'incomplete', 'whereas', 'less', '--', 'mistake', 'found', 'critically', 'likely', 'consists', 'professor', 'big', 'coordinator', 'producing', 'purposes', '+', 'prntl', 'psf/', 'remaining', 'proofread', 'knock', '10:21', 'variants', 'speaks', 'forsure', 'power', 'decently', 'reactant', '5', 'expect', 'qulaity', 'contained', 'piont', 'confirm', 'inferior', 'accessed', 'selecting', 'might', 'shard', 'make', 'outweighs', 'require', 'study', 'titleist', 'manufacturing', 'login', 'letter', '800,000', '-4', 'katie', 'optimism', 'please', 'def', 'general', 'diffences', 'wished', '|4s|if', 'processes/surfactants', 'recommendations', 'travics', 'maciej', 'getting', 'polyethylene', 'webpage', 'considered', 'thing', 'iwas', 'ie', 'justifications', 'additional', 'experimented', 'pattern', 'peak', 'one', 'when', 'quick', 'wel', 'sec', 'matieral', 'attaches', 'optimizes', '10-20', 'even', 'prioritizes', 'efficient', 'facors', 'obsolete', 'continue', '^had', 'adding', 'time', 'listed', 'hold', 'kelly', 'fired', 'yesh', 'information', 'problems', 'faults', 'brc', 'dryjet', 'involved', 'amounts', 'transcript', 'company', 'ratios', 'stick', 'investigate', 'wieght', 'info', 'pushing', 'backs', 'load', 'choosen', 'something', 'patient', 'attaching', 'gabrielle', 'sessions', 'refine', 'healthcare', 'ben', 'virtually', 'hydrohilic', '41', 'hence', 'session', 'hidering', 'situations', 'response', 'additionally', 'contains', 'darren', 'thesteric', 'broader', 'usefulness', 'parties', 'explain', 'challenges', 's.h', 'retrieved', 'reacitivity', 'bailey', 'meetings', 'hydrophobic', 'realibility', 'booted', 'preferred', 'fill', 'wed', 'l.', 'you', 'seperately', '|3s|the', 'analyzing/researching', 'theres', 'tie', 'goal', 'r.', '1,5,4', 'sample', 'ohhhh', 'aspect', 'hyrdo', 'reopening', 'interface', 'noah', 'altering', 'aww', 'enough', 'won', 'wider', 'benefited', 'lasted', 'formal', 'anything', 'primarily', 'bio', 'blocked', 'advisor', '1:35', 'preparing', 'exposure', 'cluttered', 'facebooking', 'makes', 'reaching', 'hale', 'cyrus', 'marshall', 'fake', 'opened', 'catalyst', 'ideals', 'negitve', 'tradeoffs', 'yayz', 'cite', 'prototype', '1600', 'reid', 'comradeship', 'fluxes', 'unititled', 'workflow', '-__-', 'meters', '12:30pm', 'business-', 'conglomerate', 'feels', 'toxins', 'teams', 'unable', 'income', 'enhanced', 'stands', 'limited', 'brooke', 'instead', 'ting', 'ding', 'assignments', 'remake', 'pretty', 'yao', 'scale', 'happen', 'zachary', 'tyler', 'yu', 'situation', 'short', '140', 'brad', 'rylee', 'affective', 'suited', 'clean', 'helllo', 'efore', 'hohn', 'opther', 'conducted', 'gina', 'leaving', '294/3hrs=', 'series', 'fared', 'out', 'misunderstood', 'shuffled', 'matter', '3/5', 'successful', 'two', 'sprices', 'selling', 'dean', 'broad', 'poorly-written', 'write', 'recently', '^', 'beta-thrombogloublin', 'wording', 'inc', 'nothing', 'devies', 'thanks1', 'patience', 'later', 'affest', 'cap', 'that', 'hydrophilic,6', 'tool', 'acquire', 'apa', '//nephrotex.com', 'isnstead', 'benefit', '14', 'mg3/mg2', 'cells', 'si', 'sells', 'caused', 'coast', '.5', 'explaining', '17so', 'yours', 'discussing', 'ignore', '12', 'guys', 'evey', 'definitively', 'puns', 'gong', 'trouble', 'insignificant', 'yields', 'someones', 'dealings', 'costliest', 'nd', 'sequel', 'has', 'fulfilling', 'requested', 'themes', 'hw', 'describes', 'willl', 'tiem', 'suggested', '100.', 'combine', 'dr', 'marketability', 'dramatically', '2-2.', 'browser', 'parts', 'fior', 'expectation', 'bruh', 'proportionally', 'course', 'nobody', 'steps', 'responding', 'frustrated', 'party2', 'accordingly', 'regards', 'initially', 'exposire', 'prime', 'learned', 'mvp', '4.0.', 'ionfection', 'impacts', 'improving', 'hoping', 'nano-tubes', 'sooooo', 'over', 'huge', 'example', 'smaller', 'hydrophilc', 'caught', '353/3hrs=117.66', 'no', 'thta', 'asap', 'talks', 'vice-versa', 'continuing', 'detailed', 'met', 'push', 'whose', 'foreign', 'glossary', '12:47', 'pursue', 'looking', 'walked', 'built', 'noticed', 'got', 'well-being', 'subject', 'soon', 'delayed', 'excelled', 'prioitize', 'main', 'electronics', 'substantially', 'markeability', \"doesnt't\", 'displayed', 'squared', 'appeals', '2:40', 'doctor', 'compare', 'understands', 'achieve', 'klink', 'fits', 'typo', 'moderately', 'putting', 'adequately', 'agreement', 'tells', 'h2', 'finicky', 'boom', 'outline', 'competitors', 'access', 'asks', 'compiled', 'vapor/high', 'sae=me', 'tru', 'contributor', 'fernando', '2b', 'keep', 'dante', 'numbered', 'kimberly', 'csan', 'extent', 'citing', 'chart', 'share', 'ontrol', 'kenny', 'albeit', 'guided', 'safe', '1.0-1.5', 'lowers', 'themselves', 'plot', 'where', 'surfactat', 'library', 'incorporates', 'chemistry', 'reactor', 'wind', 're-summit', 'inver', 'lead', 'discrepancy', 'doubt', 'reflect', 'swell', 'averaged', 'signs', '50.8,50.8,32.3', 'sending', 'favorable', 'shane', 'desposition', 'four', 'wayne', 'isolated', 'raises', 'outcomes', '10:20.', 're-do', 'helping', 'm.', 'outweighed', 'truuu', 'shes', 'descriptions', 'timothy', 'truly', 'attirbutes', 'sensors', '4.00', 'goes', 'chrome', 'affects', 'allows', 'consistently', 'nature', 'posibiltiy', 'inferences', '2', 'master', 'doesn', 'consumers', 'wants', 'differences', 'excellent', 'own', '3-', '43.33', 'disposition', 'disadcantages', 'static', 'sew', 'developed', 'spoon-fed', 'discrepancies', 'serviceable', 'backfired', 'few', 'i\\x89û÷ll', 'clutch', 'boy', 'safety', 'want', '1:40', 'fit', 'thinking', 'fucking', 'hand', 'extra', 'shortfall', 'expenisive', 'ti', 'p2', 'playin', 'years', 'of', 'hendering', 'greyed', 'clicking', 'brittany', 'fail', 'cosultants', 'differnet', 'productie', 'contrast', 'argument', 'approach', '1:25.', 'last', 'enabled', 'ago', 'complete', 'googled', 'hemodialytic', 'hour', 'concentrations', 'finnished', 'itss', 'awkward', 'batch', 'procedure', 'turns', 'internal', 'surfactant', 'determine', 'melina', 'cleared', 'dry-jets', 'road', 'stating', 'related', 'mandatory', 'neither', 'popular', 'safer', 'heated', 'prototype__', 'overboard', 'nephotex', 'foremost', '90.', 'infection', 'angel', 'complicated', 'brooks', 'deficits', 'pair', 'percent', 'processing', 'qualities', 'sucks', 'imortant', 'nicknames', 'profits', 'excel', 'carly', 'marketability/', 'citation', 'yest', 'evil', 'thoughi', 'expressed', 'lucie', 'lenovo', 'minimize', 'probly', 'exoskeletons', 'count', 'shoulda', 'names', 'g', 'acceptted', 'terms', 'streic', 'duplicates', 'definately', 'basic', 'inefficient', 'ì¢', 's1', 'generator', 'thingy', 'equals', 'weeks', 'filtered', 'emailed', 'pros/cons', 'gagged', 'neg', 'versus', 'analyze', 'untra-flux', 'surfactacant', 'assessment', 'tattooed', 'insane', 'cancelled', 'reult', 'treated', 'invited', 'peforming', 'investment', 'hairs', 'maria', 'in-text', 'd', 'advocate', 'sue', '2.-prnlt', 'really', 'precisely', 'capabilities', 'attachments', '10.if', 'disconnected', '1st-', '30', 'appeal', 'surprising', 'reducer', 'whoops', 'debating', 'marc', 'classify', 'indirect', 'no-go', \"'\", 'mark', 'costing', 'uhh', 'process/cna', '120/unit', 'fined', 'component', 'proposition', 'spillover', 'infer', 'welle', 'jacob', 'occurred', 'cool', '3-4', 'poster', 'extend', 'test1', 'adjustments', 'late', 'highschool', 'listing', 'typically', '5th', 'template', 'frankly', 'price', 'mistaken', 'charge', 'ones', 'relates', 'have', 'deadlines', 'sacrifice', 'ii', 'filtering', 'relationship', 'list', 'failure', 'subjects', 'cya', 'jesus', 'evacuated', 'basically', 'aubrey', 'disregard', 'makertability/cost', 'ewith', 'versatile', 'assistance', 'has/', 'kept', 'word', 'spend', 'thomasdavis312', 'designs', '110', 'hrs', 'generated', 'delivered', 'slowly', 'features', 'loses', 'throw', 'middle', 'just', 'ruled', 'frustration', 'property', 'array', 'hemodialysis', 'explored', 'http', 'radical', 'sufactants', 'consist', 'possibilities', 'fairly', 'offered', 'memo', 'on/what', 'modifications', 'proto4', 'limit', 'giving', 'numbers', '8am', '19', 'marketablitlity', 'language', 'hole', 'cnts', 'flow', 'darrrrren', 'number', 'erase', 'b', 'expenmsive', 'invested', '.......', '20.', 'compiling', 'inferring', 'well4', 'needing', 'winemiller', 'satisfaction', 'misguided', 'hydropholic', 'depoisiton', 'combining', 'filling', 'hey', 'p.m.', 'anywehre', 'logged', 'mroe', 'beta', 'relativity', 'valible', 'wise', 'e.g', 'compares', 'leaves', 'fast', '4-2', ')', 'prioritizng', 'william', 'normally', 'surfactatant', 'caps', 'emotionally', 'sweater', 'okied', 'cost.if', 'going', 'enlightened', 'lady', 'was', 'ended', 'dispersion', 'technically', 'corey', 'notifications', 'answering', 'pro.2', 'explicitly', 'turned', '1:46', '2nd-', 'furthermore', 'discuss', 'productive', 'vary', 'despite', 'rays', 'barely', 'gotten', 'provided', 'concur', 'change', 'pseudo', 'revisions', 'emphasizing', 'scored', 're-tweet', 'opionions', 'relationships', 'padma', 'evryone', 'arent', 'specs', 'decline', 'persuaded', 'somewhat', 'adheres', 'hdryo', 'taylor', 'gotcha', 'wi-fi', 'working', 'use', '75', 'resumbit', 'negated', 'ly', 'chats', 'clogging', 'realiabilty', 'wiliams', 'simulation', 'markets', 'unseen', 'sorry', '-', 'struggles', 'cost', 'suppose', 'sup', 'purchasing', 'starts', 'correlate', 'trial', 'ratio', 'vdp', 'decrease', 'noticeable', 'gerneate', 'cut', 'obviously', '1:31', 'convenient', 'specialized', 'degree', 'notes', 'tinker', 'wasvery', 'sean', 'eave', 'outlines', 'parties-', ',1.5', 'improved/reoptomized', 'videos', 'approximately', 'okedoke', 'ranking', 'unacceptable', 'messng', 'strikes', 'procedures', '8.25', 'goog', 'high', 'rita', 'endeavors', 'flourish', 'unknowns', 'obvious', 'counted', '1:25', 'thought', 'told', '3.1', 'rate', 'ish', 'pototypes', 'itd', 'saving', 'anthing', 'nanotubing', 'enlarge', 'feedback', 'beyond', 'messed', 'proceses', 'night', 'satidfaction', 'brings', 'good/average/bad', '10.0', '\\x89ûïlow', 'anderson', 'economical', 'resisting', 'investigated', 'betchya', 'laying', 'rejoining', 'tianwei', 'prices', 'revising', 'team', 'bleeding', 'victoria', 'surveyed', 'priya', 'sequels', 'credited', '9', 'adam', '10.', 'panel', 'thx', 'resultes', 'noteiced', 'he\\x89ûªd', 'acceptable', 'reduces', 'containing', 'carbonnanotubes', 'ryan', 'charige', '330-530', 'justification', 'ablity', 'positives', 'exercise', 'jennine', 'apparent', 'bilogical', 'identify', 'accommodate', 'trivial', 'tradeoff', 'non-steric', 'asked', 'neatly', 'benifits', 'any', 'note', '^major', 'marketablity', 'close', 'webpages', 'suggest', 'whomever', 'network', 'tht', 'archive', 'toss', 'spite', 'median', 'public', 'sides', 'prioritize', 'tweaks', '1', 'experimentation', 'well-rounded', 'incorporation', 'return', 'hardly', 'beause', 'rao', 'vague', 'hah', 'highlights', 'allen', 'easily', 'optimized', 'objection', 'refering', 'surfactantss', 'correctly', 'c.j', 'consults', 'margin', '5:23.', 'solid', 'match', 'ml', 'untitled', 'seeya', 'bests', 'dropping', 'everybody', 'let', 'minimal', 'way', 'firm', 'random', 'scientist', 'prbably', 'desired', 'pasting', 'speculation', 'direction', 'with', 'carbon', 'knocking', 'profile', 'cited', 'save', 'definelty', '1:02', 'goals', 'inclusive', 'such', 'date', 'article', 'examined', 'altered', 'lowering', 'on', 'draft', 'although', 'extremely', 'twice', 'exist', 'characterisitic', 'sentence', 'pursuing', 'stephen', 'west', '82', 'erased', 'sooo', 'groups', 'standpoint', 'throwing', 'composites', 'everyones', 'hmm', 'bioreactivity', 'bother', 'nephrotex', 'laptop', 'drops', 'attractiveness', 'pro.1,2,3', 'ughhh', 'restarting', 'ashlyn', 'congrats', 'showing', 'cares', 'task', 'better', 'hingdering', 'p.s', 'future', 'personaly', 'suffered', 'felt', '/5', 'story', '11.0', 'absent', 'wonder', 'sounds', 'realistic', 'deciding', '115', '4:50', 'candidates', 'regarding', 'charged', 'reporting', 'pm', 'tru^^', 'lacking', 'vastly', 'fair', 'clearification', 'section', 'comforting', 'doctors', '^^', 'nah', 'awful', 'insider', 'level', 'uncertain', 'group/', 'campus', 'balance', 'is.now', 'blood-cell', 'summer', 'processes/percentages', 'surfacnant', 'nick', '1-1.5', 'follow', 'erik', 'slackin', '#', 'downright', 'sh', 'kaitlyn', 'asd', 'consultant', 'trumped', 'layout', '5:20', 'scores', 'molly', 'ask', 'steric-hindering', 'experiments', 'absence', 'prove', 'net', 'notebook', '15th', 'position', 'very', 'reactivty', 'identifiable', 'facilitate', 'distributed', 'tomorrow', 'guerrero', '5pm', 't.', 'surfacctants', 'moment', 'smack', 'predecessor', 'argue', 'marketing', 'mind', 'realiablity', 'sufacat', 'rescue', 'cubicles', 'cold', 're-installed', '101', 'pack', 'monday', 'typical', 'bayley', 'macbook', 'means', 'tended', 'prefferred', 'clarifying', 'aming', 'connor', 'efficiency', 'differnt', 'key', 'gantt', 'following', 'flux/vapor', 'typing', 'implied', 'resource', 'lawsuits', 'patrick', 'disadvantages', 'bayleigh', 'people', 'reliablitly', 'box', 'clikced', 'stops', 'dedotated', 'grasping', 'andone', 'wanted', 'completion', 'class', 'concentration', 'hinderince', 'sterically', 'whatsup', 'nathaniel', 'recommandations', 'amazingly', 'copying', 'intro', 'impressive', '%', 'sheet', 'consequently', 'crucial', 'composed', '9:20', 'look', '1-4', 'ncessarily', 'prof', '41.4', 'upon', 'fav', 'reliabilities', 'recap', 'polysulfone', 'released', 'newest', 'remained', '4th', 'placed', 'confusingsorry', 'mest', 'known', 'keywords', 'steven', 'heavy', 'plz', 'inverstion', 'confusion', 'play', 'proto1', 'attachement', 'straightened', 'utilize', 'stgeric', 'reactivity', 'resources', '18th', 'harder', 'firefox', 'apsects', 'resulted', 'ups', 'instance', 'actuallly', 'nanotubs', 'used.poly', 'disageree', 'white', 'based', 'troubles', 'shoot', 'usual', 'treat', 'essential', 'lazy', 'tryin', 'ali', 'outlined', 'concerned', 'btg', 'documents', 'wild', 'thousands', '63.2', 'establish', 'bummer', 'observe', 'inside', 'extrememly', 'backwards', 'reliabbility', 'aaron', '4rth', 'boss', 'there', 'researches', 'remind', 'depend', 'oppinion', 'mackenzie', 'money', 'valuing', 'haley', 'blueprints', 'username', 'jerrid', 'only', 'logs', 'moving', 'recourse', 'properties', 'talked', 'hyrdophilic', 'content', 'liking', 'small', '2-alan', '2.00', 'age/medical', 'chances', 'went', 'profit', 'turning', 'technique', 'apply', 'structure', 'suffering', 'because', 'oil', '1a', 'proponent', 'improved', 'band', 'comments', 'held', 'articles', 'reactivivity', 'produce', 'curriculum', 'equipment', 'paraphrase', 'thee', 'label', 'addiditive', 'tho', 'charlie', 'botching', 'eventually', 'strong', 'fields', 'immune', 'flip', 'inform', 'practice', 'meal', 'havent', 'description', 'greetings', 'liquid', 'relatives', 'knew', 'curiosity', 'titled', 'icon', 'refreshing', 'staff', 'peace', 'logging', 'relilabilitiy', 'poorly', 'appeared', 'coating', 'developing', 'foul', 'operation', 'invest', \"'re\", '2nd', 'mini', 'complement', 'comprehend', 'solutions', 'atleast', 'nickname', 'hone', '10:45', 'correct', 'base', 'attatch', 'worst', 'remotely', 'stressed', 'surpasses', 'conditions', 'spectacular', 'pairs', 'volunteering', 'cali', 'b6', 'm3/m2-day', 'posted', 'labeled', 'favoritism', 'attractive', 'uses', 'worlds', 'attends', 'seeing', 'hydrophilic/', 'copied', 'prefers', 'unnecessary', 'leading', 'write-up', 'manner', 'today.', 'pertaining', 'ta', 'outputs', 'reference', '500,00.', 'regularly', 'varies', 'trend', 'repeats', 'enable', 'beta-', 'quest', 'feeling', 'desktop', '10/13/15', 'poll', 'usable', 'chaos', 'unrealistic', 'upset', 'shall', 'coolio', 'o.k', 'fixing', 'nose', 'perfect', 'quickly', 'struggeling', 'target', 'polymeric', 'cut-off', '-surfactant', 'therefore', 'overall.', 'impressed', 'thresh', 'occured', 'for', 'low-price', '1pm', 'eaach', 'front', 'resubmit', 'traits', 'started', 'bot', 'phenomenal', 'similarly', 'finals', 'spread', 'undecided', 'loss', 'shame', 'interestingly', 'boards', '20-22', 'significance', 'lied', 'route', 'result', 'sufficient', 'attatched', 'materail', 'perferred', 'upside', 'finalized', 'confirmed', 'grphing', 'guide', 'multiplied', 'currently', 'venting', 'fault', 'caters', 'damnit', 'monitoring', 'office', 'unorthodox', 'agent', 'bent', 'attention', 'integrate', 'idk-i', 'longest', 'stop', 'tailored', 'th', 'vale', 'consistancy', 'is', 'presented', 'driving', 'isn', 'collecting', 'dareen', 'mondays/', 'sized', 'john-michelle', 'u', 'assuming', 'manipulate', 'lowest', 'unsure', 'sick', 'josh', 'necessary', 'ngineer', 'hospitals', 'fees', 'spent', 'joseph', 'referred', 'reason', 'baised', 'uniformly', 'consequences', 're-submitted', 'customers', 'failing', '5.1', 'journal', 'valid', 'graded', 'aiming', 'why', 'joes', 'up', 'lives', 'theirs', 'hwang', 'severe', 'discard', 'oh', 'annemarie', 'factoring', 'replies', 'sections', 'yesterdays', 'rectangle', 'click', 'past', 'presence', '^^^yeah', 'right^', 'stuff', 'personal', 'certain', 'disruptive', 'notified', 'hell', 'pes-pvp', 'hailey', 'can', 'application', 'favorite', 'nuclear', 'lesser', 'alec', 'visual/physical/', 'rest', 'lots', 'without', 'versed', 'functioning', 'estimate', 'affected', 'im', 'isabella', 'thin', 'respectively', '3:30-4:30.', 'shuffle', 'touch', 'definitely', 'cnt=1.5', 'pespvp', 'take', 'afraid', 'pops', 'classroom', 'document', 'catagories', 'opinion', '0.6', 'college', 'non', 'generate', 'enjoy', 'impossible', '4x', 'developments', '500', 'average', 'alot', 'ayoooo', 'bloodcell', 'katherine', 'generation', 'mouth', 'sticky', 'mysteriously', 'ok', 'karl', 'bigger', 'each', 'incorporate', 'participating', 'reliabiltiy', 'thou', 'shorter', 'whatnot', 'in', 'jarret', 'notebooks', 'choose', 'miss', 'joining', '235', 'kayleigh', 'unique', '3.reactivity', 'mass', 'mine', 'satisfactory', 'downloading', 'bullets', 'ala', 'strict', '2-for', 't', 'alrights', 'offs', 'gold', 'aright', 'gregory', 'memebrane', 'strive', 'unkowns', '1.5-2', 'comprises', 'robert', 'p.', 'sticks', 'next', 'conlcusion', 'and/or', 'heart', 'aim', 'fridays', 'appreciate', 'joe', 'leads', 'brandon', 'cancel', 'p6', 'updated', 'holds', 'interactions', 'communicate', '10:20am', 'effect', 'lacked', 'yeyah', 'preformed', 'capitalism', 'machines', 'reading', 'marketabiltiy', 'accepts', 'reliablitity', 'exceptional', 'ian', 'problemo', 'brendan', 'edited'}\n"
     ]
    }
   ],
   "source": [
    "#all words found in the content\n",
    "word_set = set().union(*df['content_tokenized'])\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting each sublist into all content said by each user\n",
    "user_dict = [] #creating an empty list to store all the sublist of all the words said by each user\n",
    "for idx in df['userIDs'].unique(): #loop over every unique id\n",
    "    lst = [word_tokenize(i) for i in df[df['userIDs'] == idx]['content_without_stopwords'].to_list()] #tokenize the contents of each row\n",
    "    tokenized_sents = [item for sublist in lst for item in sublist] #re-formatting \n",
    "    user_dict.append(tokenized_sents) #append the sublist into the user_dict list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ion', 'clicking', '``', 'x', \"''\", 'deliverables', 'list', '.', 'cancel', 'submissions', 'alex', 'viewed', 'them', ',', 'make', 'sure', 'included', 'everything', 'required', 'submitting', '.', 'soon', 'submit', 'notebook', 'alex', 'review', 'send', 'feedback', 'soon', 'can', '.', 'waiting', ',', 'assist', 'teammates', 'submitted', 'deliverable', '.', 'team', 'able', 'move', 'next', 'task', 'team', 'members', \"'\", 'notebooks', 'witnessed', '.', 'back', 'undergrad', ',', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', '.', 'working', 'different', 'project', ',', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', '.', 'alex', 'pretty', 'similar', 'boss', 'internship', ',', 'welcome', 'use', 'template', 'write', 'own', '.', 'note', 'language', 'length', 'response', '.', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', '.', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', '.', 'alex', 'receives', 'notebook', 'receive', 'email', 'feedback', 'shortly', 'thereafter', '.', 'recommend', 'completing', 'notebook', 'revisions', 'helping', 'teammates', 'finish', 'deliverables', 'wait', 'feedback', '.', 'soon', 'team', \"'s\", 'deliverables', 'submitted', 'witnessed', ',', 'get', 'started', 'next', 'task', '.', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', '.', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', ',', 'looking', 'surfactants', '.', 'nevertheless', ',', 'welcome', 'use', 'example', 'model', 'response', 'after', '.', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', ',', 'help', 'teammates', 'submitted', 'deliverable', 'yet', '.', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', '.', 'still', 'time', 'team', 'meeting', ',', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', '.', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', '.', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', '.', 'based', 'surfactant', 'graph', ',', 'surfactants', 'perform', 'relative', 'one', 'another', '?', 'one', 'surfactant', 'obviously', 'best', 'choice', '?', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', '?', 'choose', 'best', 'surfactant', '?', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', '?', 'value', 'attributes', 'others', 'choosing', 'best', 'surfactant', '?', 'team', \"'s\", 'next', 'step', 'be', '?', 'hey', 'everyone', ',', 'posted', 'write-up', 'mechanical', 'engineering', 'consultants', \"'\", 'requirements', 'time', 'intern', '.', 'find', 'write-up', 'shared', 'space', '.', 'nephrotex', ',', 'internal', 'consultants', 'experts', 'fields', '.', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', '.', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', '.', 'intern', ',', 'describe', 'certain', 'inputs', 'influence', 'outputs', '.', 'i', \"'ve\", 'posted', 'write-up', 'shared', 'space', 'reference', '.', 'goal', 'understand', 'how', ',', 'given', 'particular', 'material', ',', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', '.', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'team', \"'s\", 'material', '.', 'back', 'internship', ',', 'justify', 'design', 'decisions', 'made', ',', 'found', 'useful', 'practice', '.', 'working', 'alex', ',', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', ',', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', '.', 'clear', ',', 'team', 'member', 'design', '5', 'prototypes', 'using', 'prnlt', 'materials', '.', 'keep', 'mind', 'supervisor', 'nephrotex', 'employees', 'read', 'record', 'discussion', '.', 'please', 'stay', 'task', ',', 'royce', '.', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', '.', 'help', 'teammates', 'complete', 'deliverables', ',', 'revise', 'incomplete', 'notebooks', ',', 'work', 'presentation', '.', 'presentation', 'include', 'everything', 'presentation', 'outline', ',', 'located', 'resources', 'section', 'workpro', '.', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', '.', 'forget', 'attach', 'team', \"'s\", 'new', 'batch', 'notebook', '.', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', '.', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', '.', 'first', 'team', 'member', 'attaches', 'submits', 'team', \"'s\", 'batch', ',', 'rest', 'team', 'members', 'option', 'attach', 'batch', '.', 'received', 'lab', 'results', 'internship', ',', 'analyze', 'write', 'findings', '.', 'remember', 'difficult', 'first', 'couple', 'times', ',', 'posted', 'one', 'old', 'lab', 'write-ups', 'shared', 'space', 'reference', '.', 'remember', ',', 'analysis', 'include', 'important', 'information', ',', 'concise', 'well-organized', '.', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', '.', 'okay', 'everyone', ',', 'let', \"'s\", 'get', 'going', '.', 'want', 'hear', 'meeting', '.', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', '.', 'team', 'received', 'batch', 'results', ',', 'successful', 'trial', '?', 'discover', 'design', 'problem', '?', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', '?', 'hello', 'team', '.', 'welcome', 'nephrotex', '!', 'i', \"'m\", 'maria', 'williams', '.', 'i', \"'ll\", 'design', 'advisor', 'internship', '.', 'i', \"'m\", 'help', 'questions', '.', 'please', 'introduce', 'name', 'prefer', 'called', '.', 'workpro', 'records', 'work', 'do', ',', 'review', 'external', 'consultant', 'improve', 'quality', 'internship', 'program', '.', 'ask', 'use', 'first', 'name', 'internship', 'protect', 'privacy', '.', 'want', 'make', 'sure', 'everyone', 'found', 'chat', 'interface', '.', 'please', 'send', 'chat', '``', 'check', 'in', \"''\", 'group', '.', 'make', 'chat', 'window', 'bigger', 'clicking', '+', 'icon', 'top', 'right', 'corner', '.', 'already', ',', 'please', 'check', 'email', '.', 'throughout', 'time', 'nephrotex', ',', 'receiving', 'emails', 'boss', ',', 'alex', '.', 'he', \"'ll\", 'send', 'instructions', 'work', 'throughout', 'course', 'internship', '.', 'now', ',', 'please', 'check', 'deliverable', 'list', 'bottom', 'right', 'corner', 'workpro', '.', 'deliverables', 'assigned', 'show', 'list', '.', 'able', 'check', 'see', 'original', 'email', 'instructions', 'alex', 'sent', 'you', ',', 'whether', 'submitted', 'deliverable', ',', 'whether', 'vedant', 'approved', 'deliverable', '.', 'detailed', 'information', 'deliverable', 'list', ',', 'click', 'info', 'button', 'top', 'right', 'corner', 'deliverables', 'list', 'tab', '.', 'provided', 'summary', 'workflow', 'resource', 'shared', 'space', '.', 'plagiarism', 'tolerated', ',', 'make', 'sure', 'paraphrase', 'summary', 'notebook', 'entry', '.', 'done', 'notebook', 'entry', ',', 'submit', 'alex', 'clicking', 'submit', 'button', '(', 'middle', 'notebook', 'window', ')', '.', 'able', 'edit', 'entry', 'submitted', 'it', ',', 'need', 'update', 'correct', 'work', ',', 'cancel', 'submission', 'clicking', '``', 'x', \"''\", 'deliverables', 'list', '.', 'cancel', 'submissions', 'alex', 'viewed', 'them', ',', 'make', 'sure', 'included', 'everything', 'required', 'submitting', '.', 'soon', 'submit', 'notebook', 'alex', 'review', 'send', 'feedback', 'soon', 'can', '.', 'waiting', ',', 'assist', 'teammates', 'submitted', 'deliverable', '.', 'team', 'able', 'move', 'next', 'task', 'team', 'members', \"'\", 'notebooks', 'witnessed', '.', 'back', 'undergrad', ',', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', '.', 'working', 'different', 'project', ',', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', '.', 'alex', 'pretty', 'similar', 'boss', 'internship', ',', 'welcome', 'use', 'template', 'write', 'own', '.', 'note', 'language', 'length', 'response', '.', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', '.', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', '.', 'alex', 'receives', 'notebook', 'receive', 'email', 'feedback', 'shortly', 'thereafter', '.', 'recommend', 'completing', 'notebook', 'revisions', 'helping', 'teammates', 'finish', 'deliverables', 'wait', 'feedback', '.', 'soon', 'team', \"'s\", 'deliverables', 'submitted', 'witnessed', ',', 'get', 'started', 'next', 'task', '.', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', '.', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', ',', 'looking', 'surfactants', '.', 'nevertheless', ',', 'welcome', 'use', 'example', 'model', 'response', 'after', '.', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', ',', 'help', 'teammates', 'submitted', 'deliverable', 'yet', '.', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', '.', 'still', 'time', 'team', 'meeting', ',', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', '.', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', '.', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', '.', 'based', 'surfactant', 'graph', ',', 'surfactants', 'perform', 'relative', 'one', 'another', '?', 'one', 'surfactant', 'obviously', 'best', 'choice', '?', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', '?', 'choose', 'best', 'surfactant', '?', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', '?', 'team', \"'s\", 'next', 'step', 'be', '?', 'need', 'improve', 'design', 'filtration', 'membrane', '?', 'hey', 'everyone', ',', 'posted', 'write-up', 'mechanical', 'engineering', 'consultants', \"'\", 'requirements', 'time', 'intern', '.', 'find', 'write-up', 'shared', 'space', '.', 'nephrotex', ',', 'internal', 'consultants', 'experts', 'fields', '.', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', '.', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', '.', 'intern', ',', 'describe', 'certain', 'inputs', 'influence', 'outputs', '.', 'i', \"'ve\", 'posted', 'write-up', 'shared', 'space', 'reference', '.', 'goal', 'understand', 'how', ',', 'given', 'particular', 'material', ',', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', '.', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'team', \"'s\", 'material', '.', 'back', 'internship', ',', 'justify', 'design', 'decisions', 'made', ',', 'found', 'useful', 'practice', '.', 'working', 'alex', ',', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', ',', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', '.', 'clear', ',', 'team', 'member', 'design', '5', 'prototypes', 'using', 'pmma', 'materials', '.', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', '.', 'help', 'teammates', 'complete', 'deliverables', ',', 'revise', 'incomplete', 'notebooks', ',', 'work', 'presentation', '.', 'presentation', 'include', 'everything', 'presentation', 'outline', ',', 'located', 'resources', 'section', 'workpro', '.', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', '.', 'forget', 'attach', 'team', \"'s\", 'new', 'batch', 'notebook', '.', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', '.', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', '.', 'first', 'team', 'member', 'attaches', 'submits', 'team', \"'s\", 'batch', ',', 'rest', 'team', 'members', 'option', 'attach', 'batch', '.', 'received', 'lab', 'results', 'internship', ',', 'analyze', 'write', 'findings', '.', 'remember', 'difficult', 'first', 'couple', 'times', ',', 'posted', 'one', 'old', 'lab', 'write-ups', 'shared', 'space', 'reference', '.', 'remember', ',', 'analysis', 'include', 'important', 'information', ',', 'concise', 'well-organized', '.', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', '.', 'okay', 'everyone', ',', 'let', \"'s\", 'get', 'going', '.', 'want', 'hear', 'meeting', '.', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', '.', 'team', 'received', 'batch', 'results', ',', 'successful', 'trial', '?', 'discover', 'design', 'problem', '?', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', '?', 'may', 'new', 'design', 'advisor', 'new', 'team', ',', 'i', \"'m\", 'glad', 'opportunity', 'work', 'though', '!', 'thanks', 'great', 'discussions', 'professionalism', '.', 'keep', 'good', 'work', 'new', 'teams', '.', 'hello', 'team', '.', 'welcome', 'nephrotex', '!', 'i', \"'m\", 'maria', 'williams', '.', 'i', \"'ll\", 'design', 'advisor', 'internship', '.', 'i', \"'m\", 'help', 'questions', '.', 'please', 'introduce', 'name', 'prefer', 'called', '.', 'workpro', 'records', 'work', 'do', ',', 'review', 'external', 'consultant', 'improve', 'quality', 'internship', 'program', '.', 'ask', 'use', 'first', 'name', 'internship', 'protect', 'privacy', '.', 'want', 'make', 'sure', 'everyone', 'found', 'chat', 'interface', '.', 'please', 'send', 'chat', '``', 'check', 'in', \"''\", 'group', '.', 'make', 'chat', 'window', 'bigger', 'clicking', '+', 'icon', 'top', 'right', 'corner', '.', 'already', ',', 'please', 'check', 'email', '.', 'throughout', 'time', 'nephrotex', ',', 'receiving', 'emails', 'boss', ',', 'alex', '.', 'he', \"'ll\", 'send', 'instructions', 'work', 'throughout', 'course', 'internship', '.', 'now', ',', 'please', 'check', 'deliverable', 'list', 'bottom', 'right', 'corner', 'workpro', '.', 'deliverables', 'assigned', 'show', 'list', '.', 'able', 'check', 'see', 'original', 'email', 'instructions', 'alex', 'sent', 'you', ',', 'whether', 'submitted', 'deliverable', ',', 'whether', 'vedant', 'approved', 'deliverable', '.', 'detailed', 'information', 'deliverable', 'list', ',', 'click', 'info', 'button', 'top', 'right', 'corner', 'deliverables', 'list', 'tab', '.', 'provided', 'summary', 'workflow', 'resource', 'shared', 'space', '.', 'plagiarism', 'tolerated', ',', 'make', 'sure', 'paraphrase', 'summary', 'notebook', 'entry', '.', 'done', 'notebook', 'entry', ',', 'submit', 'alex', 'clicking', 'submit', 'button', '(', 'middle', 'notebook', 'window', ')', '.', 'able', 'edit', 'entry', 'submitted', 'it', ',', 'need', 'update', 'correct', 'work', ',', 'cancel', 'submission', 'clicking', '``', 'x', \"''\", 'deliverables', 'list', '.', 'cancel', 'submissions', 'alex', 'viewed', 'them', ',', 'make', 'sure', 'included', 'everything', 'required', 'submitting', '.', 'back', 'undergrad', ',', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', '.', 'working', 'different', 'project', ',', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', '.', 'alex', 'pretty', 'similar', 'boss', 'internship', ',', 'welcome', 'use', 'template', 'write', 'own', '.', 'note', 'language', 'length', 'response', '.', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', '.', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', '.', 'still', 'received', 'deliverable', 'task', '.', 'deadline', 'approaching', ',', 'please', 'submit', 'notebook', 'soon', 'can', '.', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', '.', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', ',', 'looking', 'surfactants', '.', 'nevertheless', ',', 'welcome', 'use', 'example', 'model', 'response', 'after', '.', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', ',', 'help', 'teammates', 'submitted', 'deliverable', 'yet', '.', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', '.', 'still', 'time', 'team', 'meeting', ',', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', '.', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', '.', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', '.', 'based', 'surfactant', 'graph', ',', 'surfactants', 'perform', 'relative', 'one', 'another', '?', 'one', 'surfactant', 'obviously', 'best', 'choice', '?', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', '?', 'choose', 'best', 'surfactant', '?', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', '?', 'value', 'attributes', 'others', 'choosing', 'best', 'surfactant', '?', 'team', \"'s\", 'next', 'step', 'be', '?', 'hey', 'everyone', ',', 'posted', 'write-up', 'mechanical', 'engineering', 'consultants', \"'\", 'requirements', 'time', 'intern', '.', 'find', 'write-up', 'shared', 'space', '.', 'nephrotex', ',', 'internal', 'consultants', 'experts', 'fields', '.', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', '.', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', '.', 'intern', ',', 'describe', 'certain', 'inputs', 'influence', 'outputs', '.', 'i', \"'ve\", 'posted', 'write-up', 'shared', 'space', 'reference', '.', 'goal', 'understand', 'how', ',', 'given', 'particular', 'material', ',', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', '.', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'team', \"'s\", 'material', '.', 'back', 'internship', ',', 'justify', 'design', 'decisions', 'made', ',', 'found', 'useful', 'practice', '.', 'working', 'alex', ',', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', ',', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', '.', 'clear', ',', 'team', 'member', 'design', '5', 'prototypes', 'using', 'psf', 'materials', '.', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', '.', 'help', 'teammates', 'complete', 'deliverables', ',', 'revise', 'incomplete', 'notebooks', ',', 'work', 'presentation', '.', 'presentation', 'include', 'everything', 'presentation', 'outline', ',', 'located', 'resources', 'section', 'workpro', '.', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', '.', 'forget', 'attach', 'team', \"'s\", 'new', 'batch', 'notebook', '.', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', '.', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', '.', 'first', 'team', 'member', 'attaches', 'submits', 'team', \"'s\", 'batch', ',', 'rest', 'team', 'members', 'option', 'attach', 'batch', '.', 'received', 'lab', 'results', 'internship', ',', 'analyze', 'write', 'findings', '.', 'remember', 'difficult', 'first', 'couple', 'times', ',', 'posted', 'one', 'old', 'lab', 'write-ups', 'shared', 'space', 'reference', '.', 'remember', ',', 'analysis', 'include', 'important', 'information', ',', 'concise', 'well-organized', '.', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', '.', 'okay', 'everyone', ',', 'let', \"'s\", 'get', 'going', '.', 'want', 'hear', 'meeting', '.', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', '.', 'team', 'received', 'batch', 'results', ',', 'successful', 'trial', '?', 'discover', 'design', 'problem', '?', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', '?', 'access', 'shared', 'space', ',', 'notebook', ',', 'still', 'able', 'email', 'current', 'team', '.', 'may', 'new', 'design', 'advisor', 'new', 'team', ',', 'i', \"'m\", 'glad', 'opportunity', 'work', 'though', '!']\n"
     ]
    }
   ],
   "source": [
    "print(user_dict[0]) #printing all content that user 1 said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list where each sublist is a dictionary that counts the frequency of all the words that are used by a user\n",
    "word_dict = [] #create an empty list to store all the words used\n",
    "for i in range(len(user_dict)):\n",
    "    #creating dictionaries to keep count of the words\n",
    "    temp_word_dict = dict.fromkeys(word_set, 0)\n",
    "    word_dict.append(temp_word_dict) #append each dictionary to the word dictionary \n",
    "    \n",
    "    #count the words in the bag of words for each user\n",
    "    for word in user_dict[i]:\n",
    "        word_dict[i][word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ": 0, 'suited': 0, 'clean': 0, 'helllo': 0, 'efore': 0, 'hohn': 0, 'opther': 0, 'conducted': 0, 'gina': 0, 'leaving': 0, '294/3hrs=': 0, 'series': 0, 'fared': 0, 'out': 0, 'misunderstood': 0, 'shuffled': 0, 'matter': 0, '3/5': 0, 'successful': 3, 'two': 0, 'sprices': 0, 'selling': 0, 'dean': 0, 'broad': 0, 'poorly-written': 0, 'write': 6, 'recently': 0, '^': 0, 'beta-thrombogloublin': 0, 'wording': 0, 'inc': 0, 'nothing': 0, 'devies': 0, 'thanks1': 0, 'patience': 0, 'later': 0, 'affest': 0, 'cap': 0, 'that': 0, 'hydrophilic,6': 0, 'tool': 0, 'acquire': 0, 'apa': 0, '//nephrotex.com': 0, 'isnstead': 0, 'benefit': 0, '14': 0, 'mg3/mg2': 0, 'cells': 0, 'si': 0, 'sells': 0, 'caused': 0, 'coast': 0, '.5': 0, 'explaining': 0, '17so': 0, 'yours': 0, 'discussing': 0, 'ignore': 0, '12': 0, 'guys': 0, 'evey': 0, 'definitively': 0, 'puns': 0, 'gong': 0, 'trouble': 0, 'insignificant': 0, 'yields': 0, 'someones': 0, 'dealings': 0, 'costliest': 0, 'nd': 0, 'sequel': 0, 'has': 0, 'fulfilling': 0, 'requested': 0, 'themes': 0, 'hw': 0, 'describes': 0, 'willl': 0, 'tiem': 0, 'suggested': 0, '100.': 0, 'combine': 0, 'dr': 0, 'marketability': 0, 'dramatically': 0, '2-2.': 0, 'browser': 0, 'parts': 0, 'fior': 0, 'expectation': 0, 'bruh': 0, 'proportionally': 0, 'course': 3, 'nobody': 0, 'steps': 0, 'responding': 0, 'frustrated': 0, 'party2': 0, 'accordingly': 0, 'regards': 0, 'initially': 0, 'exposire': 0, 'prime': 0, 'learned': 0, 'mvp': 0, '4.0.': 0, 'ionfection': 0, 'impacts': 0, 'improving': 0, 'hoping': 0, 'nano-tubes': 0, 'sooooo': 0, 'over': 0, 'huge': 0, 'example': 15, 'smaller': 0, 'hydrophilc': 0, 'caught': 0, '353/3hrs=117.66': 0, 'no': 0, 'thta': 0, 'asap': 0, 'talks': 0, 'vice-versa': 0, 'continuing': 0, 'detailed': 3, 'met': 0, 'push': 0, 'whose': 0, 'foreign': 0, 'glossary': 0, '12:47': 0, 'pursue': 0, 'looking': 3, 'walked': 0, 'built': 0, 'noticed': 0, 'got': 0, 'well-being': 0, 'subject': 0, 'soon': 7, 'delayed': 0, 'excelled': 0, 'prioitize': 0, 'main': 0, 'electronics': 0, 'substantially': 0, 'markeability': 0, \"doesnt't\": 0, 'displayed': 0, 'squared': 0, 'appeals': 0, '2:40': 0, 'doctor': 0, 'compare': 0, 'understands': 0, 'achieve': 0, 'klink': 0, 'fits': 0, 'typo': 0, 'moderately': 0, 'putting': 0, 'adequately': 0, 'agreement': 0, 'tells': 0, 'h2': 0, 'finicky': 0, 'boom': 0, 'outline': 6, 'competitors': 0, 'access': 1, 'asks': 0, 'compiled': 0, 'vapor/high': 0, 'sae=me': 0, 'tru': 0, 'contributor': 0, 'fernando': 0, '2b': 0, 'keep': 2, 'dante': 0, 'numbered': 0, 'kimberly': 0, 'csan': 0, 'extent': 0, 'citing': 0, 'chart': 0, 'share': 0, 'ontrol': 0, 'kenny': 0, 'albeit': 0, 'guided': 0, 'safe': 0, '1.0-1.5': 0, 'lowers': 0, 'themselves': 0, 'plot': 0, 'where': 0, 'surfactat': 0, 'library': 0, 'incorporates': 0, 'chemistry': 0, 'reactor': 0, 'wind': 0, 're-summit': 0, 'inver': 0, 'lead': 0, 'discrepancy': 0, 'doubt': 0, 'reflect': 0, 'swell': 0, 'averaged': 0, 'signs': 0, '50.8,50.8,32.3': 0, 'sending': 0, 'favorable': 0, 'shane': 0, 'desposition': 0, 'four': 0, 'wayne': 0, 'isolated': 0, 'raises': 0, 'outcomes': 0, '10:20.': 0, 're-do': 0, 'helping': 2, 'm.': 0, 'outweighed': 0, 'truuu': 0, 'shes': 0, 'descriptions': 0, 'timothy': 0, 'truly': 0, 'attirbutes': 0, 'sensors': 3, '4.00': 0, 'goes': 0, 'chrome': 0, 'affects': 0, 'allows': 0, 'consistently': 0, 'nature': 0, 'posibiltiy': 0, 'inferences': 0, '2': 0, 'master': 0, 'doesn': 0, 'consumers': 0, 'wants': 3, 'differences': 0, 'excellent': 0, 'own': 3, '3-': 0, '43.33': 0, 'disposition': 0, 'disadcantages': 0, 'static': 0, 'sew': 0, 'developed': 0, 'spoon-fed': 0, 'discrepancies': 0, 'serviceable': 0, 'backfired': 0, 'few': 0, 'i\\x89û÷ll': 0, 'clutch': 0, 'boy': 0, 'safety': 0, 'want': 18, '1:40': 0, 'fit': 0, 'thinking': 0, 'fucking': 0, 'hand': 0, 'extra': 0, 'shortfall': 0, 'expenisive': 0, 'ti': 0, 'p2': 0, 'playin': 0, 'years': 0, 'of': 0, 'hendering': 0, 'greyed': 0, 'clicking': 9, 'brittany': 0, 'fail': 0, 'cosultants': 0, 'differnet': 0, 'productie': 0, 'contrast': 0, 'argument': 0, 'approach': 0, '1:25.': 0, 'last': 0, 'enabled': 0, 'ago': 0, 'complete': 3, 'googled': 0, 'hemodialytic': 0, 'hour': 0, 'concentrations': 0, 'finnished': 0, 'itss': 0, 'awkward': 0, 'batch': 15, 'procedure': 0, 'turns': 0, 'internal': 6, 'surfactant': 20, 'determine': 0, 'melina': 0, 'cleared': 0, 'dry-jets': 0, 'road': 0, 'stating': 0, 'related': 0, 'mandatory': 0, 'neither': 0, 'popular': 0, 'safer': 0, 'heated': 0, 'prototype__': 0, 'overboard': 0, 'nephotex': 0, 'foremost': 0, '90.': 0, 'infection': 0, 'angel': 0, 'complicated': 0, 'brooks': 0, 'deficits': 0, 'pair': 0, 'percent': 0, 'processing': 0, 'qualities': 0, 'sucks': 0, 'imortant': 0, 'nicknames': 0, 'profits': 0, 'excel': 0, 'carly': 0, 'marketability/': 0, 'citation': 6, 'yest': 0, 'evil': 0, 'thoughi': 0, 'expressed': 0, 'lucie': 0, 'lenovo': 0, 'minimize': 0, 'probly': 0, 'exoskeletons': 3, 'count': 0, 'shoulda': 0, 'names': 0, 'g': 0, 'acceptted': 0, 'terms': 0, 'streic': 0, 'duplicates': 0, 'definately': 0, 'basic': 0, 'inefficient': 0, 'ì¢': 0, 's1': 0, 'generator': 0, 'thingy': 0, 'equals': 0, 'weeks': 0, 'filtered': 0, 'emailed': 0, 'pros/cons': 0, 'gagged': 0, 'neg': 0, 'versus': 0, 'analyze': 3, 'untra-flux': 0, 'surfactacant': 0, 'assessment': 0, 'tattooed': 0, 'insane': 0, 'cancelled': 0, 'reult': 0, 'treated': 0, 'invited': 0, 'peforming': 0, 'investment': 0, 'hairs': 0, 'maria': 3, 'in-text': 0, 'd': 0, 'advocate': 0, 'sue': 0, '2.-prnlt': 0, 'really': 0, 'precisely': 0, 'capabilities': 0, 'attachments': 0, '10.if': 0, 'disconnected': 0, '1st-': 0, '30': 0, 'appeal': 0, 'surprising': 0, 'reducer': 0, 'whoops': 0, 'debating': 0, 'marc': 0, 'classify': 0, 'indirect': 0, 'no-go': 0, \"'\": 5, 'mark': 0, 'costing': 0, 'uhh': 0, 'process/cna': 0, '120/unit': 0, 'fined': 0, 'component': 0, 'proposition': 0, 'spillover': 0, 'infer': 0, 'welle': 0, 'jacob': 0, 'occurred': 0, 'cool': 0, '3-4': 0, 'poster': 0, 'extend': 0, 'test1': 0, 'adjustments': 0, 'late': 0, 'highschool': 0, 'listing': 0, 'typically': 0, '5th': 0, 'template': 3, 'frankly': 0, 'price': 0, 'mistaken': 0, 'charge': 0, 'ones': 0, 'relates': 0, 'have': 0, 'deadlines': 0, 'sacrifice': 0, 'ii': 0, 'filtering': 0, 'relationship': 0, 'list': 15, 'failure': 0, 'subjects': 0, 'cya': 0, 'jesus': 0, 'evacuated': 0, 'basically': 0, 'aubrey': 0, 'disregard': 0, 'makertability/cost': 0, 'ewith': 0, 'versatile': 0, 'assistance': 0, 'has/': 0, 'kept': 0, 'word': 0, 'spend': 0, 'thomasdavis312': 0, 'designs': 0, '110': 0, 'hrs': 0, 'generated': 0, 'delivered': 0, 'slowly': 0, 'features': 0, 'loses': 0, 'throw': 0, 'middle': 3, 'just': 0, 'ruled': 0, 'frustration': 0, 'property': 0, 'array': 0, 'hemodialysis': 0, 'explored': 0, 'http': 0, 'radical': 0, 'sufactants': 0, 'consist': 0, 'possibilities': 0, 'fairly': 0, 'offered': 0, 'memo': 0, 'on/what': 0, 'modifications': 0, 'proto4': 0, 'limit': 0, 'giving': 3, 'numbers': 0, '8am': 0, '19': 0, 'marketablitlity': 0, 'language': 3, 'hole': 0, 'cnts': 0, 'flow': 0, 'darrrrren': 0, 'number': 0, 'erase': 0, 'b': 0, 'expenmsive': 0, 'invested': 0, '.......': 0, '20.': 0, 'compiling': 0, 'inferring': 0, 'well4': 0, 'needing': 0, 'winemiller': 0, 'satisfaction': 0, 'misguided': 0, 'hydropholic': 0, 'depoisiton': 0, 'combining': 0, 'filling': 0, 'hey': 3, 'p.m.': 0, 'anywehre': 0, 'logged': 0, 'mroe': 0, 'beta': 0, 'relativity': 0, 'valible': 0, 'wise': 0, 'e.g': 0, 'compares': 0, 'leaves': 0, 'fast': 0, '4-2': 0, ')': 3, 'prioritizng': 0, 'william': 0, 'normally': 0, 'surfactatant': 0, 'caps': 0, 'emotionally': 0, 'sweater': 0, 'okied': 0, 'cost.if': 0, 'going': 3, 'enlightened': 0, 'lady': 0, 'was': 0, 'ended': 0, 'dispersion': 0, 'technically': 0, 'corey': 0, 'notifications': 0, 'answering': 0, 'pro.2': 0, 'explicitly': 0, 'turned': 0, '1:46': 0, '2nd-': 0, 'furthermore': 0, 'discuss': 0, 'productive': 0, 'vary': 0, 'despite': 0, 'rays': 0, 'barely': 0, 'gotten': 0, 'provided': 3, 'concur': 0, 'change': 0, 'pseudo': 0, 'revisions': 5, 'emphasizing': 0, 'scored': 0, 're-tweet': 0, 'opionions': 0, 'relationships': 0, 'padma': 0, 'evryone': 0, 'arent': 0, 'specs': 0, 'decline': 0, 'persuaded': 0, 'somewhat': 0, 'adheres': 0, 'hdryo': 0, 'taylor': 0, 'gotcha': 0, 'wi-fi': 0, 'working': 12, 'use': 12, '75': 0, 'resumbit': 0, 'negated': 0, 'ly': 0, 'chats': 0, 'clogging': 0, 'realiabilty': 0, 'wiliams': 0, 'simulation': 0, 'markets': 0, 'unseen': 0, 'sorry': 0, '-': 0, 'struggles': 0, 'cost': 0, 'suppose': 0, 'sup': 0, 'purchasing': 0, 'starts': 0, 'correlate': 0, 'trial': 3, 'ratio': 0, 'vdp': 0, 'decrease': 0, 'noticeable': 0, 'gerneate': 0, 'cut': 0, 'obviously': 3, '1:31': 0, 'convenient': 0, 'specialized': 0, 'degree': 0, 'notes': 0, 'tinker': 0, 'wasvery': 0, 'sean': 0, 'eave': 0, 'outlines': 0, 'parties-': 0, ',1.5': 0, 'improved/reoptomized': 0, 'videos': 0, 'approximately': 0, 'okedoke': 0, 'ranking': 0, 'unacceptable': 0, 'messng': 0, 'strikes': 0, 'procedures': 0, '8.25': 0, 'goog': 0, 'high': 0, 'rita': 0, 'endeavors': 0, 'flourish': 0, 'unknowns': 0, 'obvious': 0, 'counted': 0, '1:25': 0, 'thought': 0, 'told': 0, '3.1': 0, 'rate': 0, 'ish': 0, 'pototypes': 0, 'itd': 0, 'saving': 0, 'anthing': 0, 'nanotubing': 0, 'enlarge': 0, 'feedback': 9, 'beyond': 0, 'messed': 0, 'proceses': 0, 'night': 0, 'satidfaction': 0, 'brings': 0, 'good/average/bad': 0, '10.0': 0, '\\x89ûïlow': 0, 'anderson': 0, 'economical': 0, 'resisting': 0, 'investigated': 0, 'betchya': 0, 'laying': 0, 'rejoining': 0, 'tianwei': 0, 'prices': 0, 'revising': 0, 'team': 42, 'bleeding': 0, 'victoria': 0, 'surveyed': 0, 'priya': 0, 'sequels': 0, 'credited': 0, '9': 0, 'adam': 0, '10.': 0, 'panel': 0, 'thx': 0, 'resultes': 0, 'noteiced': 0, 'he\\x89ûªd': 0, 'acceptable': 0, 'reduces': 0, 'containing': 0, 'carbonnanotubes': 0, 'ryan': 0, 'charige': 0, '330-530': 0, 'justification': 3, 'ablity': 0, 'positives': 0, 'exercise': 0, 'jennine': 0, 'apparent': 0, 'bilogical': 0, 'identify': 0, 'accommodate': 0, 'trivial': 0, 'tradeoff': 0, 'non-steric': 0, 'asked': 0, 'neatly': 0, 'benifits': 0, 'any': 0, 'note': 3, '^major': 0, 'marketablity': 0, 'close': 3, 'webpages': 0, 'suggest': 0, 'whomever': 0, 'network': 0, 'tht': 0, 'archive': 0, 'toss': 0, 'spite': 0, 'median': 0, 'public': 0, 'sides': 0, 'prioritize': 0, 'tweaks': 0, '1': 0, 'experimentation': 0, 'well-rounded': 0, 'incorporation': 0, 'return': 0, 'hardly': 0, 'beause': 0, 'rao': 0, 'vague': 0, 'hah': 0, 'highlights': 0, 'allen': 0, 'easily': 0, 'optimized': 0, 'objection': 0, 'refering': 0, 'surfactantss': 0, 'correctly': 0, 'c.j': 0, 'consults': 0, 'margin': 0, '5:23.': 0, 'solid': 0, 'match': 0, 'ml': 0, 'untitled': 0, 'seeya': 0, 'bests': 0, 'dropping': 0, 'everybody': 0, 'let': 6, 'minimal': 0, 'way': 0, 'firm': 0, 'random': 0, 'scientist': 0, 'prbably': 0, 'desired': 0, 'pasting': 0, 'speculation': 0, 'direction': 0, 'with': 0, 'carbon': 0, 'knocking': 0, 'profile': 0, 'cited': 0, 'save': 0, 'definelty': 0, '1:02': 0, 'goals': 0, 'inclusive': 0, 'such': 0, 'date': 0, 'article': 0, 'examined': 0, 'altered': 0, 'lowering': 0, 'on': 0, 'draft': 0, 'although': 0, 'extremely': 0, 'twice': 0, 'exist': 0, 'characterisitic': 0, 'sentence': 0, 'pursuing': 0, 'stephen': 0, 'west': 0, '82': 0, 'erased': 0, 'sooo': 0, 'groups': 0, 'standpoint': 0, 'throwing': 0, 'composites': 0, 'everyones': 0, 'hmm': 0, 'bioreactivity': 0, 'bother': 0, 'nephrotex': 10, 'laptop': 0, 'drops': 0, 'attractiveness': 0, 'pro.1,2,3': 0, 'ughhh': 0, 'restarting': 0, 'ashlyn': 0, 'congrats': 0, 'showing': 0, 'cares': 0, 'task': 6, 'better': 0, 'hingdering': 0, 'p.s': 0, 'future': 0, 'personaly': 0, 'suffered': 0, 'felt': 0, '/5': 0, 'story': 0, '11.0': 0, 'absent': 0, 'wonder': 0, 'sounds': 0, 'realistic': 0, 'deciding': 0, '115': 0, '4:50': 0, 'candidates': 0, 'regarding': 0, 'charged': 0, 'reporting': 0, 'pm': 0, 'tru^^': 0, 'lacking': 0, 'vastly': 0, 'fair': 0, 'clearification': 0, 'section': 9, 'comforting': 0, 'doctors': 0, '^^': 0, 'nah': 0, 'awful': 0, 'insider': 0, 'level': 0, 'uncertain': 0, 'group/': 0, 'campus': 0, 'balance': 0, 'is.now': 0, 'blood-cell': 0, 'summer': 0, 'processes/percentages': 0, 'surfacnant': 0, 'nick': 0, '1-1.5': 0, 'follow': 0, 'erik': 0, 'slackin': 0, '#': 0, 'downright': 0, 'sh': 0, 'kaitlyn': 0, 'asd': 0, 'consultant': 3, 'trumped': 0, 'layout': 0, '5:20': 0, 'scores': 0, 'molly': 0, 'ask': 3, 'steric-hindering': 0, 'experiments': 0, 'absence': 0, 'prove': 0, 'net': 0, 'notebook': 38, '15th': 0, 'position': 0, 'very': 0, 'reactivty': 0, 'identifiable': 0, 'facilitate': 0, 'distributed': 0, 'tomorrow': 0, 'guerrero': 0, '5pm': 0, 't.': 0, 'surfacctants': 0, 'moment': 0, 'smack': 0, 'predecessor': 0, 'argue': 0, 'marketing': 0, 'mind': 1, 'realiablity': 0, 'sufacat': 0, 'rescue': 3, 'cubicles': 0, 'cold': 0, 're-installed': 0, '101': 0, 'pack': 0, 'monday': 0, 'typical': 0, 'bayley': 0, 'macbook': 0, 'means': 0, 'tended': 0, 'prefferred': 0, 'clarifying': 0, 'aming': 0, 'connor': 0, 'efficiency': 0, 'differnt': 0, 'key': 3, 'gantt': 0, 'following': 3, 'flux/vapor': 0, 'typing': 0, 'implied': 0, 'resource': 6, 'lawsuits': 0, 'patrick': 0, 'disadvantages': 0, 'bayleigh': 0, 'people': 0, 'reliablitly': 0, 'box': 0, 'clikced': 0, 'stops': 0, 'dedotated': 0, 'grasping': 0, 'andone': 0, 'wanted': 3, 'completion': 0, 'class': 0, 'concentration': 0, 'hinderince': 0, 'sterically': 0, 'whatsup': 0, 'nathaniel': 0, 'recommandations': 0, 'amazingly': 0, 'copying': 0, 'intro': 0, 'impressive': 0, '%': 0, 'sheet': 0, 'consequently': 0, 'crucial': 0, 'composed': 0, '9:20': 0, 'look': 0, '1-4': 0, 'ncessarily': 0, 'prof': 0, '41.4': 0, 'upon': 0, 'fav': 0, 'reliabilities': 0, 'recap': 0, 'polysulfone': 0, 'released': 0, 'newest': 0, 'remained': 0, '4th': 0, 'placed': 0, 'confusingsorry': 0, 'mest': 0, 'known': 0, 'keywords': 0, 'steven': 0, 'heavy': 0, 'plz': 0, 'inverstion': 0, 'confusion': 0, 'play': 0, 'proto1': 0, 'attachement': 0, 'straightened': 0, 'utilize': 0, 'stgeric': 0, 'reactivity': 0, 'resources': 3, '18th': 0, 'harder': 0, 'firefox': 0, 'apsects': 0, 'resulted': 0, 'ups': 0, 'instance': 0, 'actuallly': 0, 'nanotubs': 0, 'used.poly': 0, 'disageree': 0, 'white': 0, 'based': 3, 'troubles': 0, 'shoot': 0, 'usual': 0, 'treat': 0, 'essential': 0, 'lazy': 0, 'tryin': 0, 'ali': 0, 'outlined': 0, 'concerned': 0, 'btg': 0, 'documents': 0, 'wild': 0, 'thousands': 0, '63.2': 0, 'establish': 0, 'bummer': 0, 'observe': 0, 'inside': 0, 'extrememly': 0, 'backwards': 0, 'reliabbility': 0, 'aaron': 0, '4rth': 0, 'boss': 6, 'there': 0, 'researches': 0, 'remind': 0, 'depend': 0, 'oppinion': 0, 'mackenzie': 0, 'money': 0, 'valuing': 0, 'haley': 0, 'blueprints': 0, 'username': 0, 'jerrid': 0, 'only': 0, 'logs': 0, 'moving': 0, 'recourse': 0, 'properties': 3, 'talked': 0, 'hyrdophilic': 0, 'content': 0, 'liking': 0, 'small': 0, '2-alan': 0, '2.00': 0, 'age/medical': 0, 'chances': 0, 'went': 0, 'profit': 0, 'turning': 0, 'technique': 0, 'apply': 0, 'structure': 0, 'suffering': 0, 'because': 0, 'oil': 0, '1a': 0, 'proponent': 0, 'improved': 0, 'band': 0, 'comments': 0, 'held': 0, 'articles': 0, 'reactivivity': 0, 'produce': 0, 'curriculum': 0, 'equipment': 0, 'paraphrase': 3, 'thee': 0, 'label': 0, 'addiditive': 0, 'tho': 0, 'charlie': 0, 'botching': 0, 'eventually': 0, 'strong': 0, 'fields': 3, 'immune': 0, 'flip': 0, 'inform': 3, 'practice': 3, 'meal': 0, 'havent': 0, 'description': 0, 'greetings': 0, 'liquid': 0, 'relatives': 0, 'knew': 0, 'curiosity': 0, 'titled': 0, 'icon': 3, 'refreshing': 0, 'staff': 3, 'peace': 0, 'logging': 0, 'relilabilitiy': 0, 'poorly': 0, 'appeared': 0, 'coating': 0, 'developing': 3, 'foul': 0, 'operation': 0, 'invest': 0, \"'re\": 0, '2nd': 0, 'mini': 0, 'complement': 0, 'comprehend': 0, 'solutions': 0, 'atleast': 0, 'nickname': 0, 'hone': 0, '10:45': 0, 'correct': 6, 'base': 0, 'attatch': 0, 'worst': 0, 'remotely': 0, 'stressed': 0, 'surpasses': 0, 'conditions': 0, 'spectacular': 0, 'pairs': 0, 'volunteering': 0, 'cali': 0, 'b6': 0, 'm3/m2-day': 0, 'posted': 18, 'labeled': 0, 'favoritism': 0, 'attractive': 0, 'uses': 0, 'worlds': 0, 'attends': 0, 'seeing': 0, 'hydrophilic/': 0, 'copied': 0, 'prefers': 0, 'unnecessary': 0, 'leading': 0, 'write-up': 9, 'manner': 0, 'today.': 0, 'pertaining': 0, 'ta': 0, 'outputs': 3, 'reference': 9, '500,00.': 0, 'regularly': 0, 'varies': 0, 'trend': 0, 'repeats': 0, 'enable': 0, 'beta-': 0, 'quest': 0, 'feeling': 0, 'desktop': 0, '10/13/15': 0, 'poll': 0, 'usable': 0, 'chaos': 0, 'unrealistic': 0, 'upset': 0, 'shall': 0, 'coolio': 0, 'o.k': 0, 'fixing': 0, 'nose': 0, 'perfect': 0, 'quickly': 3, 'struggeling': 0, 'target': 0, 'polymeric': 0, 'cut-off': 0, '-surfactant': 0, 'therefore': 0, 'overall.': 0, 'impressed': 0, 'thresh': 0, 'occured': 0, 'for': 0, 'low-price': 0, '1pm': 0, 'eaach': 0, 'front': 0, 'resubmit': 0, 'traits': 0, 'started': 2, 'bot': 0, 'phenomenal': 0, 'similarly': 0, 'finals': 0, 'spread': 0, 'undecided': 0, 'loss': 0, 'shame': 0, 'interestingly': 0, 'boards': 0, '20-22': 0, 'significance': 0, 'lied': 0, 'route': 0, 'result': 0, 'sufficient': 0, 'attatched': 0, 'materail': 0, 'perferred': 0, 'upside': 0, 'finalized': 0, 'confirmed': 0, 'grphing': 0, 'guide': 0, 'multiplied': 0, 'currently': 0, 'venting': 0, 'fault': 0, 'caters': 0, 'damnit': 0, 'monitoring': 0, 'office': 0, 'unorthodox': 0, 'agent': 0, 'bent': 0, 'attention': 3, 'integrate': 0, 'idk-i': 0, 'longest': 0, 'stop': 0, 'tailored': 0, 'th': 0, 'vale': 0, 'consistancy': 0, 'is': 0, 'presented': 0, 'driving': 0, 'isn': 0, 'collecting': 0, 'dareen': 0, 'mondays/': 0, 'sized': 0, 'john-michelle': 0, 'u': 0, 'assuming': 3, 'manipulate': 0, 'lowest': 0, 'unsure': 0, 'sick': 0, 'josh': 0, 'necessary': 0, 'ngineer': 0, 'hospitals': 0, 'fees': 0, 'spent': 0, 'joseph': 0, 'referred': 0, 'reason': 0, 'baised': 0, 'uniformly': 0, 'consequences': 0, 're-submitted': 0, 'customers': 0, 'failing': 0, '5.1': 0, 'journal': 0, 'valid': 0, 'graded': 0, 'aiming': 0, 'why': 0, 'joes': 0, 'up': 0, 'lives': 0, 'theirs': 0, 'hwang': 0, 'severe': 0, 'discard': 0, 'oh': 0, 'annemarie': 0, 'factoring': 0, 'replies': 0, 'sections': 0, 'yesterdays': 0, 'rectangle': 0, 'click': 3, 'past': 0, 'presence': 0, '^^^yeah': 0, 'right^': 0, 'stuff': 0, 'personal': 0, 'certain': 3, 'disruptive': 0, 'notified': 0, 'hell': 0, 'pes-pvp': 0, 'hailey': 0, 'can': 3, 'application': 0, 'favorite': 0, 'nuclear': 0, 'lesser': 0, 'alec': 0, 'visual/physical/': 0, 'rest': 3, 'lots': 0, 'without': 0, 'versed': 0, 'functioning': 0, 'estimate': 0, 'affected': 0, 'im': 0, 'isabella': 0, 'thin': 0, 'respectively': 0, '3:30-4:30.': 0, 'shuffle': 0, 'touch': 0, 'definitely': 0, 'cnt=1.5': 0, 'pespvp': 0, 'take': 0, 'afraid': 0, 'pops': 0, 'classroom': 0, 'document': 0, 'catagories': 0, 'opinion': 0, '0.6': 0, 'college': 0, 'non': 0, 'generate': 0, 'enjoy': 0, 'impossible': 0, '4x': 0, 'developments': 0, '500': 0, 'average': 0, 'alot': 0, 'ayoooo': 0, 'bloodcell': 0, 'katherine': 0, 'generation': 0, 'mouth': 0, 'sticky': 0, 'mysteriously': 0, 'ok': 0, 'karl': 0, 'bigger': 3, 'each': 0, 'incorporate': 0, 'participating': 0, 'reliabiltiy': 0, 'thou': 0, 'shorter': 0, 'whatnot': 0, 'in': 3, 'jarret': 0, 'notebooks': 5, 'choose': 3, 'miss': 0, 'joining': 0, '235': 0, 'kayleigh': 0, 'unique': 0, '3.reactivity': 0, 'mass': 0, 'mine': 3, 'satisfactory': 0, 'downloading': 0, 'bullets': 0, 'ala': 0, 'strict': 0, '2-for': 0, 't': 0, 'alrights': 0, 'offs': 0, 'gold': 0, 'aright': 0, 'gregory': 0, 'memebrane': 0, 'strive': 0, 'unkowns': 0, '1.5-2': 0, 'comprises': 0, 'robert': 0, 'p.': 0, 'sticks': 0, 'next': 7, 'conlcusion': 0, 'and/or': 0, 'heart': 0, 'aim': 0, 'fridays': 0, 'appreciate': 0, 'joe': 0, 'leads': 0, 'brandon': 0, 'cancel': 6, 'p6': 0, 'updated': 0, 'holds': 0, 'interactions': 0, 'communicate': 0, '10:20am': 0, 'effect': 0, 'lacked': 0, 'yeyah': 0, 'preformed': 0, 'capitalism': 0, 'machines': 0, 'reading': 0, 'marketabiltiy': 0, 'accepts': 0, 'reliablitity': 0, 'exceptional': 0, 'ian': 0, 'problemo': 0, 'brendan': 0, 'edited': 0}\n"
     ]
    }
   ],
   "source": [
    "print(word_dict[0]) #printing the dictionary of user 1"
   ]
  },
  {
   "source": [
    "## TF-IDF\n",
    "\n",
    "Rather than just counting, we can use <u>TF-IDF</u>, short for term frequency-inverse document frequency to rank a word on it's importance.\n",
    "\n",
    "The <u>TF-IDF</u> score of a word $w$ is:\n",
    "$$tf(w) * idf(w)$$\n",
    "Where $tf(w) =$ frequency of word in a document / total number of words in the document\n",
    "\n",
    "And where $idf(w) = log$(number of documents / number of documents that contain word $w$)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(word_dict, user_dict):\n",
    "    tf_dict = {}\n",
    "    user_dict_count = len(user_dict)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(user_dict_count)\n",
    "    return tf_dict\n",
    "\n",
    "def computeIDF(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    n = len(doc_list)\n",
    "\n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(),0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "\n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(n / float(val), 10)\n",
    "\n",
    "    return idf_dict\n",
    "\n",
    "def computeTFIDF(tf_user_dict, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_user_dict.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "source": [
    "### Example of TF-IDF\n",
    "\n",
    "Suppose we have two documents as listed below. The calculation of <u>TF-IDF</u> for the term \"hello\" is performed as: \n",
    "\n",
    "The <u>TF</u>, is the frequency that the word \"hello\" appears in each document. In each document, the word appears once; but as document 1 (index 0) has more words, its relative frequency is smaller.\n",
    "\n",
    "$$ tf('hello', doc1) = \\frac{1}{6} \\approx 0.166 $$\n",
    "$$ tf('hello', doc2) = \\frac{1}{3} = 0.333 $$\n",
    "\n",
    "An <u>IDF</u> accounts for the ratio of documents that include the word \"hello\". In this case, we have a total of two documents and all of them include the word \"hello\".\n",
    "\n",
    "$$ idf('hello', documents) = log(\\frac{2}{2}) = 0 $$\n",
    "\n",
    "So <u>TF-IDF</u> is 0 for the word \"hello\" implying that the word is not very informative as it appears in all documents.\n",
    "\n",
    "$$ tfidf('hello', doc1, documents) = 0.166 * 0 = 0 $$\n",
    "$$ tfidf('hello', doc2, documents) = 0.333 * 0 = 0 $$\n",
    "\n",
    "Take the word \"team\", it occurs once only in document 1:\n",
    "\n",
    "$$ tf('team', doc1) = \\frac{1}{6} \\approx 0.166 $$\n",
    "$$ tf('team', doc2) = \\frac{0}{3} = 0 $$\n",
    "$$ idf('team', documents) = log(\\frac{2}{1}) \\approx 0.301 $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ tfidf('team', doc1, documents) = tf('team', doc1) * idf('team', documents) = 0.166 * 0.301 \\approx 0.05 $$\n",
    "$$ tfidf('team', doc2, documents) = tf('team', doc2) * idf('team', documents) = 0 * 0.301 = 0 $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   team  brandon  !  hello  .  welcome  nephrotex\n",
       "0     1        0  1      1  1        1          1\n",
       "1     0        1  1      1  0        0          0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>team</th>\n      <th>brandon</th>\n      <th>!</th>\n      <th>hello</th>\n      <th>.</th>\n      <th>welcome</th>\n      <th>nephrotex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "doc1 = word_tokenize(df['content_without_stopwords'][0])\n",
    "doc2 = word_tokenize(df['content_without_stopwords'][5])\n",
    "\n",
    "word_set_example = set(doc1).union(set(doc2))\n",
    "word_dict1 = dict.fromkeys(word_set_example, 0)\n",
    "word_dict2 = dict.fromkeys(word_set_example, 0)\n",
    "\n",
    "for word in doc1:\n",
    "    word_dict1[word] += 1\n",
    "\n",
    "for word in doc2:\n",
    "    word_dict2[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict1, word_dict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello\ntf for document 1: 0.16666666666666666\ntf for document 2: 0.3333333333333333\nidf for documents: 0.0\ntfidf for document 1: 0.0\ntfidf for document 2: 0.0\n\nteam\ntf for document 1: 0.16666666666666666\ntf for document 2: 0.0\nidf for documents: 0.30102999566398114\ntfidf for document 1: 0.05017166594399686\ntfidf for document 2: 0.0\n"
     ]
    }
   ],
   "source": [
    "tf1_example = computeTF(word_dict1, doc1)\n",
    "tf2_example = computeTF(word_dict2, doc2)\n",
    "\n",
    "idf_example = computeIDF([word_dict1, word_dict2])\n",
    "\n",
    "tfidf1_example = computeTFIDF(tf1_example, idf_example)\n",
    "tfidf2_example = computeTFIDF(tf2_example, idf_example)\n",
    "\n",
    "print(\"hello\")\n",
    "print(\"tf for document 1: \" + str(tf1_example['hello']))\n",
    "print(\"tf for document 2: \" + str(tf2_example['hello']))\n",
    "print(\"idf for documents: \" + str(idf_example['hello']))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example['hello']))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example['hello']))\n",
    "print(\"\")\n",
    "print(\"team\")\n",
    "print(\"tf for document 1: \" + str(tf1_example['team']))\n",
    "print(\"tf for document 2: \" + str(tf2_example['team']))\n",
    "print(\"idf for documents: \" + str(idf_example['team']))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example['team']))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example['team']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF(word_dict) #compute idf\n",
    "tfidf = [] #create empty list to append tf-idf values\n",
    "for i in range(len(user_dict)): \n",
    "    temp_tf_user_dict = computeTF(word_dict[i], user_dict[i]) #compute tf\n",
    "    temp_tfidf_user_dict = computeTFIDF(temp_tf_user_dict, idfs) #compute tf-idf\n",
    "    tfidf.append(temp_tfidf_user_dict) #append tf-idf values into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      another  collected  utilized      must  refection  feed  austins  \\\n",
       "0    0.001370        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "1    0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "2    0.005369        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "3    0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "4    0.004918        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "..        ...        ...       ...       ...        ...   ...      ...   \n",
       "388  0.001164        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "389  0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "390  0.000000        0.0  0.000000  0.003354        0.0   0.0      0.0   \n",
       "391  0.000000        0.0  0.007594  0.004020        0.0   0.0      0.0   \n",
       "392  0.000893        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "\n",
       "     directly  saves  holly  ...  machines  reading  marketabiltiy  accepts  \\\n",
       "0         0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "1         0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "2         0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "3         0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "4         0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "..        ...    ...    ...  ...       ...      ...            ...      ...   \n",
       "388       0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "389       0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "390       0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "391       0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "392       0.0    0.0    0.0  ...       0.0      0.0            0.0      0.0   \n",
       "\n",
       "     reliablitity  exceptional  ian  problemo  brendan  edited  \n",
       "0             0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "1             0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "2             0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "3             0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "4             0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "..            ...          ...  ...       ...      ...     ...  \n",
       "388           0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "389           0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "390           0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "391           0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "392           0.0          0.0  0.0       0.0      0.0     0.0  \n",
       "\n",
       "[393 rows x 6026 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>another</th>\n      <th>collected</th>\n      <th>utilized</th>\n      <th>must</th>\n      <th>refection</th>\n      <th>feed</th>\n      <th>austins</th>\n      <th>directly</th>\n      <th>saves</th>\n      <th>holly</th>\n      <th>...</th>\n      <th>machines</th>\n      <th>reading</th>\n      <th>marketabiltiy</th>\n      <th>accepts</th>\n      <th>reliablitity</th>\n      <th>exceptional</th>\n      <th>ian</th>\n      <th>problemo</th>\n      <th>brendan</th>\n      <th>edited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001370</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005369</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.004918</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>0.001164</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.003354</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.007594</td>\n      <td>0.004020</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>0.000893</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>393 rows × 6026 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame.from_records(tfidf) #make the matrix into a dataframe\n",
    "df_tfidf"
   ]
  },
  {
   "source": [
    "## Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      another  collected  utilized      must  refection  feed  austins  \\\n",
       "0    0.001370        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "1    0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "2    0.005369        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "3    0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "4    0.004918        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "..        ...        ...       ...       ...        ...   ...      ...   \n",
       "388  0.001164        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "389  0.000000        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "390  0.000000        0.0  0.000000  0.003354        0.0   0.0      0.0   \n",
       "391  0.000000        0.0  0.007594  0.004020        0.0   0.0      0.0   \n",
       "392  0.000893        0.0  0.000000  0.000000        0.0   0.0      0.0   \n",
       "\n",
       "     directly  saves  holly  ...  reading  marketabiltiy  accepts  \\\n",
       "0         0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "1         0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "2         0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "3         0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "4         0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "..        ...    ...    ...  ...      ...            ...      ...   \n",
       "388       0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "389       0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "390       0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "391       0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "392       0.0    0.0    0.0  ...      0.0            0.0      0.0   \n",
       "\n",
       "     reliablitity  exceptional  ian  problemo  brendan  edited  OutcomeScore  \n",
       "0             0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "1             0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "2             0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "3             0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "4             0.0          0.0  0.0       0.0      0.0     0.0             2  \n",
       "..            ...          ...  ...       ...      ...     ...           ...  \n",
       "388           0.0          0.0  0.0       0.0      0.0     0.0             7  \n",
       "389           0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "390           0.0          0.0  0.0       0.0      0.0     0.0             5  \n",
       "391           0.0          0.0  0.0       0.0      0.0     0.0             5  \n",
       "392           0.0          0.0  0.0       0.0      0.0     0.0             4  \n",
       "\n",
       "[393 rows x 6027 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>another</th>\n      <th>collected</th>\n      <th>utilized</th>\n      <th>must</th>\n      <th>refection</th>\n      <th>feed</th>\n      <th>austins</th>\n      <th>directly</th>\n      <th>saves</th>\n      <th>holly</th>\n      <th>...</th>\n      <th>reading</th>\n      <th>marketabiltiy</th>\n      <th>accepts</th>\n      <th>reliablitity</th>\n      <th>exceptional</th>\n      <th>ian</th>\n      <th>problemo</th>\n      <th>brendan</th>\n      <th>edited</th>\n      <th>OutcomeScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001370</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005369</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.004918</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>0.001164</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.003354</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.007594</td>\n      <td>0.004020</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>0.000893</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>393 rows × 6027 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "outcome_score = df.drop_duplicates(subset=['userIDs'])['OutcomeScore'].to_numpy() #grab outcome score of each individual user\n",
    "df_tfidf['OutcomeScore'] = outcome_score \n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}