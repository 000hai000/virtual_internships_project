{
 "cells": [
  {
   "source": [
    "# Virtual Internships Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Modules and Data\n",
    "\n",
    "First we will import all relevant modules. We will then import our csv as a pandas dataframe for easy use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       userIDs implementation  Line_ID ChatGroup  \\\n",
       "0            1              a        1     PRNLT   \n",
       "1            1              a        2     PRNLT   \n",
       "2            1              a        3     PRNLT   \n",
       "3            1              a        4     PRNLT   \n",
       "4            1              a        5     PRNLT   \n",
       "...        ...            ...      ...       ...   \n",
       "19175      392              o    19179    PESPVP   \n",
       "19176      388              o    19180    PESPVP   \n",
       "19177      367              o    19181    PESPVP   \n",
       "19178      393              o    19182    PESPVP   \n",
       "19179      367              o    19183    PESPVP   \n",
       "\n",
       "                                                 content  group_id RoleName  \\\n",
       "0                      Hello team. Welcome to Nephrotex!         2   Mentor   \n",
       "1      I'm Maria Williams. I'll be your design adviso...         2   Mentor   \n",
       "2            I'm here to help if you have any questions.         2   Mentor   \n",
       "3      Please introduce yourselves with the name you ...         2   Mentor   \n",
       "4      I just want to make sure everyone has found th...         2   Mentor   \n",
       "...                                                  ...       ...      ...   \n",
       "19175                                                yes         6   Player   \n",
       "19176                                        sounds good         6   Player   \n",
       "19177          Well, we are out of time for our meeting.         6   Mentor   \n",
       "19178                                          Precisely         6   Player   \n",
       "19179  Good discussion today! Don't forget to complet...         6   Mentor   \n",
       "\n",
       "                                                roomName  \\\n",
       "0      Introduction and Workflow Tutorial with Entran...   \n",
       "1      Introduction and Workflow Tutorial with Entran...   \n",
       "2      Introduction and Workflow Tutorial with Entran...   \n",
       "3      Introduction and Workflow Tutorial with Entran...   \n",
       "4      Introduction and Workflow Tutorial with Entran...   \n",
       "...                                                  ...   \n",
       "19175  Reflection team discussion of first batch results   \n",
       "19176  Reflection team discussion of first batch results   \n",
       "19177  Reflection team discussion of first batch results   \n",
       "19178  Reflection team discussion of first batch results   \n",
       "19179  Reflection team discussion of first batch results   \n",
       "\n",
       "       m_experimental_testing  m_making_design_choices  m_asking_questions  \\\n",
       "0                           0                        0                   0   \n",
       "1                           0                        0                   0   \n",
       "2                           0                        0                   0   \n",
       "3                           0                        0                   0   \n",
       "4                           0                        0                   0   \n",
       "...                       ...                      ...                 ...   \n",
       "19175                       0                        0                   0   \n",
       "19176                       0                        0                   0   \n",
       "19177                       0                        0                   0   \n",
       "19178                       0                        0                   0   \n",
       "19179                       0                        0                   0   \n",
       "\n",
       "       j_customer_consultants_requests  j_performance_parameters_requirements  \\\n",
       "0                                    0                                      0   \n",
       "1                                    0                                      0   \n",
       "2                                    0                                      0   \n",
       "3                                    1                                      0   \n",
       "4                                    0                                      0   \n",
       "...                                ...                                    ...   \n",
       "19175                                0                                      0   \n",
       "19176                                0                                      0   \n",
       "19177                                0                                      0   \n",
       "19178                                0                                      0   \n",
       "19179                                0                                      0   \n",
       "\n",
       "       j_communication  OutcomeScore  wordCount  \n",
       "0                    0             4          5  \n",
       "1                    0             4         11  \n",
       "2                    0             4          9  \n",
       "3                    0             4         51  \n",
       "4                    0             4         39  \n",
       "...                ...           ...        ...  \n",
       "19175                0             5          1  \n",
       "19176                0             8          2  \n",
       "19177                0             4          9  \n",
       "19178                0             4          1  \n",
       "19179                0             4         11  \n",
       "\n",
       "[19180 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userIDs</th>\n      <th>implementation</th>\n      <th>Line_ID</th>\n      <th>ChatGroup</th>\n      <th>content</th>\n      <th>group_id</th>\n      <th>RoleName</th>\n      <th>roomName</th>\n      <th>m_experimental_testing</th>\n      <th>m_making_design_choices</th>\n      <th>m_asking_questions</th>\n      <th>j_customer_consultants_requests</th>\n      <th>j_performance_parameters_requirements</th>\n      <th>j_communication</th>\n      <th>OutcomeScore</th>\n      <th>wordCount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>a</td>\n      <td>1</td>\n      <td>PRNLT</td>\n      <td>Hello team. Welcome to Nephrotex!</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>a</td>\n      <td>2</td>\n      <td>PRNLT</td>\n      <td>I'm Maria Williams. I'll be your design adviso...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>a</td>\n      <td>3</td>\n      <td>PRNLT</td>\n      <td>I'm here to help if you have any questions.</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>a</td>\n      <td>4</td>\n      <td>PRNLT</td>\n      <td>Please introduce yourselves with the name you ...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>a</td>\n      <td>5</td>\n      <td>PRNLT</td>\n      <td>I just want to make sure everyone has found th...</td>\n      <td>2</td>\n      <td>Mentor</td>\n      <td>Introduction and Workflow Tutorial with Entran...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19175</th>\n      <td>392</td>\n      <td>o</td>\n      <td>19179</td>\n      <td>PESPVP</td>\n      <td>yes</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19176</th>\n      <td>388</td>\n      <td>o</td>\n      <td>19180</td>\n      <td>PESPVP</td>\n      <td>sounds good</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19177</th>\n      <td>367</td>\n      <td>o</td>\n      <td>19181</td>\n      <td>PESPVP</td>\n      <td>Well, we are out of time for our meeting.</td>\n      <td>6</td>\n      <td>Mentor</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>19178</th>\n      <td>393</td>\n      <td>o</td>\n      <td>19182</td>\n      <td>PESPVP</td>\n      <td>Precisely</td>\n      <td>6</td>\n      <td>Player</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19179</th>\n      <td>367</td>\n      <td>o</td>\n      <td>19183</td>\n      <td>PESPVP</td>\n      <td>Good discussion today! Don't forget to complet...</td>\n      <td>6</td>\n      <td>Mentor</td>\n      <td>Reflection team discussion of first batch results</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>19180 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('virtualInternshipData_ADS2001.csv', encoding= 'unicode_escape') #read the csv provided\n",
    "df = df.drop(\"Unnamed: 0\",axis=1) #drop the unnamed column\n",
    "df"
   ]
  },
  {
   "source": [
    "## Stop Words\n",
    "When working with text or natural language, there are certain words that don't add any value to a sentence e.g. \"this\" and so we will need to remove these words. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With stop words: i'm maria williams. i'll be your design advisor for your internship.\nWithout stop words: maria williams design advisor internship\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "\n",
    "df['content'] = df['content'].str.lower() #make all the letters lowercase for easy of use\n",
    "\n",
    "stop = stopwords.words('english') #import english stopwords from nltk \n",
    "additional_stopwords = [\"i'm\", \"i'll\"] #add any additional stop words not from nltk\n",
    "stop = stop + additional_stopwords\n",
    "\n",
    "df['content_without_stopwords'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #remove all stopwords in content column\n",
    "\n",
    "df['content_without_stopwords'] = df['content_without_stopwords'].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation))) #remove all punctuation\n",
    "\n",
    "df['content_without_stopwords'] = df['content_without_stopwords'].apply(lambda x: \"\".join([i for i in x if not i.isdigit()])) #remove all digits\n",
    "\n",
    "print('With stop words: ' + df['content'][1])\n",
    "print('Without stop words: ' + df['content_without_stopwords'][1])"
   ]
  },
  {
   "source": [
    "## Tokenizing\n",
    "\n",
    "In natural language processing, each document or sentence can thought of as a bag of words in the form of a list where each element is a word..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['content_tokenized'] = df.apply(lambda row: word_tokenize(row['content_without_stopwords']), axis=1) #tokenize all the content"
   ]
  },
  {
   "source": [
    "Splitting the document up like this is called <u>tokenizing</u>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello', 'team', 'welcome', 'nephrotex']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['content_tokenized'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "deliver', 'multidimensional', 'bit', 'learn', 'pototypes', 'beast', 'reliabilty', 'vastly', 'design', 'necessary', 'claimed', 'developments', 'friend', 'dont', 'tab', 'proposed', 'wound', 'trivial', 'redo', 'separate', 'models', 'jamesrude', 'taht', 'hinderence', 'hmm', 'ooops', 'portal', 'satisfy', 'safe', 'surface', 'certainly', 'upper', 'sent', 'analyses', 'slots', 'woohoo', 'dj', 'reilability', 'wellwritten', 'mackenzi', 'summer', 'chemistry', 'succesful', 'about', 'accepts', 'kristins', 'wifi', 'reactability', 'cuz', 'assistance', 'samuel', 'commercially', 'formal', 'enabled', 'whereas', 'joes', 'earned', 'diffused', 'studying', 'accounted', 'turnaround', 'better', 'marc', 'generating', 'realatively', 'custom', 'ready', 'betathromogobulin', 'asoect', 'since', 'suractants', 'recommending', 'robert', 'battling', 'condense', 'treatments', 'assigment', 'cracking', 'plausible', 'reid', 'describing', 'chose', 'profiles', 'phases', 'higher', 'physics', 'writeups', 'perceived', 'brianwe', 'expects', 'do', 'believe', 'upside', 'writers', 'posssible', 'because', 'alexanders', 'safety', 'si', 'something', 'tianwei', 'understands', 'bruh', 'techniques', 'exclude', 'guarantee', 'congrats', 'directs', 'erin', 'speak', 'expectations', 'soooo', 'shown', 'investigate', 'coose', 'sweet', 'erase', 'category', 'productivity', 'joepadma', 'dean', 'maintained', 'insane', 'mijail', 'steady', 'fault', 'ting', 'clicking', 'degree', 'baby', 'ontrol', 'g', 'dareen', 'valuing', 'workpro', 'weccomended', 'manage', 'troof', 'stronger', 'nonsteric', 'letting', 'completely', 'bringing', 'pivotal', 'especially', 'sh', 'provides', 'basic', 'ever', 'gang', 'dated', 'reaction', 'mandatory', 'overcame', 'overshadowed', 'tissues', 'annemaries', 'therefore', 'hydophillic', 'workign', 'preformed', 'taylors', 'silas', 'marketability', 'incorporating', 'lab', 'welp', 'calculations', 'neatly', 'abilities', 'scientist', 'ranked', 'predictions', 'zachary', 'charged', 'morning', 'noteiced', 'disucssion', 'citation', 'cnts', 'typically', 'without', 'realibility', 'process', 'ml', 'didnt', 'umbers', 'wg', 'angel', 'marketabililty', 'is', 'dude', 'hernandez', 'realistically', 'ohh', 'cubicles', 'ii', 'stuff', 'prefers', 'proficiency', 'mates', 'wonderful', 'anthing', 'narrowing', 'genuinely', 'cleaning', 'thetesting', 'then', 'satidfaction', 'provided', 'conclusion', 'enrty', 'might', 'completing', 'attempting', 'folks', 'whcih', 'affects', 'justifying', 'extended', 'gantt', 'chester', 'lie', 'submission', 'posting', 'researches', 'loses', 'title', 'prototypr', 'sooooo', 'complications', 'offended', 'deliverables', 'pi', 'in', 'wouldve', 'days', 'backfired', 'sassyness', 'hash', 'typing', 'prevent', 'valible', 'differently', 'efficiency', 'learned', 'prorosity', 'wait', 'ayoooo', 'analyze', 'wall', 'product', 'damages', 'lives', 'rs', 'brown', 'became', 'income', 'turns', 'negatives', 'update', 'summarizing', 'lowers', 'yesterdays', 'ohhhh', 'aspec', 'luke', 'sorry', 'fix', 'fail', 'percentages', 'step', 'actually', 'matrix', 'emphasized', 'here', 'refereshed', 'outperforming', 'optimum', 'estimate', 'decsion', 'incomplete', 'rita', 'reliabilities', 'redeeming', 'files', 'tweaking', 'vanished', 'improvement', 'facilitating', 'surfactanst', 'disagreeing', 'duh', 'woooooooo', 'reguarding', 'passed', 'effort', 'downsides', 'yoooooo', 'padmas', 'comparatively', 'representation', 'basically', 'apologies', 'elaborate', 'terms', 'sticks', 'notice', 'doesnt', 'excell', 'traviswayne', 'dw', 'shard', 'kimberly', 'very', 'gladly', 'incorporates', 'contained', 'porosity', 'victorias', 'plan', 'matierals', 'messng', 'recieve', 'maxed', 'thromboglobluin', 'balanced', 'number', 'entrance', 'supported', 'leaves', 'judged', 'quesions', 'everyone', 'showcased', 'integrate', 'positives', 'angelica', 'gods', 'howdy', 'um', 'fluxes', 'transcript', 'influenced', 'corrected', 'aim', 'discount', 'logic', 'hat', 'underperformed', 'substantially', 'overoptimized', 'tattooed', 'witnesses', 'aspect', 'vote', 'appearing', 'mprning', 'exceptionally', 'many', 'sec', 'neede', 'goel', 'wilcox', 'notebookbatch', 'professionalism', 'sterric', 'approval', 'efforts', 'em', 'recourse', 'stephens', 'to', 'literally', 'headed', 'tweaks', 'engineers', 'submit', 'inefficient', 'unanimous', 'marketabuility', 'boss', 'selected', 'discuss', 'somereason', 'desire', 'haley', 'redid', 'difference', 'evening', 'reset', 'far', 'impact', 'ahve', 'tailored', 'alter', 'compensated', 'somebody', 'recommandations', 'differnt', 'exceeded', 'polygon', 'weighs', 'straightforward', 'decline', 'listen', 'various', 'earlier', 'chatting', 'project', 'wynters', 'elses', 'reach', 'define', 'feared', 'additionally', 'yas', 'llooks', 'mattered', 'mckenna', 'assumptions', 'midpoint', 'asks', 'god', 'outcome', 'looks', 'sum', 'drawbacks', 'efficiently', 'amen', 'roomate', 'stable', 'unequal', 'block', 'spotty', 'feasible', 'depisition', 'reults', 'informed', 'xing', 'deem', 'inver', 'worth', 'lacked', 'tht', 'surfacant', 'cellulose', 'havent', 'tremendously', 'replying', 'signs', 'overlays', 'caleb', 'unique', 'relflux', 'purpose', 'utterly', 'ot', 'customers', 'proportionally', 'ta', 'rth', 'adjustable', 'serviceable', 'adds', 'awkward', 'whats', 'adhering', 'pops', 'helps', 'illegible', 'against', 'safest', 'power', 'andy', 'discover', 'overboard', 'poorlywritten', 'choice', 'prorotype', 'greatings', 'occurred', 'quickly', 'subpar', 'investigating', 'team', 'viraat', 'west', 'bros', 'peoplebiological', 'responding', 'adapt', 'world', 'concise', 'present', 'technique', 'mouth', 'dan', 'evan', 'applications', 'cheap', 'remotely', 'overcompensates', 'advisors', 'attatchment', 'exactly', 'reviewed', 'manu', 'zelin', 'cutting', 'holes', 'beliebe', 'hoo', 'titled', 'mackenzy', 'izzie', 'leading', 'summarizes', 'perfomance', 'teh', 'understand', 'raises', 'reducing', 'nano', 'served', 'definently', 'depends', 'unshared', 'uh', 'contacting', 'documents', 'although', 'orr', 'large', 'hingdering', 'suited', 'hoped', 'edited', 'style', 'submits', 'goo', 'knew', 'overview', 'ultrafluxphase', 'stretch', 'seperately', 'argue', 'vapor', 'wearing', 'from', 'centers', 'unanimously', 'membranes', 'worthwhile', 'ff', 'discard', 'pmmas', 'technicalities', 'prime', 'recalled', 'fared', 'values', 'new', 'wiebke', 'lacks', 'name', 'lock', 'explicitly', 'available', 'bests', 'chunk', 'ewith', 'mechanical', 'preferable', 'shay', 'outshines', 'goto', 'qualities', 'subjects', 'melissa', 'extreme', 'proposal', 'x', 'one', 'perhaps', 'ruby', 'answers', 'hinderance', 'succeeded', 'surfucant', 'betathrombogloublin', 'theyve', 'professor', 'showing', 'cushion', 'alexander', 'gained', 'st', 'distribute', 'bts', 'done', 'proceeding', 'together', 'weve', 'relationship', 'tamaras', 'worst', 'optimized', 'chime', 'records', 'beter', 'nature', 'hi', 'prioritizes', 'jumped', 'ramping', 'waiting', 'conluded', 'surfactantss', 'tiebreakers', 'educated', 'tech', 'respect', 'evidence', 'hole', 'trials', 'satisfies', 'naming', 'match', 'free', 'challenge', 'ditto', 'forbidden', 'pattern', 'advantage', 'httpimgurcomoryejkd', 'dope', 'replies', 'chats', 'always', 'crashed', 'idc', 'nanotubule', 'plot', 'impacts', 'opionions', 'clogs', 'definitions', 'hhm', 'dialysers', 'yielded', 'reliablility', 'arent', 'bump', 'omg', 'equipment', 'scholar', 'dat', 'concluded', 'reload', 'optimism', 'doubles', 'stuck', 'double', 'downright', 'hohn', 'groupon', 'purposes', 'summaries', 'problem', 'dozens', 'dismiss', 'isolate', 'offered', 'bestflux', 'specifially', 'beginning', 'travics', 'perspective', 'priority', 'cahrge', 'yesh', 'tells', 'jet', 'preffered', 'topic', 'vedant', 'hooligan', 'garbage', 'median', 'neither', 'reliabiltiy', 'recomended', 'suggestions', 'enhance', 'designing', 'validate', 'finicky', 'contact', 'acting', 'apparently', 'concentrate', 'liked', 'unable', 'except', 'break', 'consults', 'reacts', 'f', 'sup', 'variables', 'compromises', 'exist', 'troubling', 'tools', 'ahhh', 'universal', 'between', 'multiplied', 'journey', 'requiremtns', 'justifications', 'aye', 'points', 'detriment', 'tamera', 'numerous', 'fined', 'containing', 'companys', 'table', 'pursue', 'option', 'nay', 'relatively', 'lied', 'instructors', 'low', 'moreso', 'quality', 'favored', 'nathan', 'master', 'plus', 'reccomendation', 'entering', 'demand', 'limits', 'invited', 'radical', 'rather', 'extant', 'become', 'thats', 'heartless', 'position', 'ions', 'considered', 'hwang', 'products', 'mason', 'sounds', 'padama', 'secondary', 'analytical', 'listening', 'versus', 'instructions', 'plagiarism', 'death', 'misread', 'affest', 'untill', 'nothings', 'behave', 'top', 'agrees', 'hence', 'doenst', 'timeconsuming', 'importance', 'minnesota', 'thankz', 'shortcomings', 'prioritize', 'please', 'suufactants', 'ok', 'general', 'refer', 'vdp', 'slides', 'profits', 'writeup', 'yup', 'sentences', 'sacrifice', 'pushed', 'nonzero', 'be', 'news', 'game', 'sample', 'aint', 'disappointed', 'specifics', 'marketiblity', 'crunch', 'clse', 'fulfill', 'worrying', 'performence', 'excpet', 'heres', 'presence', 'brainstorm', 'ahhhh', 'pulled', 'exact', 'uhh', 'sake', 'grades', 'round', 'give', 'requiring', 'pores', 'jacks', 'interesting', 'overkill', 'risking', 'broad', 'leaving', 'btwe', 'beneficial', 'glitchy', 'tucker', 'cancel', 'bayleigh', 'fellow', 'enlightened', 'ie', 'csan', 'internship', 'statements', 'timothy', 'prof', 'hw', 'know', 'life', 'offense', 'prolonged', 'elaines', 'xiangs', 'hindernace', 'nevermind', 'remake', 'workability', 'ge', 'parts', 'failures', 'haoxins', 'collected', 'justification', 'namelycharlie', 'thought', 'advanced', 'smallest', 'benefit', 'nuclear', 'fine', 'bench', 'delayed', 'ti', 'eliminated', 'desktop', 'inform', 'yeswith', 'depending', 'advise', 'asked', 'does', 'andor', 'surfactacant', 'affirmative', 'opinions', 'shape', 'knock', 'tk', 'referenced', 'thin', 'diversify', 'myself', 'wasting', 'kurt', 'thankfully', 'peace', 'evacuate', 'premade', 'dropping', 'apart', 'overlord', 'lawsuits', 'optimization', 'interview', 'sometime', 'mentions', 'tj', 'ellens', 'rylee', 'spendng', 'effexct', 'grey', 'serfactants', 'limitations', 'anyhow', 'hurt', 'while', 'reactivivity', 'byt', 'pamda', 'paid', 'dons', 'catagory', 'azuma', 'categorywhich', 'votes', 'inbox', 'problematic', 'listened', 'grasping', 'paperclip', 'lets', 'expressed', 'inevitable', 'however', 'headtohead', 'shocked', 'hahahhaa', 'themes', 'idk', 'minds', 'extensive', 'controlling', 'knowlege', 'r', 'introduce', 'mac', 'surprises', 'qucker', 'blowing', 'submitting', 'allowed', 'beforehand', 'sams', 'print', 'clearly', 'access', 'someones', 'aesthetics', 'notebbok', 'd', 'solid', 'critically', 'marketabilaty', 'bent', 'thankyou', 'realiable', 'averaged', 'must', 'kyle', 'finnished', 'info', 'partially', 'welcome', 'technonolgy', 'knowing', 'typical', 'enhanced', 'closer', 'fact', 'u', 'catergories', 'filling', 'assest', 'lowprice', 'interests', 'indicate', 'balence', 'webpage', 'hinderince', 'ballpark', 'assign', 'figures', 'status', 'meaning', 'want', 'manuf', 'implementing', 'respond', 'toolsgraphing', 'sufactant', 'josephs', 'hydrophilicjust', 'offs', 'little', 'began', 'part', 'umm', 'largest', 'comprehend', 'recommand', 'gaining', 'that', 'i\\x89û÷ll', 'reult', 'joe', 'therapy', 'rtfav', 'choose', 'friends', 'identifiable', 'hydrophilic', 'attends', 'agreed', 'financial', 'valid', 'insights', 'drywet', 'loaded', 'balances', 'paraphrase', 'permieter', 'questionmaybe', 'scale', 'exception', 'hydrophase', 'you\\x89ûªre', 'exceptions', 'tes', 'subject', 'hah', 'wikipedia', 'expand', 'pleasure', 'promoted', 'write', 'differnent', 'sufacat', 'jsut', 'preformance', 'electronic', 'researchgraph', 'sterichindrance', 'corey', 'reentered', 'shoot', 'way', 'no', 'allthough', 'sption', 'lacking', 'honestly', 'imagine', 'preferably', 'hgih', 'amazingly', 'fixing', 'locations', 'aarons', 'corrext', 'toy', 'insignificant', 'business', 'ruining', 'significantly', 'never', 'ddeposition', 'nassims', 'giid', 'mark', 'consistency', 'not', 'retrieve', 'narrowed', 'wanted', 'rated', 'trends', 'computers', 'silly', 'failed', 'glance', 'regard', 'owe', 'ionfection', 'idki', 'commonly', 'off', 'brought', 'max', 'spend', 'deflect', 'fresh', 'displayed', 'ovals', 'surfactantes', 'emily', 'justins', 'okay', 'chnage', 'literature', 'ignoring', 'favorite', 'yea', 'lesser', 'buusiness', 'witnessed', 'specifying', 'requirements', 'raised', 'allows', 'mess', 'thermoheglobin', 'nephrotex', 'home', 'formatting', 'weird', 'lively', 'managed', 'zeros', 'profit', 'processes', 'pasting', 'advertising', 'biological', 'header', 'paragraph', 'polymeric', 'timeor', 'he\\x89ûªd', 'arbitrary', 'characterisitic', 'chris', 'jake', 'adam', 'net', 'allowable', 'insurance', 'workbook', 'inferring', 'soun', 'interactions', 'deffeciency', 'operation', 'sufactants', 'severe', 'experimntally', 'combining', 'referencing', 'lowish', 'visualized', 'stayed', 'background', 'protos', 'ending', 'opinion', 'manufacture', 'alarm', 'fire', 'submited', 'guard', 'youre', 'fluxreliability', 'e', 'superscripts', 'tshirt', 'fyi', 'sets', 'decision', 'slot', 'relates', 'concentration', 'deviate', 'forever', 'sat', 'listing', 'clients', 'recommended', 'convenient', 'state', 'technically', 'runs', 'priyasha', 'boost', 'punches', 'warranted', 'for', 'checked', 'entainl', 'decreases', 'panel', 'ment', 'told', 'costliest', 'guide', 'assessments', 'confused', 'technical', 'thresh', 'bath', 'andrews', 'biggest', 'focuses', 'attachment', 'open', 'looked', 'rankings', 'depth', 'failure', 'mediocre', 'john', 'relevant', 'theorectically', 'attaches', 'cell', 'stats', 'costlu', 'headphones', 'logans', 'factor', 'peak', 'analyzing', 'improving', 'story', 'beta', 'micheal', 'peaks', 'bs', 'pack', 'principals', 'marketablity', 'anticipated', 'susceptible', 'synthetic', 'include', 'pull', 'came', 'helloooooo', 'have', 'bullets', 'allround', 'consultants\\x89ûª', 'anyhting', 'jonathon', 'happiest', 'witnessreturn', 'publishing', 'imortant', 'web', 'scottland', 'force', 'careful', 'achievable', 'civil', 'stand', 'logical', 'killin', 'admitted', 'bo', 'basis', 'confusion', 'marketabiliity', 'groupwide', 'relating', 'scorer', 'dieterle', 'combine', 'kennys', 'costlty', 'whomeveer', 'concentrations', 'profile', 'consultant', 'graphhelp', 'afternoon', 'configuration', 'intent', 'primarily', 'chances', 'rudy', 'yellow', 'clinics', 'determining', 'mondays', 'happened', 'reloaded', 'albert', 'commas', 'explored', 'soso', 'splendid', 'proofread', 'approaches', 'glossary', 'built', 'loading', 'starters', 'we', 'seperate', 'lenovo', 'harder', 'determined', 'hindrance', 'dumb', 'surprise', 'decay', 'trouble', 'smooth', 'effective', 'our', 'hdryo', 'clearer', 'pretty', 'article', 'im', 'principles', 'accidentally', 'crispins', 'correlated', 'fallow', 'department', 'comparable', 'advances', 'button', 'haha', 'representative', 'old', 'recent', 'polyrenalate', 'lose', 'teams', 'everyones', 'fully', 'extra', 'or', 'allergic', 'tomo', 'uncomfortable', 'composites', 'color', 'obsolete', 'painfully', 'realistic', 'original', 'made', 'conduct', 'thatthat', 'hinerance', 'coating', 'prototyper', 'premades', 'term', 'guidelines', 'yourselves', 'hidrance', 'delivered', 'hope', 'modifications', 'undecided', 'trade', 'could', 'matiral', 'desirable', 'signature', 'wiht', 'connect', 'depended', 'curve', 'chirstopher', 'texted', 'overlayed', 'period', 'steric', 'teresa', 'pure', 'tiem', 'permeablility', 'aww', 'aggressive', 'beause', 'jkim', 'hindurance', 'concussion', 'hemodialysis', 'everybodythank', 'polymerization', 'delgado', 'correction', 'assessed', 'collin', 'support', 'tristen', 'remedysolution', 'wholeheartedly', 'jordan', 'proceed', 'spite', 'newest', 'danny', 'specifically', 'alans', 'rational', 'unsubmitted', 'nicholas', 'goodnight', 'performs', 'topnotch', 'hello', 'clutch', 'achieved', 'sufficient', 'practices', 'convention', 'julie', 'readings', 'stilas', 'infer', 'manufactoring', 'oking', 'indication', 'across', 'test', 'noncorrelating', 'ponder', 'squad', 'tommorrow', 'normal', 'ruling', 'ended', 'opther', 'everyoness', 'frequently', 'areabut', 'aslo', 'read', 'vague', 'hydrophilc', 'onwhat', 'nest', 'finn', 'facility', 'members', 'upreminder', 'sue', 'loose', 'establish', 'production', 'inferior', 'asap', 'unknowns', 'disageree', 'sacrificed', 'appropriate', 'hindering', 'downside', 'difficulties', 'healthcare', 'letter', 'videos', 'right', 'wild', 'change', 'dear', 'confine', 'helped', 'called', 'above', 'funds', 'useless', 'first', 'glitch', 'leveled', 'struggeling', 'eduardo', 'adding', 'sized', 'compatible', 'worried', 'bestish', 'whenever', 'kristin', 'imma', 'needed', 'julia', 'speaking', 'okkkkay', 'sixth', 'al', 'smart', 'optimal', 'nobody', 'agreeded', 'frivolous', 'showed', 'stat', 'misguided', 'lasted', 'alpha', 'seconded', 'spelling', 'brings', 'honing', 'helping', 'choie', 'examples', 'tricky', 'satisfactory', 'icons', 'procress', 'suractant', 'alloweed', 'characteristics', 'simpler', 'late', 'highflux', 'ddahlksuedu', 'resultes', 'goodaveragebad', 'dokie', 'bar', 'asses', 'versions', 'tight', 'operates', 'upset', 'attaching', 'outweigh', 'pc', 'holds', 'head', 'pointed', 'nonrelaible', 'excells', 'nanotube', 'score', 'meet', 'toxins', 'reacitivity', 'markeability', 'contributor', 'candidate', 'greetings', 'refreshingclosing', 'sacrificing', 'rays', 'paste', 'nooo', 'adriannas', 'fake', 'package', 'oaky', 'corrections', 'jacob', 'represent', 'perfectly', 'annemarie', 'offsets', 'lucie', 'getting', 'elizabeth', 'meche', 'improve', 'apply', 'approved', 'member', 'ksu', 'laying', 'understandable', 'pmma', 'ours', 'directions', 'scaled', 'accident', 'gotten', 'suremaria', 'hows', 'been', 'fridays', 'dialyzing', 'everythings', 'dryjets', 'varieties', 'ya', 'prior', 'paying', 'deleted', 'tweaked', 'visualize', 'document', 'pair', 'unsuccessful', 'love', 'unnecessary', 'remember', 'care', 'hydrophilicty', 'renal', 'appease', 'reids', 'watching', 'tho', 'sacrifices', 'till', 'bae', 'wishes', 'speculation', 'sensors', 'fifth', 'isnstead', 'approx', 'as', 'won', 'happen', 'talk', 'wo', 'identical', 'distracted', 'much', 'filter', 'successes', 'impressive', 'names', 'final', 'sponsored', 'usual', 'roof', 'shaded', 'managerhis', 'prnlt', 'rounded', 'yoo', 'thurseday', 'jarrett', 'presented', 'reactive', 'ayudame', 'complies', 'figure', 'strict', 'was', 'chosen', 'white', 'expectation', 'leaning', 'hyophilic', 'marking', 'manner', 'produced', 'hyrophilic', 'thromogoglobulin', 'specificationspmma', 'ctrlc', 'effects', 'constructing', 'regularly', 'qualifications', 'proficient', 'fit', 'kiv', 'caught', 'materail', 'numbering', 'instance', 'customer', 'due', 'whatsup', 'awwwwww', 'exam', 'declared', 'francesca', 'college', 'tallied', 'attractive', 'graphms', 'acceptted', 'brooks', 'body', 'changes', 'ignore', 'revolving', 'hmmmaybe', 'maintaining', 'deal', 'details', 'reader', 'lena', 'shall', 'waiti', 'ahh', 'costly', 'darrens', 'stopped', 'picking', 'computer', 'finshed', 'attempt', 'bacth', 'matt', 'teammates', 'fourth', 'moores', 'shared', 'proccess', 'bugs', 'asking', 'yield', 'suites', 'pm', 'irrelevant', 'kk', 'ntc', 'seem', 'too', 'cyborg', 'finished', 'confusing', 'ì¢resourcesì¢', 'inverstion', 'yours', 'allisons', 'booted', 'trial', 'michelle', 'yinz', 'flourish', 'calender', 'fluctuate', 'persons', 'volunteer', 'wanye', 'colored', 'percentage', 'agemedical', 'continue', 'comments', 'refection', 't', 'properties', 'randomly', 'skills', 'thikn', 'woops', 'systems', 'covers', 'codes', 'statement', 'afternoonevening', 'hydro', 'bcr', 'definelty', 'waaaait', 'within', 'reporting', 'tie', 'mollys', 'employees', 'observations', 'memo', 'testable', 'bet', 'persuaded', 'fluxtfluxt', 'rock', 'addiditive', 'lowest', 'prioritizng', 'exposure', 'graphs', 'testin', 'undergrad', 'push', 'articles', 'albeit', 'glaring', 'hold', 'summarized', 'connecting', 'known', 'cold', 'posted', 'him', 'cancle', 'everthing', 'spoonfed', 'campus'}\n"
     ]
    }
   ],
   "source": [
    "#all words found in the content\n",
    "word_set = set().union(*df['content_tokenized'])\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting each sublist into all content said by each user\n",
    "user_dict = [] #creating an empty list to store all the sublist of all the words said by each user\n",
    "for idx in df['userIDs'].unique(): #loop over every unique id\n",
    "    lst = [word_tokenize(i) for i in df[df['userIDs'] == idx]['content_without_stopwords'].to_list()] #tokenize the contents of each row\n",
    "    tokenized_sents = [item for sublist in lst for item in sublist] #re-formatting \n",
    "    user_dict.append(tokenized_sents) #append the sublist into the user_dict list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['hello', 'team', 'welcome', 'nephrotex', 'maria', 'williams', 'design', 'advisor', 'internship', 'help', 'questions', 'please', 'introduce', 'name', 'prefer', 'called', 'workpro', 'records', 'work', 'do', 'review', 'external', 'consultant', 'improve', 'quality', 'internship', 'program', 'ask', 'use', 'first', 'name', 'internship', 'protect', 'privacy', 'want', 'make', 'sure', 'everyone', 'found', 'chat', 'interface', 'please', 'send', 'chat', 'check', 'in', 'group', 'make', 'chat', 'window', 'bigger', 'clicking', 'icon', 'top', 'right', 'corner', 'already', 'please', 'check', 'email', 'throughout', 'time', 'nephrotex', 'receiving', 'emails', 'boss', 'alex', 'hell', 'send', 'instructions', 'work', 'throughout', 'course', 'internship', 'now', 'please', 'check', 'deliverable', 'list', 'bottom', 'right', 'corner', 'workpro', 'deliverables', 'assigned', 'show', 'list', 'able', 'check', 'see', 'original', 'email', 'instructions', 'alex', 'sent', 'you', 'whether', 'submitted', 'deliverable', 'whether', 'vedant', 'approved', 'deliverable', 'detailed', 'information', 'deliverable', 'list', 'click', 'info', 'button', 'top', 'right', 'corner', 'deliverables', 'list', 'tab', 'provided', 'summary', 'workflow', 'resource', 'shared', 'space', 'plagiarism', 'tolerated', 'make', 'sure', 'paraphrase', 'summary', 'notebook', 'entry', 'done', 'notebook', 'entry', 'submit', 'alex', 'clicking', 'submit', 'button', 'middle', 'notebook', 'window', 'able', 'edit', 'entry', 'submitted', 'it', 'need', 'update', 'correct', 'work', 'cancel', 'submission', 'clicking', 'x', 'deliverables', 'list', 'cancel', 'submissions', 'alex', 'viewed', 'them', 'make', 'sure', 'included', 'everything', 'required', 'submitting', 'soon', 'submit', 'notebook', 'alex', 'review', 'send', 'feedback', 'soon', 'can', 'waiting', 'assist', 'teammates', 'submitted', 'deliverable', 'team', 'able', 'move', 'next', 'task', 'team', 'members', 'notebooks', 'witnessed', 'back', 'undergrad', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', 'working', 'different', 'project', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', 'alex', 'pretty', 'similar', 'boss', 'internship', 'welcome', 'use', 'template', 'write', 'own', 'note', 'language', 'length', 'response', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', 'alex', 'receives', 'notebook', 'receive', 'email', 'feedback', 'shortly', 'thereafter', 'recommend', 'completing', 'notebook', 'revisions', 'helping', 'teammates', 'finish', 'deliverables', 'wait', 'feedback', 'soon', 'teams', 'deliverables', 'submitted', 'witnessed', 'get', 'started', 'next', 'task', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', 'looking', 'surfactants', 'nevertheless', 'welcome', 'use', 'example', 'model', 'response', 'after', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', 'help', 'teammates', 'submitted', 'deliverable', 'yet', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', 'still', 'time', 'team', 'meeting', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', 'based', 'surfactant', 'graph', 'surfactants', 'perform', 'relative', 'one', 'another', 'one', 'surfactant', 'obviously', 'best', 'choice', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', 'choose', 'best', 'surfactant', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', 'value', 'attributes', 'others', 'choosing', 'best', 'surfactant', 'teams', 'next', 'step', 'be', 'hey', 'everyone', 'posted', 'writeup', 'mechanical', 'engineering', 'consultants', 'requirements', 'time', 'intern', 'find', 'writeup', 'shared', 'space', 'nephrotex', 'internal', 'consultants', 'experts', 'fields', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', 'intern', 'describe', 'certain', 'inputs', 'influence', 'outputs', 'ive', 'posted', 'writeup', 'shared', 'space', 'reference', 'goal', 'understand', 'how', 'given', 'particular', 'material', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'teams', 'material', 'back', 'internship', 'justify', 'design', 'decisions', 'made', 'found', 'useful', 'practice', 'working', 'alex', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', 'clear', 'team', 'member', 'design', 'prototypes', 'using', 'prnlt', 'materials', 'keep', 'mind', 'supervisor', 'nephrotex', 'employees', 'read', 'record', 'discussion', 'please', 'stay', 'task', 'royce', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', 'help', 'teammates', 'complete', 'deliverables', 'revise', 'incomplete', 'notebooks', 'work', 'presentation', 'presentation', 'include', 'everything', 'presentation', 'outline', 'located', 'resources', 'section', 'workpro', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', 'forget', 'attach', 'teams', 'new', 'batch', 'notebook', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', 'first', 'team', 'member', 'attaches', 'submits', 'teams', 'batch', 'rest', 'team', 'members', 'option', 'attach', 'batch', 'received', 'lab', 'results', 'internship', 'analyze', 'write', 'findings', 'remember', 'difficult', 'first', 'couple', 'times', 'posted', 'one', 'old', 'lab', 'writeups', 'shared', 'space', 'reference', 'remember', 'analysis', 'include', 'important', 'information', 'concise', 'wellorganized', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', 'okay', 'everyone', 'lets', 'get', 'going', 'want', 'hear', 'meeting', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', 'team', 'received', 'batch', 'results', 'successful', 'trial', 'discover', 'design', 'problem', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', 'hello', 'team', 'welcome', 'nephrotex', 'maria', 'williams', 'design', 'advisor', 'internship', 'help', 'questions', 'please', 'introduce', 'name', 'prefer', 'called', 'workpro', 'records', 'work', 'do', 'review', 'external', 'consultant', 'improve', 'quality', 'internship', 'program', 'ask', 'use', 'first', 'name', 'internship', 'protect', 'privacy', 'want', 'make', 'sure', 'everyone', 'found', 'chat', 'interface', 'please', 'send', 'chat', 'check', 'in', 'group', 'make', 'chat', 'window', 'bigger', 'clicking', 'icon', 'top', 'right', 'corner', 'already', 'please', 'check', 'email', 'throughout', 'time', 'nephrotex', 'receiving', 'emails', 'boss', 'alex', 'hell', 'send', 'instructions', 'work', 'throughout', 'course', 'internship', 'now', 'please', 'check', 'deliverable', 'list', 'bottom', 'right', 'corner', 'workpro', 'deliverables', 'assigned', 'show', 'list', 'able', 'check', 'see', 'original', 'email', 'instructions', 'alex', 'sent', 'you', 'whether', 'submitted', 'deliverable', 'whether', 'vedant', 'approved', 'deliverable', 'detailed', 'information', 'deliverable', 'list', 'click', 'info', 'button', 'top', 'right', 'corner', 'deliverables', 'list', 'tab', 'provided', 'summary', 'workflow', 'resource', 'shared', 'space', 'plagiarism', 'tolerated', 'make', 'sure', 'paraphrase', 'summary', 'notebook', 'entry', 'done', 'notebook', 'entry', 'submit', 'alex', 'clicking', 'submit', 'button', 'middle', 'notebook', 'window', 'able', 'edit', 'entry', 'submitted', 'it', 'need', 'update', 'correct', 'work', 'cancel', 'submission', 'clicking', 'x', 'deliverables', 'list', 'cancel', 'submissions', 'alex', 'viewed', 'them', 'make', 'sure', 'included', 'everything', 'required', 'submitting', 'soon', 'submit', 'notebook', 'alex', 'review', 'send', 'feedback', 'soon', 'can', 'waiting', 'assist', 'teammates', 'submitted', 'deliverable', 'team', 'able', 'move', 'next', 'task', 'team', 'members', 'notebooks', 'witnessed', 'back', 'undergrad', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', 'working', 'different', 'project', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', 'alex', 'pretty', 'similar', 'boss', 'internship', 'welcome', 'use', 'template', 'write', 'own', 'note', 'language', 'length', 'response', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', 'alex', 'receives', 'notebook', 'receive', 'email', 'feedback', 'shortly', 'thereafter', 'recommend', 'completing', 'notebook', 'revisions', 'helping', 'teammates', 'finish', 'deliverables', 'wait', 'feedback', 'soon', 'teams', 'deliverables', 'submitted', 'witnessed', 'get', 'started', 'next', 'task', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', 'looking', 'surfactants', 'nevertheless', 'welcome', 'use', 'example', 'model', 'response', 'after', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', 'help', 'teammates', 'submitted', 'deliverable', 'yet', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', 'still', 'time', 'team', 'meeting', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', 'based', 'surfactant', 'graph', 'surfactants', 'perform', 'relative', 'one', 'another', 'one', 'surfactant', 'obviously', 'best', 'choice', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', 'choose', 'best', 'surfactant', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', 'teams', 'next', 'step', 'be', 'need', 'improve', 'design', 'filtration', 'membrane', 'hey', 'everyone', 'posted', 'writeup', 'mechanical', 'engineering', 'consultants', 'requirements', 'time', 'intern', 'find', 'writeup', 'shared', 'space', 'nephrotex', 'internal', 'consultants', 'experts', 'fields', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', 'intern', 'describe', 'certain', 'inputs', 'influence', 'outputs', 'ive', 'posted', 'writeup', 'shared', 'space', 'reference', 'goal', 'understand', 'how', 'given', 'particular', 'material', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'teams', 'material', 'back', 'internship', 'justify', 'design', 'decisions', 'made', 'found', 'useful', 'practice', 'working', 'alex', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', 'clear', 'team', 'member', 'design', 'prototypes', 'using', 'pmma', 'materials', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', 'help', 'teammates', 'complete', 'deliverables', 'revise', 'incomplete', 'notebooks', 'work', 'presentation', 'presentation', 'include', 'everything', 'presentation', 'outline', 'located', 'resources', 'section', 'workpro', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', 'forget', 'attach', 'teams', 'new', 'batch', 'notebook', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', 'first', 'team', 'member', 'attaches', 'submits', 'teams', 'batch', 'rest', 'team', 'members', 'option', 'attach', 'batch', 'received', 'lab', 'results', 'internship', 'analyze', 'write', 'findings', 'remember', 'difficult', 'first', 'couple', 'times', 'posted', 'one', 'old', 'lab', 'writeups', 'shared', 'space', 'reference', 'remember', 'analysis', 'include', 'important', 'information', 'concise', 'wellorganized', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', 'okay', 'everyone', 'lets', 'get', 'going', 'want', 'hear', 'meeting', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', 'team', 'received', 'batch', 'results', 'successful', 'trial', 'discover', 'design', 'problem', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', 'may', 'new', 'design', 'advisor', 'new', 'team', 'glad', 'opportunity', 'work', 'though', 'thanks', 'great', 'discussions', 'professionalism', 'keep', 'good', 'work', 'new', 'teams', 'hello', 'team', 'welcome', 'nephrotex', 'maria', 'williams', 'design', 'advisor', 'internship', 'help', 'questions', 'please', 'introduce', 'name', 'prefer', 'called', 'workpro', 'records', 'work', 'do', 'review', 'external', 'consultant', 'improve', 'quality', 'internship', 'program', 'ask', 'use', 'first', 'name', 'internship', 'protect', 'privacy', 'want', 'make', 'sure', 'everyone', 'found', 'chat', 'interface', 'please', 'send', 'chat', 'check', 'in', 'group', 'make', 'chat', 'window', 'bigger', 'clicking', 'icon', 'top', 'right', 'corner', 'already', 'please', 'check', 'email', 'throughout', 'time', 'nephrotex', 'receiving', 'emails', 'boss', 'alex', 'hell', 'send', 'instructions', 'work', 'throughout', 'course', 'internship', 'now', 'please', 'check', 'deliverable', 'list', 'bottom', 'right', 'corner', 'workpro', 'deliverables', 'assigned', 'show', 'list', 'able', 'check', 'see', 'original', 'email', 'instructions', 'alex', 'sent', 'you', 'whether', 'submitted', 'deliverable', 'whether', 'vedant', 'approved', 'deliverable', 'detailed', 'information', 'deliverable', 'list', 'click', 'info', 'button', 'top', 'right', 'corner', 'deliverables', 'list', 'tab', 'provided', 'summary', 'workflow', 'resource', 'shared', 'space', 'plagiarism', 'tolerated', 'make', 'sure', 'paraphrase', 'summary', 'notebook', 'entry', 'done', 'notebook', 'entry', 'submit', 'alex', 'clicking', 'submit', 'button', 'middle', 'notebook', 'window', 'able', 'edit', 'entry', 'submitted', 'it', 'need', 'update', 'correct', 'work', 'cancel', 'submission', 'clicking', 'x', 'deliverables', 'list', 'cancel', 'submissions', 'alex', 'viewed', 'them', 'make', 'sure', 'included', 'everything', 'required', 'submitting', 'back', 'undergrad', 'interned', 'mechanical', 'engineering', 'company', 'designed', 'exoskeletons', 'rescue', 'workers', 'working', 'different', 'project', 'put', 'example', 'summary', 'used', 'previous', 'project', 'shared', 'space', 'alex', 'pretty', 'similar', 'boss', 'internship', 'welcome', 'use', 'template', 'write', 'own', 'note', 'language', 'length', 'response', 'please', 'pay', 'close', 'attention', 'citation', 'methods', 'used', 'example', 'know', 'alex', 'stickler', 'following', 'correct', 'citation', 'methods', 'still', 'received', 'deliverable', 'task', 'deadline', 'approaching', 'please', 'submit', 'notebook', 'soon', 'can', 'posted', 'another', 'notebook', 'entry', 'old', 'internship', 'shared', 'space', 'internship', 'studied', 'control', 'sensors', 'power', 'sources', 'looking', 'surfactants', 'nevertheless', 'welcome', 'use', 'example', 'model', 'response', 'after', 'submitted', 'notebook', 'waiting', 'feedback', 'alex', 'help', 'teammates', 'submitted', 'deliverable', 'yet', 'could', 'also', 'wrap', 'notebook', 'revisions', 'time', 'finish', 'earlier', 'still', 'time', 'team', 'meeting', 'may', 'want', 'start', 'working', 'final', 'presentation', 'giving', 'end', 'internship', 'find', 'outline', 'alex', 'expects', 'presentations', 'resource', 'section', 'workpro', 'recommend', 'start', 'working', 'background', 'research', 'section', 'presentation', 'now', 'based', 'surfactant', 'graph', 'surfactants', 'perform', 'relative', 'one', 'another', 'one', 'surfactant', 'obviously', 'best', 'choice', 'one', 'surfactant', 'performed', 'well', 'every', 'attribute', 'choose', 'best', 'surfactant', 'surfactant', 'graphs', 'helpful', 'making', 'final', 'surfactant', 'choice', 'value', 'attributes', 'others', 'choosing', 'best', 'surfactant', 'teams', 'next', 'step', 'be', 'hey', 'everyone', 'posted', 'writeup', 'mechanical', 'engineering', 'consultants', 'requirements', 'time', 'intern', 'find', 'writeup', 'shared', 'space', 'nephrotex', 'internal', 'consultants', 'experts', 'fields', 'let', 'know', 'questions', 'requirements', 'membrane', 'design', 'probably', 'want', 'check', 'staff', 'pages', 'information', 'too', 'intern', 'describe', 'certain', 'inputs', 'influence', 'outputs', 'ive', 'posted', 'writeup', 'shared', 'space', 'reference', 'goal', 'understand', 'how', 'given', 'particular', 'material', 'different', 'design', 'parameters', 'affect', 'attributes', 'prototype', 'alex', 'wants', 'figure', 'design', 'choices', 'different', 'internal', 'consultants', 'favor', 'assuming', 'use', 'teams', 'material', 'back', 'internship', 'justify', 'design', 'decisions', 'made', 'found', 'useful', 'practice', 'working', 'alex', 'know', 'would', 'like', 'see', 'similar', 'style', 'justification', 'posted', 'old', 'notebook', 'mine', 'shared', 'space', 'reference', 'clear', 'team', 'member', 'design', 'prototypes', 'using', 'psf', 'materials', 'alex', 'wanted', 'inform', 'things', 'submit', 'notebook', 'help', 'teammates', 'complete', 'deliverables', 'revise', 'incomplete', 'notebooks', 'work', 'presentation', 'presentation', 'include', 'everything', 'presentation', 'outline', 'located', 'resources', 'section', 'workpro', 'may', 'want', 'consider', 'research', 'design', 'challenges', 'developing', 'dialyzer', 'forget', 'attach', 'teams', 'new', 'batch', 'notebook', 'alex', 'upload', 'design', 'specifications', 'server', 'submit', 'justifications', 'member', 'team', 'needs', 'attach', 'submit', 'batch', 'testing', 'first', 'team', 'member', 'attaches', 'submits', 'teams', 'batch', 'rest', 'team', 'members', 'option', 'attach', 'batch', 'received', 'lab', 'results', 'internship', 'analyze', 'write', 'findings', 'remember', 'difficult', 'first', 'couple', 'times', 'posted', 'one', 'old', 'lab', 'writeups', 'shared', 'space', 'reference', 'remember', 'analysis', 'include', 'important', 'information', 'concise', 'wellorganized', 'alex', 'want', 'able', 'find', 'key', 'points', 'analysis', 'quickly', 'okay', 'everyone', 'lets', 'get', 'going', 'want', 'hear', 'meeting', 'please', 'see', 'meeting', 'summary', 'example', 'posted', 'shared', 'space', 'earlier', 'internship', 'need', 'example', 'notebook', 'team', 'received', 'batch', 'results', 'successful', 'trial', 'discover', 'design', 'problem', 'know', 'different', 'design', 'choices', 'affect', 'properties', 'device', 'access', 'shared', 'space', 'notebook', 'still', 'able', 'email', 'current', 'team', 'may', 'new', 'design', 'advisor', 'new', 'team', 'glad', 'opportunity', 'work', 'though']\n"
     ]
    }
   ],
   "source": [
    "print(user_dict[0]) #printing all content that user 1 said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list where each sublist is a dictionary that counts the frequency of all the words that are used by a user\n",
    "word_dict = [] #create an empty list to store all the words used\n",
    "for i in range(len(user_dict)):\n",
    "    #creating dictionaries to keep count of the words\n",
    "    temp_word_dict = dict.fromkeys(word_set, 0)\n",
    "    word_dict.append(temp_word_dict) #append each dictionary to the word dictionary \n",
    "    \n",
    "    #count the words in the bag of words for each user\n",
    "    for word in user_dict[i]:\n",
    "        word_dict[i][word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nefficient': 0, 'unanimous': 0, 'marketabuility': 0, 'boss': 6, 'selected': 0, 'discuss': 0, 'somereason': 0, 'desire': 0, 'haley': 0, 'redid': 0, 'difference': 0, 'evening': 0, 'reset': 0, 'far': 0, 'impact': 0, 'ahve': 0, 'tailored': 0, 'alter': 0, 'compensated': 0, 'somebody': 0, 'recommandations': 0, 'differnt': 0, 'exceeded': 0, 'polygon': 0, 'weighs': 0, 'straightforward': 0, 'decline': 0, 'listen': 0, 'various': 0, 'earlier': 6, 'chatting': 0, 'project': 6, 'wynters': 0, 'elses': 0, 'reach': 0, 'define': 0, 'feared': 0, 'additionally': 0, 'yas': 0, 'llooks': 0, 'mattered': 0, 'mckenna': 0, 'assumptions': 0, 'midpoint': 0, 'asks': 0, 'god': 0, 'outcome': 0, 'looks': 0, 'sum': 0, 'drawbacks': 0, 'efficiently': 0, 'amen': 0, 'roomate': 0, 'stable': 0, 'unequal': 0, 'block': 0, 'spotty': 0, 'feasible': 0, 'depisition': 0, 'reults': 0, 'informed': 0, 'xing': 0, 'deem': 0, 'inver': 0, 'worth': 0, 'lacked': 0, 'tht': 0, 'surfacant': 0, 'cellulose': 0, 'havent': 0, 'tremendously': 0, 'replying': 0, 'signs': 0, 'overlays': 0, 'caleb': 0, 'unique': 0, 'relflux': 0, 'purpose': 0, 'utterly': 0, 'ot': 0, 'customers': 0, 'proportionally': 0, 'ta': 0, 'rth': 0, 'adjustable': 0, 'serviceable': 0, 'adds': 0, 'awkward': 0, 'whats': 0, 'adhering': 0, 'pops': 0, 'helps': 0, 'illegible': 0, 'against': 0, 'safest': 0, 'power': 3, 'andy': 0, 'discover': 3, 'overboard': 0, 'poorlywritten': 0, 'choice': 6, 'prorotype': 0, 'greatings': 0, 'occurred': 0, 'quickly': 3, 'subpar': 0, 'investigating': 0, 'team': 28, 'viraat': 0, 'west': 0, 'bros': 0, 'peoplebiological': 0, 'responding': 0, 'adapt': 0, 'world': 0, 'concise': 3, 'present': 0, 'technique': 0, 'mouth': 0, 'dan': 0, 'evan': 0, 'applications': 0, 'cheap': 0, 'remotely': 0, 'overcompensates': 0, 'advisors': 0, 'attatchment': 0, 'exactly': 0, 'reviewed': 0, 'manu': 0, 'zelin': 0, 'cutting': 0, 'holes': 0, 'beliebe': 0, 'hoo': 0, 'titled': 0, 'mackenzy': 0, 'izzie': 0, 'leading': 0, 'summarizes': 0, 'perfomance': 0, 'teh': 0, 'understand': 3, 'raises': 0, 'reducing': 0, 'nano': 0, 'served': 0, 'definently': 0, 'depends': 0, 'unshared': 0, 'uh': 0, 'contacting': 0, 'documents': 0, 'although': 0, 'orr': 0, 'large': 0, 'hingdering': 0, 'suited': 0, 'hoped': 0, 'edited': 0, 'style': 3, 'submits': 3, 'goo': 0, 'knew': 0, 'overview': 0, 'ultrafluxphase': 0, 'stretch': 0, 'seperately': 0, 'argue': 0, 'vapor': 0, 'wearing': 0, 'from': 0, 'centers': 0, 'unanimously': 0, 'membranes': 0, 'worthwhile': 0, 'ff': 0, 'discard': 0, 'pmmas': 0, 'technicalities': 0, 'prime': 0, 'recalled': 0, 'fared': 0, 'values': 0, 'new': 8, 'wiebke': 0, 'lacks': 0, 'name': 6, 'lock': 0, 'explicitly': 0, 'available': 0, 'bests': 0, 'chunk': 0, 'ewith': 0, 'mechanical': 6, 'preferable': 0, 'shay': 0, 'outshines': 0, 'goto': 0, 'qualities': 0, 'subjects': 0, 'melissa': 0, 'extreme': 0, 'proposal': 0, 'x': 3, 'one': 12, 'perhaps': 0, 'ruby': 0, 'answers': 0, 'hinderance': 0, 'succeeded': 0, 'surfucant': 0, 'betathrombogloublin': 0, 'theyve': 0, 'professor': 0, 'showing': 0, 'cushion': 0, 'alexander': 0, 'gained': 0, 'st': 0, 'distribute': 0, 'bts': 0, 'done': 3, 'proceeding': 0, 'together': 0, 'weve': 0, 'relationship': 0, 'tamaras': 0, 'worst': 0, 'optimized': 0, 'chime': 0, 'records': 3, 'beter': 0, 'nature': 0, 'hi': 0, 'prioritizes': 0, 'jumped': 0, 'ramping': 0, 'waiting': 5, 'conluded': 0, 'surfactantss': 0, 'tiebreakers': 0, 'educated': 0, 'tech': 0, 'respect': 0, 'evidence': 0, 'hole': 0, 'trials': 0, 'satisfies': 0, 'naming': 0, 'match': 0, 'free': 0, 'challenge': 0, 'ditto': 0, 'forbidden': 0, 'pattern': 0, 'advantage': 0, 'httpimgurcomoryejkd': 0, 'dope': 0, 'replies': 0, 'chats': 0, 'always': 0, 'crashed': 0, 'idc': 0, 'nanotubule': 0, 'plot': 0, 'impacts': 0, 'opionions': 0, 'clogs': 0, 'definitions': 0, 'hhm': 0, 'dialysers': 0, 'yielded': 0, 'reliablility': 0, 'arent': 0, 'bump': 0, 'omg': 0, 'equipment': 0, 'scholar': 0, 'dat': 0, 'concluded': 0, 'reload': 0, 'optimism': 0, 'doubles': 0, 'stuck': 0, 'double': 0, 'downright': 0, 'hohn': 0, 'groupon': 0, 'purposes': 0, 'summaries': 0, 'problem': 3, 'dozens': 0, 'dismiss': 0, 'isolate': 0, 'offered': 0, 'bestflux': 0, 'specifially': 0, 'beginning': 0, 'travics': 0, 'perspective': 0, 'priority': 0, 'cahrge': 0, 'yesh': 0, 'tells': 0, 'jet': 0, 'preffered': 0, 'topic': 0, 'vedant': 3, 'hooligan': 0, 'garbage': 0, 'median': 0, 'neither': 0, 'reliabiltiy': 0, 'recomended': 0, 'suggestions': 0, 'enhance': 0, 'designing': 0, 'validate': 0, 'finicky': 0, 'contact': 0, 'acting': 0, 'apparently': 0, 'concentrate': 0, 'liked': 0, 'unable': 0, 'except': 0, 'break': 0, 'consults': 0, 'reacts': 0, 'f': 0, 'sup': 0, 'variables': 0, 'compromises': 0, 'exist': 0, 'troubling': 0, 'tools': 0, 'ahhh': 0, 'universal': 0, 'between': 0, 'multiplied': 0, 'journey': 0, 'requiremtns': 0, 'justifications': 3, 'aye': 0, 'points': 3, 'detriment': 0, 'tamera': 0, 'numerous': 0, 'fined': 0, 'containing': 0, 'companys': 0, 'table': 0, 'pursue': 0, 'option': 3, 'nay': 0, 'relatively': 0, 'lied': 0, 'instructors': 0, 'low': 0, 'moreso': 0, 'quality': 3, 'favored': 0, 'nathan': 0, 'master': 0, 'plus': 0, 'reccomendation': 0, 'entering': 0, 'demand': 0, 'limits': 0, 'invited': 0, 'radical': 0, 'rather': 0, 'extant': 0, 'become': 0, 'thats': 0, 'heartless': 0, 'position': 0, 'ions': 0, 'considered': 0, 'hwang': 0, 'products': 0, 'mason': 0, 'sounds': 0, 'padama': 0, 'secondary': 0, 'analytical': 0, 'listening': 0, 'versus': 0, 'instructions': 6, 'plagiarism': 3, 'death': 0, 'misread': 0, 'affest': 0, 'untill': 0, 'nothings': 0, 'behave': 0, 'top': 6, 'agrees': 0, 'hence': 0, 'doenst': 0, 'timeconsuming': 0, 'importance': 0, 'minnesota': 0, 'thankz': 0, 'shortcomings': 0, 'prioritize': 0, 'please': 20, 'suufactants': 0, 'ok': 0, 'general': 0, 'refer': 0, 'vdp': 0, 'slides': 0, 'profits': 0, 'writeup': 9, 'yup': 0, 'sentences': 0, 'sacrifice': 0, 'pushed': 0, 'nonzero': 0, 'be': 3, 'news': 0, 'game': 0, 'sample': 0, 'aint': 0, 'disappointed': 0, 'specifics': 0, 'marketiblity': 0, 'crunch': 0, 'clse': 0, 'fulfill': 0, 'worrying': 0, 'performence': 0, 'excpet': 0, 'heres': 0, 'presence': 0, 'brainstorm': 0, 'ahhhh': 0, 'pulled': 0, 'exact': 0, 'uhh': 0, 'sake': 0, 'grades': 0, 'round': 0, 'give': 0, 'requiring': 0, 'pores': 0, 'jacks': 0, 'interesting': 0, 'overkill': 0, 'risking': 0, 'broad': 0, 'leaving': 0, 'btwe': 0, 'beneficial': 0, 'glitchy': 0, 'tucker': 0, 'cancel': 6, 'bayleigh': 0, 'fellow': 0, 'enlightened': 0, 'ie': 0, 'csan': 0, 'internship': 33, 'statements': 0, 'timothy': 0, 'prof': 0, 'hw': 0, 'know': 12, 'life': 0, 'offense': 0, 'prolonged': 0, 'elaines': 0, 'xiangs': 0, 'hindernace': 0, 'nevermind': 0, 'remake': 0, 'workability': 0, 'ge': 0, 'parts': 0, 'failures': 0, 'haoxins': 0, 'collected': 0, 'justification': 3, 'namelycharlie': 0, 'thought': 0, 'advanced': 0, 'smallest': 0, 'benefit': 0, 'nuclear': 0, 'fine': 0, 'bench': 0, 'delayed': 0, 'ti': 0, 'eliminated': 0, 'desktop': 0, 'inform': 3, 'yeswith': 0, 'depending': 0, 'advise': 0, 'asked': 0, 'does': 0, 'andor': 0, 'surfactacant': 0, 'affirmative': 0, 'opinions': 0, 'shape': 0, 'knock': 0, 'tk': 0, 'referenced': 0, 'thin': 0, 'diversify': 0, 'myself': 0, 'wasting': 0, 'kurt': 0, 'thankfully': 0, 'peace': 0, 'evacuate': 0, 'premade': 0, 'dropping': 0, 'apart': 0, 'overlord': 0, 'lawsuits': 0, 'optimization': 0, 'interview': 0, 'sometime': 0, 'mentions': 0, 'tj': 0, 'ellens': 0, 'rylee': 0, 'spendng': 0, 'effexct': 0, 'grey': 0, 'serfactants': 0, 'limitations': 0, 'anyhow': 0, 'hurt': 0, 'while': 0, 'reactivivity': 0, 'byt': 0, 'pamda': 0, 'paid': 0, 'dons': 0, 'catagory': 0, 'azuma': 0, 'categorywhich': 0, 'votes': 0, 'inbox': 0, 'problematic': 0, 'listened': 0, 'grasping': 0, 'paperclip': 0, 'lets': 3, 'expressed': 0, 'inevitable': 0, 'however': 0, 'headtohead': 0, 'shocked': 0, 'hahahhaa': 0, 'themes': 0, 'idk': 0, 'minds': 0, 'extensive': 0, 'controlling': 0, 'knowlege': 0, 'r': 0, 'introduce': 3, 'mac': 0, 'surprises': 0, 'qucker': 0, 'blowing': 0, 'submitting': 3, 'allowed': 0, 'beforehand': 0, 'sams': 0, 'print': 0, 'clearly': 0, 'access': 1, 'someones': 0, 'aesthetics': 0, 'notebbok': 0, 'd': 0, 'solid': 0, 'critically': 0, 'marketabilaty': 0, 'bent': 0, 'thankyou': 0, 'realiable': 0, 'averaged': 0, 'must': 0, 'kyle': 0, 'finnished': 0, 'info': 3, 'partially': 0, 'welcome': 9, 'technonolgy': 0, 'knowing': 0, 'typical': 0, 'enhanced': 0, 'closer': 0, 'fact': 0, 'u': 0, 'catergories': 0, 'filling': 0, 'assest': 0, 'lowprice': 0, 'interests': 0, 'indicate': 0, 'balence': 0, 'webpage': 0, 'hinderince': 0, 'ballpark': 0, 'assign': 0, 'figures': 0, 'status': 0, 'meaning': 0, 'want': 18, 'manuf': 0, 'implementing': 0, 'respond': 0, 'toolsgraphing': 0, 'sufactant': 0, 'josephs': 0, 'hydrophilicjust': 0, 'offs': 0, 'little': 0, 'began': 0, 'part': 0, 'umm': 0, 'largest': 0, 'comprehend': 0, 'recommand': 0, 'gaining': 0, 'that': 0, 'i\\x89û÷ll': 0, 'reult': 0, 'joe': 0, 'therapy': 0, 'rtfav': 0, 'choose': 3, 'friends': 0, 'identifiable': 0, 'hydrophilic': 0, 'attends': 0, 'agreed': 0, 'financial': 0, 'valid': 0, 'insights': 0, 'drywet': 0, 'loaded': 0, 'balances': 0, 'paraphrase': 3, 'permieter': 0, 'questionmaybe': 0, 'scale': 0, 'exception': 0, 'hydrophase': 0, 'you\\x89ûªre': 0, 'exceptions': 0, 'tes': 0, 'subject': 0, 'hah': 0, 'wikipedia': 0, 'expand': 0, 'pleasure': 0, 'promoted': 0, 'write': 6, 'differnent': 0, 'sufacat': 0, 'jsut': 0, 'preformance': 0, 'electronic': 0, 'researchgraph': 0, 'sterichindrance': 0, 'corey': 0, 'reentered': 0, 'shoot': 0, 'way': 0, 'no': 0, 'allthough': 0, 'sption': 0, 'lacking': 0, 'honestly': 0, 'imagine': 0, 'preferably': 0, 'hgih': 0, 'amazingly': 0, 'fixing': 0, 'locations': 0, 'aarons': 0, 'corrext': 0, 'toy': 0, 'insignificant': 0, 'business': 0, 'ruining': 0, 'significantly': 0, 'never': 0, 'ddeposition': 0, 'nassims': 0, 'giid': 0, 'mark': 0, 'consistency': 0, 'not': 0, 'retrieve': 0, 'narrowed': 0, 'wanted': 3, 'rated': 0, 'trends': 0, 'computers': 0, 'silly': 0, 'failed': 0, 'glance': 0, 'regard': 0, 'owe': 0, 'ionfection': 0, 'idki': 0, 'commonly': 0, 'off': 0, 'brought': 0, 'max': 0, 'spend': 0, 'deflect': 0, 'fresh': 0, 'displayed': 0, 'ovals': 0, 'surfactantes': 0, 'emily': 0, 'justins': 0, 'okay': 3, 'chnage': 0, 'literature': 0, 'ignoring': 0, 'favorite': 0, 'yea': 0, 'lesser': 0, 'buusiness': 0, 'witnessed': 4, 'specifying': 0, 'requirements': 6, 'raised': 0, 'allows': 0, 'mess': 0, 'thermoheglobin': 0, 'nephrotex': 10, 'home': 0, 'formatting': 0, 'weird': 0, 'lively': 0, 'managed': 0, 'zeros': 0, 'profit': 0, 'processes': 0, 'pasting': 0, 'advertising': 0, 'biological': 0, 'header': 0, 'paragraph': 0, 'polymeric': 0, 'timeor': 0, 'he\\x89ûªd': 0, 'arbitrary': 0, 'characterisitic': 0, 'chris': 0, 'jake': 0, 'adam': 0, 'net': 0, 'allowable': 0, 'insurance': 0, 'workbook': 0, 'inferring': 0, 'soun': 0, 'interactions': 0, 'deffeciency': 0, 'operation': 0, 'sufactants': 0, 'severe': 0, 'experimntally': 0, 'combining': 0, 'referencing': 0, 'lowish': 0, 'visualized': 0, 'stayed': 0, 'background': 3, 'protos': 0, 'ending': 0, 'opinion': 0, 'manufacture': 0, 'alarm': 0, 'fire': 0, 'submited': 0, 'guard': 0, 'youre': 0, 'fluxreliability': 0, 'e': 0, 'superscripts': 0, 'tshirt': 0, 'fyi': 0, 'sets': 0, 'decision': 0, 'slot': 0, 'relates': 0, 'concentration': 0, 'deviate': 0, 'forever': 0, 'sat': 0, 'listing': 0, 'clients': 0, 'recommended': 0, 'convenient': 0, 'state': 0, 'technically': 0, 'runs': 0, 'priyasha': 0, 'boost': 0, 'punches': 0, 'warranted': 0, 'for': 0, 'checked': 0, 'entainl': 0, 'decreases': 0, 'panel': 0, 'ment': 0, 'told': 0, 'costliest': 0, 'guide': 0, 'assessments': 0, 'confused': 0, 'technical': 0, 'thresh': 0, 'bath': 0, 'andrews': 0, 'biggest': 0, 'focuses': 0, 'attachment': 0, 'open': 0, 'looked': 0, 'rankings': 0, 'depth': 0, 'failure': 0, 'mediocre': 0, 'john': 0, 'relevant': 0, 'theorectically': 0, 'attaches': 3, 'cell': 0, 'stats': 0, 'costlu': 0, 'headphones': 0, 'logans': 0, 'factor': 0, 'peak': 0, 'analyzing': 0, 'improving': 0, 'story': 0, 'beta': 0, 'micheal': 0, 'peaks': 0, 'bs': 0, 'pack': 0, 'principals': 0, 'marketablity': 0, 'anticipated': 0, 'susceptible': 0, 'synthetic': 0, 'include': 6, 'pull': 0, 'came': 0, 'helloooooo': 0, 'have': 0, 'bullets': 0, 'allround': 0, 'consultants\\x89ûª': 0, 'anyhting': 0, 'jonathon': 0, 'happiest': 0, 'witnessreturn': 0, 'publishing': 0, 'imortant': 0, 'web': 0, 'scottland': 0, 'force': 0, 'careful': 0, 'achievable': 0, 'civil': 0, 'stand': 0, 'logical': 0, 'killin': 0, 'admitted': 0, 'bo': 0, 'basis': 0, 'confusion': 0, 'marketabiliity': 0, 'groupwide': 0, 'relating': 0, 'scorer': 0, 'dieterle': 0, 'combine': 0, 'kennys': 0, 'costlty': 0, 'whomeveer': 0, 'concentrations': 0, 'profile': 0, 'consultant': 3, 'graphhelp': 0, 'afternoon': 0, 'configuration': 0, 'intent': 0, 'primarily': 0, 'chances': 0, 'rudy': 0, 'yellow': 0, 'clinics': 0, 'determining': 0, 'mondays': 0, 'happened': 0, 'reloaded': 0, 'albert': 0, 'commas': 0, 'explored': 0, 'soso': 0, 'splendid': 0, 'proofread': 0, 'approaches': 0, 'glossary': 0, 'built': 0, 'loading': 0, 'starters': 0, 'we': 0, 'seperate': 0, 'lenovo': 0, 'harder': 0, 'determined': 0, 'hindrance': 0, 'dumb': 0, 'surprise': 0, 'decay': 0, 'trouble': 0, 'smooth': 0, 'effective': 0, 'our': 0, 'hdryo': 0, 'clearer': 0, 'pretty': 3, 'article': 0, 'im': 0, 'principles': 0, 'accidentally': 0, 'crispins': 0, 'correlated': 0, 'fallow': 0, 'department': 0, 'comparable': 0, 'advances': 0, 'button': 6, 'haha': 0, 'representative': 0, 'old': 9, 'recent': 0, 'polyrenalate': 0, 'lose': 0, 'teams': 15, 'everyones': 0, 'fully': 0, 'extra': 0, 'or': 0, 'allergic': 0, 'tomo': 0, 'uncomfortable': 0, 'composites': 0, 'color': 0, 'obsolete': 0, 'painfully': 0, 'realistic': 0, 'original': 3, 'made': 3, 'conduct': 0, 'thatthat': 0, 'hinerance': 0, 'coating': 0, 'prototyper': 0, 'premades': 0, 'term': 0, 'guidelines': 0, 'yourselves': 0, 'hidrance': 0, 'delivered': 0, 'hope': 0, 'modifications': 0, 'undecided': 0, 'trade': 0, 'could': 3, 'matiral': 0, 'desirable': 0, 'signature': 0, 'wiht': 0, 'connect': 0, 'depended': 0, 'curve': 0, 'chirstopher': 0, 'texted': 0, 'overlayed': 0, 'period': 0, 'steric': 0, 'teresa': 0, 'pure': 0, 'tiem': 0, 'permeablility': 0, 'aww': 0, 'aggressive': 0, 'beause': 0, 'jkim': 0, 'hindurance': 0, 'concussion': 0, 'hemodialysis': 0, 'everybodythank': 0, 'polymerization': 0, 'delgado': 0, 'correction': 0, 'assessed': 0, 'collin': 0, 'support': 0, 'tristen': 0, 'remedysolution': 0, 'wholeheartedly': 0, 'jordan': 0, 'proceed': 0, 'spite': 0, 'newest': 0, 'danny': 0, 'specifically': 0, 'alans': 0, 'rational': 0, 'unsubmitted': 0, 'nicholas': 0, 'goodnight': 0, 'performs': 0, 'topnotch': 0, 'hello': 3, 'clutch': 0, 'achieved': 0, 'sufficient': 0, 'practices': 0, 'convention': 0, 'julie': 0, 'readings': 0, 'stilas': 0, 'infer': 0, 'manufactoring': 0, 'oking': 0, 'indication': 0, 'across': 0, 'test': 0, 'noncorrelating': 0, 'ponder': 0, 'squad': 0, 'tommorrow': 0, 'normal': 0, 'ruling': 0, 'ended': 0, 'opther': 0, 'everyoness': 0, 'frequently': 0, 'areabut': 0, 'aslo': 0, 'read': 1, 'vague': 0, 'hydrophilc': 0, 'onwhat': 0, 'nest': 0, 'finn': 0, 'facility': 0, 'members': 5, 'upreminder': 0, 'sue': 0, 'loose': 0, 'establish': 0, 'production': 0, 'inferior': 0, 'asap': 0, 'unknowns': 0, 'disageree': 0, 'sacrificed': 0, 'appropriate': 0, 'hindering': 0, 'downside': 0, 'difficulties': 0, 'healthcare': 0, 'letter': 0, 'videos': 0, 'right': 9, 'wild': 0, 'change': 0, 'dear': 0, 'confine': 0, 'helped': 0, 'called': 3, 'above': 0, 'funds': 0, 'useless': 0, 'first': 9, 'glitch': 0, 'leveled': 0, 'struggeling': 0, 'eduardo': 0, 'adding': 0, 'sized': 0, 'compatible': 0, 'worried': 0, 'bestish': 0, 'whenever': 0, 'kristin': 0, 'imma': 0, 'needed': 0, 'julia': 0, 'speaking': 0, 'okkkkay': 0, 'sixth': 0, 'al': 0, 'smart': 0, 'optimal': 0, 'nobody': 0, 'agreeded': 0, 'frivolous': 0, 'showed': 0, 'stat': 0, 'misguided': 0, 'lasted': 0, 'alpha': 0, 'seconded': 0, 'spelling': 0, 'brings': 0, 'honing': 0, 'helping': 2, 'choie': 0, 'examples': 0, 'tricky': 0, 'satisfactory': 0, 'icons': 0, 'procress': 0, 'suractant': 0, 'alloweed': 0, 'characteristics': 0, 'simpler': 0, 'late': 0, 'highflux': 0, 'ddahlksuedu': 0, 'resultes': 0, 'goodaveragebad': 0, 'dokie': 0, 'bar': 0, 'asses': 0, 'versions': 0, 'tight': 0, 'operates': 0, 'upset': 0, 'attaching': 0, 'outweigh': 0, 'pc': 0, 'holds': 0, 'head': 0, 'pointed': 0, 'nonrelaible': 0, 'excells': 0, 'nanotube': 0, 'score': 0, 'meet': 0, 'toxins': 0, 'reacitivity': 0, 'markeability': 0, 'contributor': 0, 'candidate': 0, 'greetings': 0, 'refreshingclosing': 0, 'sacrificing': 0, 'rays': 0, 'paste': 0, 'nooo': 0, 'adriannas': 0, 'fake': 0, 'package': 0, 'oaky': 0, 'corrections': 0, 'jacob': 0, 'represent': 0, 'perfectly': 0, 'annemarie': 0, 'offsets': 0, 'lucie': 0, 'getting': 0, 'elizabeth': 0, 'meche': 0, 'improve': 4, 'apply': 0, 'approved': 3, 'member': 9, 'ksu': 0, 'laying': 0, 'understandable': 0, 'pmma': 1, 'ours': 0, 'directions': 0, 'scaled': 0, 'accident': 0, 'gotten': 0, 'suremaria': 0, 'hows': 0, 'been': 0, 'fridays': 0, 'dialyzing': 0, 'everythings': 0, 'dryjets': 0, 'varieties': 0, 'ya': 0, 'prior': 0, 'paying': 0, 'deleted': 0, 'tweaked': 0, 'visualize': 0, 'document': 0, 'pair': 0, 'unsuccessful': 0, 'love': 0, 'unnecessary': 0, 'remember': 6, 'care': 0, 'hydrophilicty': 0, 'renal': 0, 'appease': 0, 'reids': 0, 'watching': 0, 'tho': 0, 'sacrifices': 0, 'till': 0, 'bae': 0, 'wishes': 0, 'speculation': 0, 'sensors': 3, 'fifth': 0, 'isnstead': 0, 'approx': 0, 'as': 0, 'won': 0, 'happen': 0, 'talk': 0, 'wo': 0, 'identical': 0, 'distracted': 0, 'much': 0, 'filter': 0, 'successes': 0, 'impressive': 0, 'names': 0, 'final': 6, 'sponsored': 0, 'usual': 0, 'roof': 0, 'shaded': 0, 'managerhis': 0, 'prnlt': 1, 'rounded': 0, 'yoo': 0, 'thurseday': 0, 'jarrett': 0, 'presented': 0, 'reactive': 0, 'ayudame': 0, 'complies': 0, 'figure': 3, 'strict': 0, 'was': 0, 'chosen': 0, 'white': 0, 'expectation': 0, 'leaning': 0, 'hyophilic': 0, 'marking': 0, 'manner': 0, 'produced': 0, 'hyrophilic': 0, 'thromogoglobulin': 0, 'specificationspmma': 0, 'ctrlc': 0, 'effects': 0, 'constructing': 0, 'regularly': 0, 'qualifications': 0, 'proficient': 0, 'fit': 0, 'kiv': 0, 'caught': 0, 'materail': 0, 'numbering': 0, 'instance': 0, 'customer': 0, 'due': 0, 'whatsup': 0, 'awwwwww': 0, 'exam': 0, 'declared': 0, 'francesca': 0, 'college': 0, 'tallied': 0, 'attractive': 0, 'graphms': 0, 'acceptted': 0, 'brooks': 0, 'body': 0, 'changes': 0, 'ignore': 0, 'revolving': 0, 'hmmmaybe': 0, 'maintaining': 0, 'deal': 0, 'details': 0, 'reader': 0, 'lena': 0, 'shall': 0, 'waiti': 0, 'ahh': 0, 'costly': 0, 'darrens': 0, 'stopped': 0, 'picking': 0, 'computer': 0, 'finshed': 0, 'attempt': 0, 'bacth': 0, 'matt': 0, 'teammates': 10, 'fourth': 0, 'moores': 0, 'shared': 25, 'proccess': 0, 'bugs': 0, 'asking': 0, 'yield': 0, 'suites': 0, 'pm': 0, 'irrelevant': 0, 'kk': 0, 'ntc': 0, 'seem': 0, 'too': 3, 'cyborg': 0, 'finished': 0, 'confusing': 0, 'ì¢resourcesì¢': 0, 'inverstion': 0, 'yours': 0, 'allisons': 0, 'booted': 0, 'trial': 3, 'michelle': 0, 'yinz': 0, 'flourish': 0, 'calender': 0, 'fluctuate': 0, 'persons': 0, 'volunteer': 0, 'wanye': 0, 'colored': 0, 'percentage': 0, 'agemedical': 0, 'continue': 0, 'comments': 0, 'refection': 0, 't': 0, 'properties': 3, 'randomly': 0, 'skills': 0, 'thikn': 0, 'woops': 0, 'systems': 0, 'covers': 0, 'codes': 0, 'statement': 0, 'afternoonevening': 0, 'hydro': 0, 'bcr': 0, 'definelty': 0, 'waaaait': 0, 'within': 0, 'reporting': 0, 'tie': 0, 'mollys': 0, 'employees': 1, 'observations': 0, 'memo': 0, 'testable': 0, 'bet': 0, 'persuaded': 0, 'fluxtfluxt': 0, 'rock': 0, 'addiditive': 0, 'lowest': 0, 'prioritizng': 0, 'exposure': 0, 'graphs': 3, 'testin': 0, 'undergrad': 3, 'push': 0, 'articles': 0, 'albeit': 0, 'glaring': 0, 'hold': 0, 'summarized': 0, 'connecting': 0, 'known': 0, 'cold': 0, 'posted': 18, 'him': 0, 'cancle': 0, 'everthing': 0, 'spoonfed': 0, 'campus': 0}\n"
     ]
    }
   ],
   "source": [
    "print(word_dict[0]) #printing the dictionary of user 1"
   ]
  },
  {
   "source": [
    "## TF-IDF\n",
    "\n",
    "Rather than just counting, we can use <u>TF-IDF</u>, short for term frequency-inverse document frequency to rank a word on it's importance.\n",
    "\n",
    "The <u>TF-IDF</u> score of a word $w$ is:\n",
    "$$tf(w) * idf(w)$$\n",
    "Where $tf(w) =$ frequency of word in a document / total number of words in the document\n",
    "\n",
    "And where $idf(w) = log$(number of documents / number of documents that contain word $w$)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(word_dict, user_dict):\n",
    "    tf_dict = {}\n",
    "    user_dict_count = len(user_dict)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(user_dict_count)\n",
    "    return tf_dict\n",
    "\n",
    "def computeIDF(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    n = len(doc_list)\n",
    "\n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(),0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "\n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(n / float(val), 10)\n",
    "\n",
    "    return idf_dict\n",
    "\n",
    "def computeTFIDF(tf_user_dict, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_user_dict.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "source": [
    "### Example of TF-IDF\n",
    "\n",
    "Suppose we have two documents as listed below. The calculation of <u>TF-IDF</u> for the term \"hello\" is performed as: \n",
    "\n",
    "The <u>TF</u>, is the frequency that the word \"hello\" appears in each document. In each document, the word appears once; but as document 1 (index 0) has more words, its relative frequency is smaller.\n",
    "\n",
    "$$ tf('hello', doc1) = \\frac{1}{4} = 0.25 $$\n",
    "$$ tf('hello', doc2) = \\frac{1}{2} = 0.5 $$\n",
    "\n",
    "An <u>IDF</u> accounts for the ratio of documents that include the word \"hello\". In this case, we have a total of two documents and all of them include the word \"hello\".\n",
    "\n",
    "$$ idf('hello', documents) = log(\\frac{2}{2}) = 0 $$\n",
    "\n",
    "So <u>TF-IDF</u> is 0 for the word \"hello\" implying that the word is not very informative as it appears in all documents.\n",
    "\n",
    "$$ tfidf('hello', doc1, documents) = 0.25 * 0 = 0 $$\n",
    "$$ tfidf('hello', doc2, documents) = 0.5 * 0 = 0 $$\n",
    "\n",
    "Take the word \"team\", it occurs once only in document 1:\n",
    "\n",
    "$$ tf('team', doc1) = \\frac{1}{4} = 0.25 $$\n",
    "$$ tf('team', doc2) = \\frac{0}{2} = 0 $$\n",
    "$$ idf('team', documents) = log(\\frac{2}{1}) \\approx 0.301 $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ tfidf('team', doc1, documents) = tf('team', doc1) * idf('team', documents) = 0.25 * 0.301 \\approx 0.075 $$\n",
    "$$ tfidf('team', doc2, documents) = tf('team', doc2) * idf('team', documents) = 0 * 0.301 = 0 $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   hello  brandon  welcome  team  nephrotex\n",
       "0      1        0        1     1          1\n",
       "1      1        1        0     0          0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hello</th>\n      <th>brandon</th>\n      <th>welcome</th>\n      <th>team</th>\n      <th>nephrotex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "doc1 = word_tokenize(df['content_without_stopwords'][0])\n",
    "doc2 = word_tokenize(df['content_without_stopwords'][5])\n",
    "\n",
    "word_set_example = set(doc1).union(set(doc2))\n",
    "word_dict1 = dict.fromkeys(word_set_example, 0)\n",
    "word_dict2 = dict.fromkeys(word_set_example, 0)\n",
    "\n",
    "for word in doc1:\n",
    "    word_dict1[word] += 1\n",
    "\n",
    "for word in doc2:\n",
    "    word_dict2[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict1, word_dict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello\ntf for document 1: 0.25\ntf for document 2: 0.5\nidf for documents: 0.0\ntfidf for document 1: 0.0\ntfidf for document 2: 0.0\n\nteam\ntf for document 1: 0.25\ntf for document 2: 0.0\nidf for documents: 0.30102999566398114\ntfidf for document 1: 0.07525749891599529\ntfidf for document 2: 0.0\n"
     ]
    }
   ],
   "source": [
    "tf1_example = computeTF(word_dict1, doc1)\n",
    "tf2_example = computeTF(word_dict2, doc2)\n",
    "\n",
    "idf_example = computeIDF([word_dict1, word_dict2])\n",
    "\n",
    "tfidf1_example = computeTFIDF(tf1_example, idf_example)\n",
    "tfidf2_example = computeTFIDF(tf2_example, idf_example)\n",
    "\n",
    "print(\"hello\")\n",
    "print(\"tf for document 1: \" + str(tf1_example['hello']))\n",
    "print(\"tf for document 2: \" + str(tf2_example['hello']))\n",
    "print(\"idf for documents: \" + str(idf_example['hello']))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example['hello']))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example['hello']))\n",
    "print(\"\")\n",
    "print(\"team\")\n",
    "print(\"tf for document 1: \" + str(tf1_example['team']))\n",
    "print(\"tf for document 2: \" + str(tf2_example['team']))\n",
    "print(\"idf for documents: \" + str(idf_example['team']))\n",
    "print(\"tfidf for document 1: \" + str(tfidf1_example['team']))\n",
    "print(\"tfidf for document 2: \" + str(tfidf2_example['team']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF(word_dict) #compute idf\n",
    "tf = [] #create empty list to append tf values\n",
    "tfidf = [] #create empty list to append tf-idf values\n",
    "for i in range(len(user_dict)): \n",
    "    temp_tf_user_dict = computeTF(word_dict[i], user_dict[i]) #compute tf\n",
    "    temp_tfidf_user_dict = computeTFIDF(temp_tf_user_dict, idfs) #compute tf-idf\n",
    "    tf.append(temp_tf_user_dict) #append tf values into list\n",
    "    tfidf.append(temp_tfidf_user_dict) #append tf-idf values into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       exceed  erics   hm  betathrom  exactky  dyjet  cohesiveness    amount  \\\n",
       "1    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "2    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.002933   \n",
       "3    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "4    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "5    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "..        ...    ...  ...        ...      ...    ...           ...       ...   \n",
       "389  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "390  0.004854    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "391  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "392  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "393  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "\n",
       "     drops  recap  ...  summarized  connecting  known  cold    posted  him  \\\n",
       "1      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.009704  0.0   \n",
       "2      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "3      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "4      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "5      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "..     ...    ...  ...         ...         ...    ...   ...       ...  ...   \n",
       "389    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "390    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "391    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "392    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "393    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "\n",
       "     cancle  everthing  spoonfed  campus  \n",
       "1       0.0        0.0       0.0     0.0  \n",
       "2       0.0        0.0       0.0     0.0  \n",
       "3       0.0        0.0       0.0     0.0  \n",
       "4       0.0        0.0       0.0     0.0  \n",
       "5       0.0        0.0       0.0     0.0  \n",
       "..      ...        ...       ...     ...  \n",
       "389     0.0        0.0       0.0     0.0  \n",
       "390     0.0        0.0       0.0     0.0  \n",
       "391     0.0        0.0       0.0     0.0  \n",
       "392     0.0        0.0       0.0     0.0  \n",
       "393     0.0        0.0       0.0     0.0  \n",
       "\n",
       "[393 rows x 5632 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exceed</th>\n      <th>erics</th>\n      <th>hm</th>\n      <th>betathrom</th>\n      <th>exactky</th>\n      <th>dyjet</th>\n      <th>cohesiveness</th>\n      <th>amount</th>\n      <th>drops</th>\n      <th>recap</th>\n      <th>...</th>\n      <th>summarized</th>\n      <th>connecting</th>\n      <th>known</th>\n      <th>cold</th>\n      <th>posted</th>\n      <th>him</th>\n      <th>cancle</th>\n      <th>everthing</th>\n      <th>spoonfed</th>\n      <th>campus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.009704</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002933</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.004854</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>393 rows × 5632 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_tf = pd.DataFrame.from_records(tf)\n",
    "df_tf.index = df_tf.index + 1 #shift index over by 1 to match the user id \n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       exceed  erics   hm  betathrom  exactky  dyjet  cohesiveness    amount  \\\n",
       "1    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "2    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.003117   \n",
       "3    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "4    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "5    0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "..        ...    ...  ...        ...      ...    ...           ...       ...   \n",
       "389  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "390  0.009672    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "391  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "392  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "393  0.000000    0.0  0.0        0.0      0.0    0.0           0.0  0.000000   \n",
       "\n",
       "     drops  recap  ...  summarized  connecting  known  cold    posted  him  \\\n",
       "1      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.010314  0.0   \n",
       "2      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "3      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "4      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "5      0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "..     ...    ...  ...         ...         ...    ...   ...       ...  ...   \n",
       "389    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "390    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "391    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "392    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "393    0.0    0.0  ...         0.0         0.0    0.0   0.0  0.000000  0.0   \n",
       "\n",
       "     cancle  everthing  spoonfed  campus  \n",
       "1       0.0        0.0       0.0     0.0  \n",
       "2       0.0        0.0       0.0     0.0  \n",
       "3       0.0        0.0       0.0     0.0  \n",
       "4       0.0        0.0       0.0     0.0  \n",
       "5       0.0        0.0       0.0     0.0  \n",
       "..      ...        ...       ...     ...  \n",
       "389     0.0        0.0       0.0     0.0  \n",
       "390     0.0        0.0       0.0     0.0  \n",
       "391     0.0        0.0       0.0     0.0  \n",
       "392     0.0        0.0       0.0     0.0  \n",
       "393     0.0        0.0       0.0     0.0  \n",
       "\n",
       "[393 rows x 5632 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exceed</th>\n      <th>erics</th>\n      <th>hm</th>\n      <th>betathrom</th>\n      <th>exactky</th>\n      <th>dyjet</th>\n      <th>cohesiveness</th>\n      <th>amount</th>\n      <th>drops</th>\n      <th>recap</th>\n      <th>...</th>\n      <th>summarized</th>\n      <th>connecting</th>\n      <th>known</th>\n      <th>cold</th>\n      <th>posted</th>\n      <th>him</th>\n      <th>cancle</th>\n      <th>everthing</th>\n      <th>spoonfed</th>\n      <th>campus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.010314</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003117</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.009672</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>393 rows × 5632 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame.from_records(tfidf) #make the matrix into a dataframe\n",
    "df_tfidf.index = df_tfidf.index + 1\n",
    "df_tfidf"
   ]
  },
  {
   "source": [
    "## Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_score = df.drop_duplicates(subset=['userIDs'])['OutcomeScore'].to_numpy() #grab outcome score of each individual user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User 376 outcome score: 8\n\nyes           0.023747\nnegative      0.021108\nprototypes    0.021108\none           0.018470\nwould         0.018470\nagree         0.015831\ncharge        0.015831\nflux          0.015831\nsteric        0.015831\nbest          0.013193\nName: 376, dtype: float64\n\nzachary        0.015003\neliminating    0.012102\nelizabeth      0.011173\nraw            0.010002\nyea            0.009471\ntaylor         0.008844\ndespite        0.008414\nnegative       0.006858\ndialyzing      0.006845\ncategorizes    0.006845\nName: 376, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_id = np.argmax(outcome_score)\n",
    "print(\"User \" + str(user_id) + \" outcome score: \" + str(outcome_score[user_id]) + '\\n')\n",
    "\n",
    "print(df_tf.loc[user_id].sort_values(ascending=False)[:10])\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_tfidf.loc[user_id].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User 14 outcome score: 0\n\nlasted         0.046332\nsurfactant     0.046332\nhydrophilic    0.034749\nsteric         0.030888\nhindrance      0.023166\nhours          0.023166\nsurfactants    0.019305\nbiological     0.015444\ntwo            0.015444\nthink          0.015444\nName: 14, dtype: float64\n\nlasted          0.120204\nproductivity    0.030051\ndropping        0.026564\nhours           0.024332\nfull            0.021955\nhour            0.017148\nhindrance       0.014609\ntimes           0.013471\nhydrophilic     0.012296\nlong            0.010577\nName: 14, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_id = np.argmin(outcome_score)\n",
    "print(\"User \" + str(user_id) + \" outcome score: \" + str(outcome_score[user_id]) + '\\n')\n",
    "\n",
    "print(df_tf.loc[user_id].sort_values(ascending=False)[:10])\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_tfidf.loc[user_id].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probability table for testing set is:\n[[1.08955394e-278 5.37459014e-288 3.11746239e-177 1.09043578e-019\n  1.10777551e-148 1.00000000e+000 4.00272349e-213 5.06558693e-193\n  2.38244696e-105]\n [0.00000000e+000 0.00000000e+000 1.00000000e+000 7.81517685e-108\n  0.00000000e+000 0.00000000e+000 6.39729629e-284 0.00000000e+000\n  0.00000000e+000]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  0.00000000e+000]\n [6.04696891e-134 0.00000000e+000 5.06923209e-127 1.00000000e+000\n  1.48100592e-091 3.92674989e-226 5.85540688e-199 4.76293950e-230\n  4.13893671e-109]\n [4.68672994e-101 0.00000000e+000 9.07076396e-299 1.57360207e-159\n  1.00000000e+000 9.97792163e-149 7.46886532e-142 1.62087621e-237\n  2.05209085e-119]\n [6.09382361e-126 9.76674834e-287 1.00522094e-124 1.10189557e-090\n  7.47061997e-050 1.00000000e+000 8.76478543e-108 1.87927993e-159\n  1.09323979e-052]\n [5.39703301e-276 1.38820251e-286 2.60795506e-156 1.00000000e+000\n  1.73538480e-114 3.14387690e-155 1.90429531e-170 1.28266838e-188\n  1.10215439e-117]\n [0.00000000e+000 0.00000000e+000 2.51661339e-298 7.10595588e-244\n  1.00000000e+000 7.69572971e-135 4.07026417e-240 1.66754652e-297\n  1.06129481e-186]\n [9.03766526e-143 2.04687193e-231 9.04173305e-071 1.00000000e+000\n  4.76308474e-188 4.75735834e-021 1.53317573e-055 3.37029561e-154\n  8.26572594e-037]\n [4.19593209e-215 0.00000000e+000 6.65143781e-318 7.26652772e-052\n  1.00000000e+000 1.70009627e-296 2.29919376e-298 2.06985477e-269\n  2.06671404e-169]\n [9.20304604e-284 7.16395186e-322 8.77608119e-118 4.41639373e-126\n  1.00000000e+000 6.95014450e-169 6.57700896e-119 2.72130422e-216\n  2.73529527e-101]\n [1.67939863e-260 0.00000000e+000 1.62160192e-264 1.81354206e-128\n  1.00000000e+000 1.21071363e-156 8.63072857e-147 1.75362379e-238\n  1.83530955e-116]\n [9.63034522e-245 0.00000000e+000 1.24922014e-312 1.00000000e+000\n  2.80993533e-237 0.00000000e+000 2.42889763e-203 0.00000000e+000\n  3.94588978e-240]\n [0.00000000e+000 0.00000000e+000 1.56060884e-200 1.65017064e-140\n  1.00000000e+000 4.90538185e-108 8.86181098e-103 3.03544584e-237\n  4.33286836e-124]\n [3.43833869e-131 8.43844398e-304 8.87309276e-238 3.25362040e-117\n  1.00000000e+000 3.39083701e-128 2.96017092e-148 7.03464856e-229\n  5.35385852e-095]\n [2.94314101e-248 0.00000000e+000 2.76283983e-219 1.00000000e+000\n  0.00000000e+000 7.20761380e-137 5.22940747e-216 1.75358428e-274\n  9.89548494e-152]\n [1.09949038e-187 2.83099615e-321 8.67605081e-011 8.22835952e-023\n  1.00000000e+000 3.62101361e-093 7.47921424e-040 2.73300779e-215\n  2.72248138e-064]\n [2.43574285e-051 2.42795178e-225 1.02715111e-040 1.00000000e+000\n  2.19239604e-079 1.82160938e-058 4.24784164e-125 1.63497512e-149\n  3.65399267e-043]\n [5.83543989e-270 1.55250919e-294 1.42831769e-229 1.00000000e+000\n  1.03130451e-042 9.08178378e-100 4.63065057e-112 3.15299386e-184\n  6.78797747e-092]\n [4.09125448e-057 4.76701785e-314 3.08319519e-209 1.00000000e+000\n  1.52203030e-087 1.87785473e-158 3.16185840e-073 9.74072124e-152\n  2.31738862e-069]\n [2.99492231e-077 2.16762217e-313 3.13003409e-236 9.20614560e-097\n  1.00000000e+000 1.66696642e-089 4.66792581e-233 2.45357509e-223\n  2.64454664e-107]\n [2.30381643e-075 0.00000000e+000 3.66653974e-170 2.37369446e-013\n  1.00000000e+000 2.35605303e-128 1.42005584e-154 1.45084844e-157\n  5.74803819e-069]\n [5.65561513e-150 0.00000000e+000 1.90602453e-252 1.23271470e-119\n  1.04933215e-098 1.00000000e+000 1.33438066e-127 4.80438889e-241\n  3.17423725e-120]\n [3.51143729e-239 0.00000000e+000 5.26159672e-143 1.12230459e-013\n  1.00000000e+000 3.85497604e-118 4.09713595e-156 1.71969193e-184\n  5.94519344e-078]\n [0.00000000e+000 1.16462445e-238 0.00000000e+000 3.08669481e-254\n  1.00000000e+000 1.08225288e-180 1.09214329e-201 7.35612107e-297\n  2.88874739e-172]\n [0.00000000e+000 0.00000000e+000 1.60613440e-272 0.00000000e+000\n  1.00000000e+000 5.80027881e-154 0.00000000e+000 0.00000000e+000\n  5.86748651e-276]\n [6.84704586e-114 3.01897515e-267 2.84654786e-086 1.23006391e-040\n  2.48671904e-066 6.88652975e-027 1.00000000e+000 2.19050433e-137\n  2.21846737e-026]\n [3.08281010e-184 7.27161066e-206 5.34754391e-159 1.00000000e+000\n  5.80958878e-071 1.37574329e-059 1.07624407e-142 1.40016992e-178\n  5.85638632e-075]\n [0.00000000e+000 2.00000448e-299 1.13246836e-111 6.49302813e-087\n  1.00000000e+000 1.54409558e-207 4.23900725e-146 7.92757908e-248\n  1.69783836e-110]\n [3.49481664e-211 0.00000000e+000 1.27793236e-048 1.00000000e+000\n  2.38616792e-162 1.86733433e-045 1.38954306e-141 3.32754141e-197\n  2.98044979e-096]\n [0.00000000e+000 0.00000000e+000 1.41125167e-137 2.04613529e-062\n  0.00000000e+000 6.17284625e-178 1.00000000e+000 0.00000000e+000\n  4.97142105e-217]\n [1.88694215e-117 0.00000000e+000 7.27903621e-199 1.00000000e+000\n  1.20327001e-027 0.00000000e+000 2.37852484e-192 8.13604044e-267\n  6.24887041e-160]\n [6.44849757e-227 1.02080585e-204 1.54236850e-121 8.94845869e-008\n  8.13904624e-067 9.99999911e-001 1.93188525e-093 2.27653806e-166\n  2.88443747e-045]\n [0.00000000e+000 1.89962707e-300 1.04460930e-213 8.54818821e-260\n  0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000\n  1.35208873e-291]\n [1.84462830e-225 1.12646967e-321 9.04543861e-093 1.56921179e-104\n  1.00000000e+000 9.44678309e-118 3.38227582e-010 7.43026646e-195\n  4.56640160e-076]\n [2.05010712e-236 1.50839358e-290 4.98899306e-154 1.45175447e-168\n  1.00000000e+000 5.83474350e-165 1.52597833e-122 1.18955909e-206\n  7.31006063e-099]\n [2.69428079e-120 0.00000000e+000 1.61168514e-156 2.88044411e-039\n  7.78039187e-089 1.00000000e+000 9.53381739e-106 2.00068239e-130\n  8.25270755e-069]\n [1.76207961e-305 0.00000000e+000 2.02439502e-218 1.20255895e-139\n  1.00000000e+000 2.34421547e-080 6.57959940e-203 1.37704162e-214\n  1.40776822e-127]\n [1.47586639e-169 5.42496518e-236 2.96135344e-027 1.00000000e+000\n  1.31310586e-167 2.83113168e-111 6.86263944e-151 7.02011570e-206\n  4.24725967e-080]\n [7.58316517e-254 4.60350293e-315 4.58116994e-029 1.00000000e+000\n  4.74700442e-025 1.26868048e-105 6.03432471e-111 2.07832348e-158\n  4.86294269e-042]\n [1.86821767e-124 1.62649576e-238 2.16752278e-069 1.00000000e+000\n  1.40972064e-028 9.90584292e-048 2.61849961e-093 2.40835542e-128\n  6.75545039e-031]\n [1.85440362e-258 4.39747704e-245 1.19467181e-086 5.75045146e-054\n  1.00000000e+000 5.80175149e-028 7.03625550e-083 2.08143753e-162\n  1.26685882e-056]\n [2.29533400e-314 0.00000000e+000 2.13053682e-193 2.14758950e-115\n  1.00000000e+000 3.25596750e-152 6.56156075e-249 3.84940065e-269\n  5.80698952e-149]\n [0.00000000e+000 1.23413868e-307 1.29602945e-154 2.17536072e-166\n  1.16846551e-044 1.00000000e+000 9.02170930e-194 9.19195011e-215\n  1.31438755e-128]\n [1.93627856e-231 0.00000000e+000 3.67186430e-252 2.82584979e-147\n  1.00000000e+000 6.19428874e-208 5.27948514e-249 8.48678575e-259\n  3.33165214e-156]\n [2.94426233e-024 7.90576844e-277 1.00000000e+000 4.79562177e-074\n  4.55705311e-143 1.18725753e-317 3.02371692e-119 8.27126751e-076\n  8.30083234e-081]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  0.00000000e+000]\n [3.96519850e-250 0.00000000e+000 3.65732152e-273 2.95786896e-175\n  1.00000000e+000 3.68223675e-052 4.20940729e-147 3.29285662e-223\n  1.21960373e-117]\n [4.18253263e-199 5.80254598e-262 3.49431101e-135 1.00000000e+000\n  5.10898707e-049 3.91099783e-103 4.72159939e-054 4.70762837e-177\n  1.85550277e-056]\n [5.37716753e-290 1.32696905e-313 2.76342543e-287 7.02345346e-095\n  3.26346364e-108 1.00000000e+000 2.86088542e-090 4.50273085e-206\n  1.47655681e-115]\n [0.00000000e+000 0.00000000e+000 1.17264708e-200 8.92206641e-181\n  3.33351272e-159 1.00000000e+000 4.48477851e-257 3.77220682e-221\n  1.54883338e-149]\n [0.00000000e+000 0.00000000e+000 1.00000000e+000 2.52739578e-182\n  1.14152989e-086 0.00000000e+000 0.00000000e+000 4.22516567e-301\n  1.62265997e-213]\n [3.11379684e-148 8.04249396e-160 3.34691949e-116 1.00000000e+000\n  1.15573116e-028 2.45567754e-026 1.75402383e-145 1.99955553e-144\n  1.44325920e-044]\n [0.00000000e+000 0.00000000e+000 7.30063735e-242 1.46325593e-033\n  1.00000000e+000 1.26780834e-089 2.12312282e-246 6.85230149e-217\n  7.16357686e-114]\n [1.67237793e-307 0.00000000e+000 1.07506341e-252 4.98049677e-308\n  1.00000000e+000 9.29680695e-266 3.11300602e-252 5.78046924e-319\n  7.28114651e-221]\n [4.82153710e-250 1.03227494e-225 1.93012277e-167 4.84543786e-001\n  5.15456214e-001 3.31265641e-222 3.69983112e-252 2.07575696e-187\n  5.74542162e-116]\n [4.80680989e-260 9.33635163e-266 2.94799412e-074 1.19368386e-023\n  1.02299272e-062 1.00000000e+000 3.64824273e-114 2.08749224e-148\n  1.31258243e-065]\n [5.67391606e-039 0.00000000e+000 2.83821551e-097 1.00000000e+000\n  6.37344683e-322 1.10676372e-047 2.49511543e-072 7.18753048e-137\n  1.07902096e-084]\n [6.48541831e-269 0.00000000e+000 6.22825822e-215 3.16095219e-122\n  9.99998304e-001 1.69565160e-006 3.39650418e-163 7.28535097e-232\n  5.81350891e-110]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000 8.25986342e-235\n  1.00000000e+000 1.17954456e-298 0.00000000e+000 0.00000000e+000\n  8.00456826e-265]\n [4.14157493e-175 5.72840335e-266 3.28565994e-111 2.53922446e-069\n  6.96138809e-072 1.00000000e+000 4.42394218e-082 1.14897623e-135\n  6.59566993e-054]\n [3.14929221e-255 5.23361105e-184 2.21224032e-053 1.00000000e+000\n  1.03962621e-091 3.34665074e-276 7.52192209e-126 1.79967261e-207\n  1.03091688e-096]\n [2.12665433e-261 2.01245757e-273 1.00000000e+000 5.66880011e-053\n  2.86859200e-201 2.45080272e-138 8.31678614e-176 1.15387583e-245\n  7.87502170e-105]\n [0.00000000e+000 0.00000000e+000 3.49539323e-252 1.00000000e+000\n  0.00000000e+000 6.01838461e-246 4.01498890e-280 0.00000000e+000\n  5.31966883e-214]\n [2.46343708e-289 3.60061748e-281 9.41386803e-194 1.00000000e+000\n  5.63182133e-017 6.82969916e-013 1.61242107e-121 3.85496540e-189\n  2.59893726e-063]\n [4.46548220e-069 1.19857171e-312 1.45342624e-216 2.71141931e-103\n  1.00000000e+000 5.29503873e-205 8.90730332e-136 1.64132538e-182\n  2.93476674e-081]\n [1.72712854e-263 0.00000000e+000 1.90526396e-096 4.64604092e-022\n  1.00000000e+000 3.02459379e-106 4.93854565e-171 1.75026596e-202\n  2.48260575e-100]\n [2.02685422e-306 5.29374438e-104 8.64362767e-179 1.00000000e+000\n  3.52976147e-126 8.54038039e-035 3.03248769e-162 3.09690114e-221\n  7.86197675e-089]\n [4.58803246e-237 1.54939879e-300 3.47197441e-308 2.42665559e-220\n  1.00000000e+000 3.13393357e-114 3.74534760e-193 3.04873442e-225\n  6.14359644e-123]\n [1.37702699e-044 6.06534708e-161 4.91099215e-253 9.23325241e-136\n  1.00000000e+000 2.91034515e-154 1.28373029e-042 1.28318673e-172\n  5.30790026e-066]\n [2.19886605e-214 4.41830059e-302 5.18242538e-109 1.00000000e+000\n  2.41932859e-129 2.13040829e-069 3.40596274e-148 4.03114406e-124\n  4.39456364e-056]\n [5.90620864e-129 2.49335169e-319 8.44779445e-177 6.35745582e-144\n  4.31552782e-027 1.00000000e+000 6.16394265e-069 1.76692489e-182\n  9.51092570e-068]\n [0.00000000e+000 0.00000000e+000 9.41301399e-234 1.00000000e+000\n  3.77724645e-272 6.59997593e-319 1.85641364e-176 3.44155943e-257\n  5.02576178e-192]\n [1.55978568e-292 2.88553372e-274 1.44843152e-151 3.44973057e-178\n  1.00000000e+000 6.40987005e-016 1.86363760e-038 7.15231609e-190\n  1.26197533e-074]\n [2.27133929e-148 9.95555145e-243 6.58146848e-058 2.16179875e-074\n  1.00000000e+000 1.61669554e-106 6.68538997e-186 3.05249385e-163\n  2.23150697e-076]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000 1.58126421e-207\n  1.00000000e+000 8.83976379e-279 4.18137583e-248 0.00000000e+000\n  1.44332418e-226]\n [1.77552580e-243 8.36848391e-320 3.25533012e-133 1.00000000e+000\n  7.85816846e-143 8.96628260e-032 2.23904729e-176 7.98039176e-150\n  6.37769583e-083]\n [5.08172341e-273 7.85072263e-236 4.58683582e-261 1.04113892e-111\n  1.80809921e-059 1.00000000e+000 8.74902687e-189 2.69583444e-206\n  8.67904260e-111]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n  0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # for splitting the data into training and testing sets\n",
    "from sklearn.linear_model import LogisticRegression # import the LogisticRegression model\n",
    "\n",
    "X = df_tfidf\n",
    "Y = outcome_score\n",
    "\n",
    "# split the data into 80% training and 20% testing, random_state=0 ensures that the results are repeatable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,train_size=0.8,random_state=0)  \n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "# penalty='none' implies no regularization and solver='lbfgs' is the default solver\n",
    "# different solvers can be used, dependent on the type of penalties that are implemented\n",
    "logreg = LogisticRegression(solver='lbfgs',penalty='none')\n",
    "logreg.fit(X_train,y_train) # fit the training data to the model\n",
    "\n",
    "y_preda = logreg.predict_proba(X_test) # calculate the probabilities for the test features\n",
    "# print out the probability table with a header\n",
    "print('Probability table for testing set is:')\n",
    "print(y_preda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.26582278481012656\n"
     ]
    }
   ],
   "source": [
    "y_pred=logreg.predict(X_test) # calculate the predicted values of the model for the test features\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score # import the score functions \n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred)) # calculate and print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              document  outcome_score\n",
       "0    hello team welcome nephrotex maria williams de...              4\n",
       "1    hello brandon imperative know answers question...              4\n",
       "2    zelin hi mean two relative table pattern biolo...              4\n",
       "3    jack flux time equals matter teh helpful showe...              4\n",
       "4    hey rachel agree cost factor would rather bett...              2\n",
       "..                                                 ...            ...\n",
       "388  hi royce yeah noticed thing cant right even fa...              7\n",
       "389  carly okay kind lost find marketability cost t...              4\n",
       "390  ellie used flux found steric hindering perform...              5\n",
       "391  hi cyrus anyone else receive email incorrect v...              5\n",
       "392  tyler meet group class coordinate project bett...              4\n",
       "\n",
       "[393 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>outcome_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hello team welcome nephrotex maria williams de...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hello brandon imperative know answers question...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>zelin hi mean two relative table pattern biolo...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jack flux time equals matter teh helpful showe...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hey rachel agree cost factor would rather bett...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>hi royce yeah noticed thing cant right even fa...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>carly okay kind lost find marketability cost t...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>ellie used flux found steric hindering perform...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>hi cyrus anyone else receive email incorrect v...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>tyler meet group class coordinate project bett...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>393 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "documents = [] \n",
    "for i in range(len(user_dict)): \n",
    "    doc = \" \".join(user_dict[i]) \n",
    "    documents.append(doc) \n",
    "\n",
    "df_documents = pd.DataFrame()\n",
    "df_documents[\"document\"] = documents\n",
    "df_documents[\"outcome_score\"] = outcome_score\n",
    "df_documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}